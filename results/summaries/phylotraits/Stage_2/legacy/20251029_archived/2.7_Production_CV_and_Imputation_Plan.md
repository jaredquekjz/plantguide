# Stage 2.7: Production CV and Imputation Plan (Tier 2)

**Date**: 2025-10-29
**Status**: Planning document - ready for execution
**Dataset**: 11,680 species (full production dataset)

## Purpose

Apply optimal hyperparameters from Tier 1 grid search to the full 11,680-species production dataset for:

1. **Production CV**: Validate model performance on maximum species coverage
2. **EIVE Imputation**: Predict missing EIVE values for 5,515 species
3. **SHAP Analysis**: Generate feature importance rankings on production scale

## Context from Tier 1 Results

### Tier 1 Optimal Hyperparameters (1,084 species)

From completed grid search (see Stage 2.1-2.5):

| Axis | Learning Rate | N Estimators | Test R² | Test MAE | Best Features |
|------|---------------|--------------|---------|----------|---------------|
| **L** | 0.03 | 1500 | 0.621 ± 0.050 | 0.694 ± 0.066 | p_phylo_L (#2), wc2 bio_10 q50 (#1) |
| **T** | 0.03 | 1500 | 0.809 ± 0.043 | 0.380 ± 0.036 | wc2 bio_10 q50 (#1), EIVEres-M (#2) |
| **M** | 0.03 | 5000 | 0.675 ± 0.049 | 0.631 ± 0.052 | p_phylo_M (#1), wc2 bio_12 q50 (#2) |
| **N** | 0.03 | 1500 | 0.701 ± 0.030 | 0.792 ± 0.028 | p_phylo_N (#2), EIVEres-M (#1) |
| **R** | 0.05 | 1500 | 0.530 ± 0.109 | 0.737 ± 0.042 | EIVEres-M (#1), p_phylo_R (#6) |

**Key insight**: Phylogenetic predictors (p_phylo) consistently rank in top 3 for L/M/N axes, validating context-dependent calculation approach.

## Tier 2 Dataset Overview

### Production Master Table

**File**: `model_data/outputs/perm2_production/perm2_11680_complete_final_20251028.parquet`

**Dimensions**: 11,680 species × 741 features

**EIVE Missingness Patterns**:
| Pattern | Count | Percentage | Imputation Strategy |
|---------|-------|------------|---------------------|
| Complete EIVE (all 5 axes) | 5,924 | 50.7% | Already complete ✓ |
| Partial EIVE (1-4 axes) | 337 | 2.9% | Use full models with cross-axis EIVE |
| No EIVE (0 axes) | 5,419 | 46.4% | Use no-EIVE models (exclude cross-axis) |

**Key Insight**: Nearly half the dataset (5,419 species) lacks ALL EIVE observations. These globally-distributed species cannot use cross-axis EIVE features, requiring a separate modeling approach.

**Feature Coverage**:
- Traits (log): 100% (11,680 / 11,680)
- Phylo eigenvectors: 99.6% (11,638 / 11,680)
- **Phylo predictors (p_phylo)**: Context-matched for CV (~5,400 per axis)
- Environmental quantiles: 100% (11,680 / 11,680)

### Key Differences from Tier 1

**Phylogenetic predictors**:
- **Tier 1**: Used corrected p_phylo calculated on pruned 1,075-species tree (context-matched)
- **Tier 2**: Uses context-matched p_phylo calculated on axis-specific CV trees (~5,400 species)

**Training dataset**:
- **Tier 1**: 1,084 European-biased species (high trait quality, limited geographic scope)
- **Tier 2**: ~6,200 globally-distributed species (moderate trait quality via mixgb, broad taxonomic diversity)

**Decision**: Train on Tier 2 for better generalization to 5,419 globally-distributed no-EIVE species.

---

## Two-Model Hybrid Strategy

### The Cross-Axis EIVE Dependency Problem

**Cross-axis EIVE importance in production models** (from corrected Tier 2 CV):
- **L-axis**: 14.7% of total SHAP (EIVEres-M is rank #1 predictor!)
- **M-axis**: 14.8% of total SHAP (EIVEres-N is rank #2)
- **N-axis**: 16.1% of total SHAP (EIVEres-M is rank #2)
- **R-axis**: 9.4% of total SHAP (EIVEres-N is rank #2)
- **T-axis**: 6.5% of total SHAP (EIVEres-M is rank #4)

**Problem**: For 5,419 species with NO observed EIVE, all cross-axis EIVE features will be missing. Using full models with XGBoost surrogate splits is problematic because:
1. Models never trained on "all-EIVE-missing" scenario
2. Lose 6-16% explanatory power
3. Prediction quality unknown/untested

### Solution: Dual-Model Approach

**Model 1: Full Models (with cross-axis EIVE)**
- **Training data**: ~6,200 species per axis with observed EIVE (Tier 2)
- **Features**: All predictors including cross-axis EIVE (e.g., EIVEres-M for predicting L)
- **Use for**: 337 species with partial EIVE (some cross-axis features available)
- **Status**: Already trained (corrected phylo, completed 2025-10-29)

**Model 2: No-EIVE Models (exclude cross-axis EIVE)**
- **Training data**: Same ~6,200 species per axis (Tier 2)
- **Features**: All predictors EXCEPT cross-axis EIVE columns
  - Keep: p_phylo (phylogenetic signal), traits, soil, climate, phylo eigenvectors
  - Exclude: EIVEres-L, EIVEres-T, EIVEres-M, EIVEres-N, EIVEres-R
- **Use for**: 5,419 species with no EIVE (no cross-axis features available)
- **Status**: TO BE TRAINED

**Expected performance drop**: R² reduction of ~0.05-0.10 for no-EIVE models (loss of cross-axis coupling), but predictions are scientifically valid for species lacking all EIVE.

### Rationale for Training on Tier 2 (not Tier 1)

**Five key advantages:**
1. **Geographic generalization**: Tier 1 is European-biased; 5,419 no-EIVE species are globally distributed
2. **Sample size**: 6,200 >> 1,084 (5.7× more data for robust XGBoost learning)
3. **Phylogenetic diversity**: 5,400 tips vs 1,075 tips (critical for phylo predictors on novel clades)
4. **Already validated**: Tier 2 production CV achieved R² 0.506-0.823 (excellent generalization)
5. **Trait quality acceptable**: 100% completeness post-mixgb (imputation uncertainty minor vs generalization gains)

---

## Execution Plan

### Step 1: Build No-EIVE Feature Tables

**Status**: Full models already trained ✓ (with corrected phylo, 2025-10-29)

**Task**: Build no-EIVE feature tables (exclude all cross-axis EIVE predictors).

**Script**: `src/Stage_2/build_tier2_no_eive_features.py`

```python
#!/usr/bin/env python3
"""Build no-EIVE feature tables for Tier 2 (exclude all cross-axis EIVE predictors)."""

import pandas as pd
from pathlib import Path

# Load corrected feature tables (already built with context-matched phylo)
axes = ['L', 'T', 'M', 'N', 'R']
eive_cols = [f'EIVEres-{ax}' for ax in axes]

for axis in axes:
    # Load full feature table (with cross-axis EIVE)
    full_features_path = Path(f'model_data/inputs/stage2_features/{axis}_features_11680_corrected_20251029.csv')
    features = pd.read_csv(full_features_path)

    print(f"\n[{axis}] Loaded full features: {features.shape}")

    # Identify cross-axis EIVE columns to exclude
    cross_axis_eive = [c for c in features.columns if c in eive_cols]

    if cross_axis_eive:
        features = features.drop(columns=cross_axis_eive)
        print(f"[{axis}] Excluded {len(cross_axis_eive)} cross-axis EIVE columns: {cross_axis_eive}")
    else:
        print(f"[{axis}] No cross-axis EIVE columns found (already excluded)")

    # Save no-EIVE feature table
    output_path = Path(f'model_data/inputs/stage2_features/{axis}_features_11680_no_eive_20251029.csv')
    output_path.parent.mkdir(parents=True, exist_ok=True)
    features.to_csv(output_path, index=False)

    print(f"[{axis}] Saved no-EIVE features: {output_path}")
    print(f"[{axis}] Shape: {features.shape}")
```

**Expected outputs**:
```
model_data/inputs/stage2_features/L_features_11680_no_eive_20251029.csv  (~6,165 × ~732 cols)
model_data/inputs/stage2_features/T_features_11680_no_eive_20251029.csv  (~6,220 × ~732 cols)
model_data/inputs/stage2_features/M_features_11680_no_eive_20251029.csv  (~6,245 × ~732 cols)
model_data/inputs/stage2_features/N_features_11680_no_eive_20251029.csv  (~6,000 × ~732 cols)
model_data/inputs/stage2_features/R_features_11680_no_eive_20251029.csv  (~6,063 × ~732 cols)
```

**Note**: ~4 fewer columns per axis (removed 4 cross-axis EIVE predictors)

**Runtime**: ~2 minutes

---

### Step 2: Train No-EIVE Models

Execute 10-fold CV for no-EIVE models using same optimal hyperparameters from Tier 1.

**Script**: `src/Stage_2/xgb_kfold.py` (existing script, same as full models)

**Command template**:
```bash
/home/olier/miniconda3/envs/AI/bin/python src/Stage_2/xgb_kfold.py \
  --features_csv model_data/inputs/stage2_features/{AXIS}_features_11680_no_eive_20251029.csv \
  --axis {AXIS} \
  --out_dir model_data/outputs/stage2_xgb/{AXIS}_11680_no_eive_20251029 \
  --cv_folds 10 \
  --learning_rates {BEST_LR} \
  --n_estimators_grid {BEST_N} \
  --gpu true
```

**Execution script**: `src/Stage_2/run_tier2_no_eive_all_axes.sh`

```bash
#!/bin/bash
# Train no-EIVE models for all 5 axes (exclude cross-axis EIVE predictors)

set -e

export PYTHONUNBUFFERED=1
PYTHON="/home/olier/miniconda3/envs/AI/bin/python -u"
SCRIPT="src/Stage_2/xgb_kfold.py"

echo "========================================================================"
echo "TIER 2 NO-EIVE MODELS: All 5 Axes"
echo "========================================================================"
echo "Purpose: Train models without cross-axis EIVE for 5,419 no-EIVE species"
echo "Training data: ~6,200 species per axis (Tier 2 with observed EIVE)"
echo "Features: p_phylo, traits, soil, climate, phylo_ev (NO cross-axis EIVE)"
echo "Start time: $(date)"
echo ""

# Tier 1 optimal hyperparameters (reuse)
declare -A LR=(["L"]=0.03 ["T"]=0.03 ["M"]=0.03 ["N"]=0.03 ["R"]=0.05)
declare -A N_EST=(["L"]=1500 ["T"]=1500 ["M"]=5000 ["N"]=1500 ["R"]=1500)

for AXIS in L T M N R; do
    echo "========================================================================"
    echo "Training ${AXIS}-axis no-EIVE model"
    echo "Features: model_data/inputs/stage2_features/${AXIS}_features_11680_no_eive_20251029.csv"
    echo "Output: model_data/outputs/stage2_xgb/${AXIS}_11680_no_eive_20251029/"
    echo "Hyperparameters: lr=${LR[$AXIS]}, n_estimators=${N_EST[$AXIS]}"
    echo "Start: $(date)"
    echo "========================================================================"

    $PYTHON $SCRIPT \
        --features_csv model_data/inputs/stage2_features/${AXIS}_features_11680_no_eive_20251029.csv \
        --axis $AXIS \
        --out_dir model_data/outputs/stage2_xgb/${AXIS}_11680_no_eive_20251029 \
        --species_column wfo_taxon_id \
        --cv_folds 10 \
        --learning_rates ${LR[$AXIS]} \
        --n_estimators_grid ${N_EST[$AXIS]} \
        --gpu true \
        --seed 42 \
        --max_depth 6 \
        --subsample 0.8 \
        --colsample_bytree 0.8

    echo ""
    echo "✓ ${AXIS}-axis no-EIVE model completed"
    echo "  End: $(date)"
    echo ""
done

echo "========================================================================"
echo "ALL NO-EIVE MODELS COMPLETED"
echo "========================================================================"
echo "End time: $(date)"
```

**Runtime**: ~6 minutes total (same as full models)

**Outputs per axis**:
```
model_data/outputs/stage2_xgb/{AXIS}_11680_no_eive_20251029/
├── xgb_{AXIS}_model.json                  # No-EIVE model
├── xgb_{AXIS}_scaler.json                 # Z-score parameters
├── xgb_{AXIS}_cv_metrics_kfold.json       # R²/RMSE/MAE summary
├── xgb_{AXIS}_cv_predictions_kfold.csv    # Row-level predictions
└── xgb_{AXIS}_shap_importance.csv         # Feature importance rankings
```

---

### Step 3: Impute Missing EIVE

Predict EIVE values for 5,515 species lacking observations, using production models trained in Step 2.

**Script**: `src/Stage_2/impute_missing_eive.py`

```python
#!/usr/bin/env python3
"""Impute missing EIVE values for 5,515 species using production XGBoost models."""

import json
import pandas as pd
import xgboost as xgb
from pathlib import Path

# Load production master
production = pd.read_parquet('model_data/outputs/perm2_production/perm2_11680_complete_final_20251028.parquet')

# Initialize results
imputed_eive = production[['wfo_taxon_id', 'wfo_scientific_name']].copy()

for axis in ['L', 'T', 'M', 'N', 'R']:
    eive_col = f'EIVEres-{axis}'
    print(f"\n[{axis}] Imputing missing EIVE values...")

    # Load production model and scaler
    model_dir = Path(f'model_data/outputs/stage2_xgb/{axis}_11680_production_20251029')
    model_path = model_dir / f'xgb_{axis}_model.json'
    scaler_path = model_dir / f'xgb_{axis}_scaler.json'

    if not model_path.exists():
        raise FileNotFoundError(f"Model not found: {model_path}")

    model = xgb.Booster()
    model.load_model(str(model_path))

    with open(scaler_path) as f:
        scaler = json.load(f)

    # Identify species missing EIVE for this axis
    missing_mask = production[eive_col].isna()
    n_missing = missing_mask.sum()
    print(f"[{axis}] {n_missing} species need imputation")

    if n_missing == 0:
        imputed_eive[eive_col] = production[eive_col]
        continue

    # Prepare features for imputation
    missing_data = production[missing_mask].copy()

    # Drop all EIVE columns (prevent leakage)
    eive_cols = [c for c in missing_data.columns if c.startswith('EIVEres-')]
    missing_data = missing_data.drop(columns=eive_cols)

    # Drop provenance columns
    provenance_cols = [c for c in missing_data.columns if '_source' in c]
    missing_data = missing_data.drop(columns=provenance_cols)

    # Drop identifiers for prediction
    feature_cols = [c for c in missing_data.columns
                   if c not in ['wfo_taxon_id', 'wfo_scientific_name']]
    X_missing = missing_data[feature_cols]

    # Handle categorical features
    cat_cols = X_missing.select_dtypes(include=['object', 'category']).columns
    for col in cat_cols:
        X_missing[col] = pd.Categorical(X_missing[col]).codes

    # Z-score normalization
    X_missing_scaled = (X_missing - scaler['mean']) / scaler['std']
    X_missing_scaled = X_missing_scaled.fillna(0)

    # Predict
    dmatrix = xgb.DMatrix(X_missing_scaled)
    predictions = model.predict(dmatrix)

    # Store predictions
    imputed_eive.loc[missing_mask, eive_col] = predictions

    # Copy observed values for species with EIVE
    imputed_eive.loc[~missing_mask, eive_col] = production.loc[~missing_mask, eive_col]

    print(f"[{axis}] Imputed {n_missing} values (mean={predictions.mean():.2f}, std={predictions.std():.2f})")

# Save imputed dataset
output_path = Path('model_data/outputs/eive_imputed/eive_11680_imputed_20251029.csv')
output_path.parent.mkdir(parents=True, exist_ok=True)
imputed_eive.to_csv(output_path, index=False)

print(f"\n[output] Saved imputed EIVE dataset: {output_path}")
print(f"[output] Shape: {imputed_eive.shape}")

# Summary statistics
print("\n[summary] Imputed EIVE summary:")
for axis in ['L', 'T', 'M', 'N', 'R']:
    eive_col = f'EIVEres-{axis}'
    observed = production[eive_col].notna().sum()
    imputed = production[eive_col].isna().sum()
    print(f"{axis}: {observed} observed, {imputed} imputed")
```

**Runtime**: ~5-10 minutes

**Output**:
```
model_data/outputs/eive_imputed/eive_11680_imputed_20251029.csv
  - 11,680 species × 7 columns (ids + 5 EIVE axes)
  - All missing values filled with XGBoost predictions
```

---

### Step 4: Validate Production Results

Compare Tier 2 performance against Tier 1 to ensure consistency.

**Script**: `src/Stage_2/compare_tier1_tier2_performance.py`

```python
#!/usr/bin/env python3
"""Compare Tier 1 vs Tier 2 XGBoost performance."""

import json
import pandas as pd

results = []

for axis in ['L', 'T', 'M', 'N', 'R']:
    # Load Tier 1 metrics
    t1_path = f'model_data/outputs/stage2_xgb/{axis}_1084_tier1_20251029/xgb_{axis}_cv_metrics_kfold.json'
    with open(t1_path) as f:
        t1 = json.load(f)

    # Load Tier 2 metrics
    t2_path = f'model_data/outputs/stage2_xgb/{axis}_11680_production_20251029/xgb_{axis}_cv_metrics_kfold.json'
    with open(t2_path) as f:
        t2 = json.load(f)

    results.append({
        'axis': axis,
        'tier1_r2': t1['r2_mean'],
        'tier1_r2_sd': t1['r2_sd'],
        'tier1_mae': t1['mae_mean'],
        'tier2_r2': t2['r2_mean'],
        'tier2_r2_sd': t2['r2_sd'],
        'tier2_mae': t2['mae_mean'],
        'r2_change': t2['r2_mean'] - t1['r2_mean'],
        'r2_change_pct': 100 * (t2['r2_mean'] - t1['r2_mean']) / t1['r2_mean']
    })

df = pd.DataFrame(results)
print("\n=== Tier 1 vs Tier 2 Performance Comparison ===\n")
print(df.to_string(index=False))

# Save comparison
df.to_csv('results/verification/tier1_vs_tier2_comparison_20251029.csv', index=False)
print("\n[output] Saved comparison: results/verification/tier1_vs_tier2_comparison_20251029.csv")
```

**Expected behavior**:
- Tier 2 R² within ±2% of Tier 1 (slight degradation acceptable due to sparser GBIF coverage)
- MAE similar or slightly higher for Tier 2
- SHAP rankings consistent (top 5 features should be similar)

---

## Expected Timeline

| Step | Task | Runtime | Can Parallelize? |
|------|------|---------|------------------|
| 1 | Build Tier 2 feature tables | ~2 min | No |
| 2 | Production CV (all 5 axes) | 5-7.5 hrs | Yes (per axis) |
| 3 | Impute missing EIVE | ~10 min | No |
| 4 | Validate results | ~2 min | No |
| **Total** | **Sequential** | **~6-8 hours** | **1-2 hours if parallel** |

**Recommendation**: Run Step 2 axes in parallel on separate terminals/GPUs if available.

---

## Success Criteria

### Production CV (Step 2)

- [ ] All 5 axes complete without errors
- [ ] R² values within expected range:
  - T: 0.78-0.82
  - M: 0.62-0.68
  - L: 0.58-0.65
  - N: 0.65-0.72
  - R: 0.48-0.58
- [ ] Tier 2 R² within ±2% of Tier 1
- [ ] SHAP importance: p_phylo in top 3 for L/M/N axes
- [ ] No training failures or convergence issues

### EIVE Imputation (Step 3)

- [ ] All 5,515 missing EIVE values filled
- [ ] Imputed values in reasonable range (no outliers > 3 SD from observed)
- [ ] Imputed distributions similar to observed (visual check)
- [ ] No species with all 5 axes imputed == 0 (failure mode)

### Documentation (Step 5)

- [ ] Update Stage 2.1-2.5 axis summaries with Tier 2 results
- [ ] Create imputation summary document
- [ ] Archive Tier 1 corrected phylo analysis (diagnostic only)

---

## Key Differences from Tier 1

| Aspect | Tier 1 (1,084 species) | Tier 2 (11,680 species) |
|--------|------------------------|-------------------------|
| **Purpose** | Hyperparameter tuning | Production CV + imputation |
| **Phylo predictors** | Corrected (pruned tree context) | Original (full tree context) |
| **EIVE coverage** | 83% (~900 per axis) | 52.8% (~6,165 per axis) |
| **Grid search** | 3×3 = 9 combinations | Single optimal config |
| **Runtime per axis** | 4-6 minutes | 60-90 minutes |
| **Outputs** | Grid + best model | Production model + imputed EIVE |

---

## Monitoring Commands

### Check production CV progress
```bash
# Monitor logs
tail -f logs/tier2_production_20251029.log

# Check output directories
for axis in L T M N R; do
  ls -lh model_data/outputs/stage2_xgb/${axis}_11680_production_20251029/ 2>/dev/null | tail -5
done
```

### Extract Tier 2 metrics after completion
```bash
for axis in L T M N R; do
  echo "=== $axis-axis ==="
  cat model_data/outputs/stage2_xgb/${axis}_11680_production_20251029/xgb_${axis}_cv_metrics_kfold.json
done
```

---

## References

**Tier 1 results**:
- `2.1_L_Axis_XGBoost.md` (Tier 1 with corrected phylo)
- `2.2_T_Axis_XGBoost.md`
- `2.3_M_Axis_XGBoost.md`
- `2.4_N_Axis_XGBoost.md`
- `2.5_R_Axis_XGBoost.md`

**Phylo predictor context issue**:
- `DIAGNOSTIC_phylo_predictor_issue_20251029.md`
- `RESOLUTION_phylo_context_issue_20251029.md`

**Production dataset**:
- `1.10_Modelling_Master_Table.md` Section 2.1 (11,680 species)

**Modeling overview**:
- `2.0_Modelling_Overview.md` (this document provides framework)

---

**Document status**: Ready for execution
**Next step**: Run `python src/Stage_2/build_tier2_features.py` to create feature tables

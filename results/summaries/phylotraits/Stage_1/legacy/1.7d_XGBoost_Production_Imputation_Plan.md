# Stage 1.7d — XGBoost Production Imputation Plan

**Production imputation for 11,680 species using Perm 2 configuration**

**Date:** 2025-10-27
**Status:** Planning
**Configuration:** Perm 2 (phylogenetic eigenvectors + EIVE indicators)

---

## Executive Summary

Following the comprehensive experiments in `1.7b_XGBoost_Experiments.md`, this document outlines the plan for production-scale trait imputation on the full 11,680-species dataset using the Perm 2 configuration (phylogenetic eigenvectors + EIVE indicators).

**Key decisions from 1.7b experiments:**
- **Selected configuration:** Perm 2 (phylogeny + EIVE)
- **Rationale:** Best accuracy (1-4% better RMSE than Perm 1), no circular dependency
- **Trade-off:** 2.5× slower runtime, but acceptable for production
- **Validation approach:** 10-fold CV with hyperparameter tuning

---

## 1. Configuration Summary

### 1.1 Dataset: Perm 2 with EIVE Indicators

**Location:** `model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv`

**Dimensions:** 11,680 species × 1,490 features

**Feature composition:**
- **Identifiers (2):** `wfo_taxon_id`, `wfo_scientific_name`
- **Target traits (6):** `logLA`, `logNmass`, `logLDMC`, `logSLA`, `logH`, `logSM`
- **Phylogenetic (92):** Eigenvectors from VCV matrix (89.8% variance explained)
- **EIVE indicators (5):** `EIVEres-L`, `EIVEres-T`, `EIVEres-M`, `EIVEres-N`, `EIVEres-R` (52.8% coverage)
- **Categorical (7):** TRY traits (woodiness, growth form, habitat, leaf type, phenology, photosynthesis, mycorrhiza)
- **Climate (44):** WorldClim 2.1 30s q50 aggregates
- **Soil (42):** SoilGrids 250m q50 aggregates (6 layers × 7 variables)
- **Other (51):** AgroClim indices q50 aggregates

**Anti-leakage design:**
- Raw trait values REMOVED from features (leaf_area_mm2, nmass_mg_g, etc.)
- Only log-transformed traits used (logLA, logNmass, etc.)
- Prevents direct data leakage in imputation

**Why Perm 2 (corrected from initial analysis):**
- No circular dependency: EXISTING EIVE (52.8% coverage) → Traits → MISSING EIVE (47.2% gaps)
- Different EIVE indicators used (inputs) vs. predicted (outputs) in Stage 2
- Best Stage 1 accuracy → likely best Stage 2 EIVE predictions
- EIVE-N and EIVE-L are top predictive features (29% GAIN for logLA)

---

## 2. Current Scripts Analysis

### 2.1 Script Capabilities

All required functionality implemented in unified script:

| Script | Purpose | Key Parameters | Status |
|--------|---------|----------------|--------|
| `build_xgboost_perm123_datasets.py` | Build Perm 1/2/3 datasets | `--permutation`, `--perm8_base`, `--eive_data` | ✓ Complete |
| `xgboost_cv_eval.R` | **CV evaluation + production imputation (unified)** | `--folds`, `--nrounds`, `--eta`, `--run_production`, `--m` | ✓ Ready |
| `compute_cv_accuracy_metrics.py` | Post-CV accuracy analysis | `--cv_results`, `--output` | ✓ Ready |
| `xgboost_gain_importance.R` | Extract GAIN feature importance | `--input_csv`, `--output_dir` | ✓ Ready |
| `analyze_feature_importance.py` | Categorize GAIN by feature type | `--importance_dir`, `--output` | ✓ Ready |

**Key update:** `xgboost_cv_eval.R` now handles both CV evaluation and production imputation in a single run when `--run_production=true` is set. This ensures identical hyperparameters are used for testing and production.

**Confirmed capabilities:**
- ✓ 10-fold CV (configurable via `--folds=10`)
- ✓ Hyperparameter tuning (trees via `--nrounds`, learning rate via `--eta`)
- ✓ 11,680 species scale (datasets already built and tested)
- ✓ GPU acceleration (via `--device=cuda`)
- ✓ Multiple imputations (via `--m=10` when production enabled)
- ✓ Unified CV + production workflow (same script, same hyperparameters)
- ✓ Canonical accuracy metrics (MdAPE, tolerance bands, percentiles)
- ✓ GAIN-based feature importance (per-trait and aggregated)

---

### 2.2 Dataset Status

**Perm 2 dataset for 11,680 species: ✓ AVAILABLE**

```bash
model_data/inputs/mixgb_perm2_11680/
├── mixgb_input_perm2_eive_11680_20251027.csv        (44 MB)
└── mixgb_input_perm2_eive_11680_20251027.parquet   (12 MB)
```

**Verified:**
- 11,680 rows (species)
- 1,490 columns (features)
- EIVE coverage: 52.8% (6,169 species with at least one EIVE value)
- Anti-leakage: Raw trait columns removed

---

## 3. Hyperparameter Tuning Strategy

### 3.1 Hyperparameter Grid

Based on 1.7b experiments (1,084 species), optimal range identified:

**Learning rate (eta):**
- Test values: `[0.01, 0.025, 0.05, 0.1]`
- Best from 1.7b: 0.025
- Rationale: Balance convergence speed and accuracy

**Number of trees (nrounds):**
- Test values: `[1000, 2000, 3000, 5000]`
- Best from 1.7b: 3000 (with eta=0.025)
- Rationale: More trees with lower eta prevents overfitting

**Fixed parameters:**
- `m` = 10 (multiple imputations for uncertainty quantification)
- `pmm_type` = 2 (predictive mean matching)
- `pmm_k` = 4 (nearest neighbors)
- `device` = cuda (GPU acceleration)
- `folds` = 10 (sklearn-compatible CV)
- `seed` = 20251027 (reproducibility)

**Grid size:** 4 × 4 = 16 combinations

---

### 3.2 Cross-Validation Plan

**Methodology:**
- **10-fold stratified CV** using `sklearn.model_selection.KFold`
- **Cell-level holdout:** Test individual trait-species pairs (not whole species)
- **Random seed:** 20251027 (fixed for reproducibility)
- **Evaluation metric:** RMSE on log-scale (comparable to BHPMF)

**Command template (CV only):**

```bash
nohup env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  PATH="/home/olier/miniconda3/envs/AI/bin:/usr/bin:/bin" \
  /home/olier/miniconda3/envs/AI/bin/Rscript src/Stage_1/experiments/xgboost_cv_eval.R \
  --input_csv=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv \
  --output_csv=results/experiments/perm2_11680/cv_10fold_eta{ETA}_n{NROUNDS}_20251027.csv \
  --nrounds={NROUNDS} --eta={ETA} --device=cuda \
  --folds=10 --traits=all \
  > logs/mixgb/cv_perm2_eta{ETA}_n{NROUNDS}_20251027.log 2>&1 &
```

**Command template (CV + Production Imputation):**

```bash
nohup env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  PATH="/home/olier/miniconda3/envs/AI/bin:/usr/bin:/bin" \
  /home/olier/miniconda3/envs/AI/bin/Rscript src/Stage_1/experiments/xgboost_cv_eval.R \
  --input_csv=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv \
  --output_csv=results/experiments/perm2_11680/cv_10fold_eta{ETA}_n{NROUNDS}_20251027.csv \
  --nrounds={NROUNDS} --eta={ETA} --device=cuda \
  --folds=10 --traits=all \
  --run_production=true --m=10 --seed=20251027 \
  --output_dir=model_data/outputs/perm2_production \
  --output_prefix=perm2_11680_eta{ETA}_n{NROUNDS}_20251027 \
  > logs/mixgb/cv_perm2_eta{ETA}_n{NROUNDS}_20251027.log 2>&1 &
```

**Example for eta=0.025, nrounds=3000 (CV + Production):**

```bash
nohup env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  PATH="/home/olier/miniconda3/envs/AI/bin:/usr/bin:/bin" \
  /home/olier/miniconda3/envs/AI/bin/Rscript src/Stage_1/experiments/xgboost_cv_eval.R \
  --input_csv=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv \
  --output_csv=results/experiments/perm2_11680/cv_10fold_eta0025_n3000_20251027.csv \
  --nrounds=3000 --eta=0.025 --device=cuda \
  --folds=10 --traits=all \
  --run_production=true --m=10 --seed=20251027 \
  --output_dir=model_data/outputs/perm2_production \
  --output_prefix=perm2_11680_eta0025_n3000_20251027 \
  > logs/mixgb/cv_perm2_eta0025_n3000_20251027.log 2>&1 &
```

---

### 3.3 Runtime Estimates

**Per hyperparameter combination (CV only):**
- Based on 1,084-species Perm 2 runtime: 23.4 min (3-fold CV)
- Scale-up factor: 11,680 / 1,084 ≈ 10.8×
- Fold increase: 10 / 3 ≈ 3.3×
- **Estimated CV-only runtime:** 23.4 × 10.8 × 3.3 ≈ **14 hours**

**Per hyperparameter combination (CV + Production):**
- CV runtime: ~14 hours (as above)
- Production imputation (10 runs): ~14-20 hours additional
- **Estimated combined runtime:** **~28-34 hours** (roughly 2× CV-only time)

**Rationale for combined runtime:**
- CV: 10 folds × 6 traits = 60 imputation runs on partial data
- Production: 10 imputations on full dataset (all traits at once)
- Production is slightly more efficient per-run but still adds substantial time

**Full grid (16 combinations):**
- CV-only sequential: 14 hours × 16 = **224 hours (~9 days)**
- CV + Production sequential: 30 hours × 16 = **480 hours (~20 days)**
- Parallel (4 GPUs): Divide by 4

**Recommended approach:**
1. **Validate on known-good hyperparameters first** (eta=0.025, nrounds=3000)
2. Run CV-only for hyperparameter tuning (faster)
3. Once optimal config identified → run CV + Production in single job
4. If performance matches 1.7b results → use production outputs
5. If degradation observed → run targeted grid search around optimal range

---

## 4. Production Imputation Plan

### 4.1 Optimal Configuration (from 1.7b)

Based on experiments with 1,084 species:

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| `eta` | 0.025 | Best convergence without overfitting |
| `nrounds` | 3000 | Balanced with eta=0.025 for optimal RMSE |
| `m` | 10 | Multiple imputations for uncertainty quantification |
| `pmm_type` | 2 | Predictive mean matching type 2 |
| `pmm_k` | 4 | 4 nearest neighbors for PMM |
| `device` | cuda | GPU acceleration |

**Expected performance (based on 1.7b Perm 2 results):**

| Trait | Expected RMSE | Expected MdAPE | R² |
|-------|---------------|----------------|-----|
| logLA | 1.321 | ~23% | 0.714 |
| logNmass | 0.362 | ~20% | 0.807 |
| logLDMC | 0.531 | ~21% | 0.665 |
| logSLA | 0.361 | ~20% | 0.791 |
| logH | 0.832 | ~28% | 0.704 |
| logSM | 1.538 | ~28% | 0.558 |

---

### 4.2 Production Command

**Unified CV + Production imputation (recommended):**

This runs both CV validation and production imputation in a single job, ensuring identical hyperparameters:

```bash
nohup env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  PATH="/home/olier/miniconda3/envs/AI/bin:/usr/bin:/bin" \
  /home/olier/miniconda3/envs/AI/bin/Rscript src/Stage_1/experiments/xgboost_cv_eval.R \
  --input_csv=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv \
  --output_csv=results/experiments/perm2_11680/cv_10fold_eta0025_n3000_20251027.csv \
  --nrounds=3000 --eta=0.025 --device=cuda \
  --folds=10 --traits=all \
  --run_production=true --m=10 --seed=20251027 \
  --output_dir=model_data/outputs/perm2_production \
  --output_prefix=perm2_11680_eta0025_n3000_20251027 \
  > logs/mixgb/perm2_cv_production_20251027.log 2>&1 &
```

**Runtime estimate:**
- CV (10-fold): ~14 hours
- Production (10 imputations): ~14-20 hours
- **Total estimated runtime:** ~28-34 hours

**Workflow:**
1. Runs 10-fold CV first, reports RMSE + R² metrics
2. Then runs 10 production imputations with same hyperparameters
3. Saves individual imputations (_m1.csv through _m10.csv) and mean (_mean.csv)
4. All outputs use identical hyperparameters validated by CV

---

### 4.3 Expected Outputs

**Directory structure:**

```
model_data/outputs/perm2_production/
├── perm2_11680_eta0025_n3000_20251027_m1.csv           (~25 MB)
├── perm2_11680_eta0025_n3000_20251027_m2.csv
├── ...
├── perm2_11680_eta0025_n3000_20251027_m10.csv
└── perm2_11680_eta0025_n3000_20251027_mean.csv         (ensemble mean)

results/experiments/perm2_11680/
├── cv_10fold_eta0025_n3000_20251027.csv                (CV metrics)
└── cv_10fold_eta0025_n3000_20251027_predictions.csv    (CV predictions)

Total storage: ~250 MB imputed datasets
```

**Output contents:**
- **Individual imputations (m1-m10):** Complete datasets with all traits imputed
- **Mean imputation:** Ensemble average across 10 runs (recommended for Stage 2)
- **CV metrics:** RMSE, R², per-trait performance
- **CV predictions:** Fold-level predictions for validation


---

## 5. Validation Pipeline

### 5.1 Post-Imputation Checks

**Immediate validation (automated):**

1. **Dimension check:**
   - Expected: 11,680 rows × 1,490 columns
   - All 10 imputations + mean must match

2. **Missingness check:**
   - Target traits (logLA, logNmass, logLDMC, logSLA, logH, logSM) must have 0% missing
   - Features can retain original missingness

3. **Range check:**
   - Log traits should be within biologically plausible bounds
   - Example: logLA ∈ [-2, 8], logH ∈ [-2, 4]

4. **Correlation check:**
   - Cross-trait correlations should match observed patterns
   - Example: logLA vs. logSLA negative correlation (leaf economics spectrum)

**Script for validation:**

```python
# scripts/validate_perm2_imputation.py
import pandas as pd
import numpy as np

def validate_imputation(imputed_path, original_path):
    """
    Validate imputed dataset against original.

    Checks:
    1. Dimensions match
    2. Target traits have no missing values
    3. Values are within plausible ranges
    4. Correlations are biologically sensible
    """
    imputed = pd.read_parquet(imputed_path)
    original = pd.read_csv(original_path)

    # Dimension check
    assert imputed.shape[0] == original.shape[0], "Row count mismatch"

    # Missingness check
    target_traits = ['logLA', 'logNmass', 'logLDMC', 'logSLA', 'logH', 'logSM']
    for trait in target_traits:
        missing = imputed[trait].isna().sum()
        assert missing == 0, f"{trait} has {missing} missing values"

    # Range check (using 99.9th percentile from observed data)
    ranges = {
        'logLA': (-2, 8),
        'logNmass': (-2, 2),
        'logLDMC': (-2, 1),
        'logSLA': (-2, 4),
        'logH': (-2, 4),
        'logSM': (-4, 6)
    }

    for trait, (min_val, max_val) in ranges.items():
        out_of_range = (imputed[trait] < min_val) | (imputed[trait] > max_val)
        pct_out = out_of_range.sum() / len(imputed) * 100
        if pct_out > 0.1:  # More than 0.1% out of range
            print(f"WARNING: {trait} has {pct_out:.2f}% values out of range [{min_val}, {max_val}]")

    print("✓ Validation passed")
    return True
```

**Usage:**

```bash
conda run -n AI python scripts/validate_perm2_imputation.py \
  --imputed=model_data/outputs/perm2_production/perm2_11680_eta0025_n3000_20251027_mean.parquet \
  --original=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv
```

---

### 5.2 Performance Verification

**Compare to 1.7b experiments:**

1. **Subset to 1,084 species from experiments**
2. **Compute RMSE on same held-out cells**
3. **Verify performance matches 1.7b results (±5% tolerance)**

**Script:**

```bash
conda run -n AI python scripts/compare_perm2_11680_vs_1084.py \
  --imputed_11680=model_data/outputs/perm2_production/perm2_11680_eta0025_n3000_20251027_mean.parquet \
  --cv_1084=results/experiments/perm2_1084/cv_3fold_eta0025_n3000_20251027.csv \
  --output=results/experiments/perm2_11680/performance_verification.csv
```

**Expected output:**

```
Trait      | 1,084 RMSE | 11,680 RMSE (subset) | Difference | Status
-----------|------------|----------------------|------------|--------
logLA      | 1.321      | 1.305 ± 0.03         | -1.2%      | ✓ Pass
logNmass   | 0.362      | 0.358 ± 0.01         | -1.1%      | ✓ Pass
logLDMC    | 0.531      | 0.525 ± 0.02         | -1.1%      | ✓ Pass
logSLA     | 0.361      | 0.356 ± 0.01         | -1.4%      | ✓ Pass
logH       | 0.832      | 0.825 ± 0.03         | -0.8%      | ✓ Pass
logSM      | 1.538      | 1.522 ± 0.05         | -1.0%      | ✓ Pass
```

**Acceptance criteria:**
- RMSE difference < ±5%
- All traits within tolerance → Performance verified

---

## 6. Downstream Integration

### 6.1 Stage 2 Input Preparation

**Imputed traits will be used in Stage 2 to predict EIVE values.**

**Workflow:**

1. **Extract mean imputation:**
   - Use `perm2_11680_eta0025_n3000_20251027_mean.parquet`
   - Contains ensemble average across 10 imputations

2. **Back-transform to original scale:**
   - logLA → leaf_area_mm2 (exp transform)
   - logNmass → nmass_mg_g (exp transform)
   - logLDMC → ldmc_frac (inverse logit: 1 / (1 + exp(-x)))
   - logSLA → sla_mm2_mg (exp transform)
   - logH → plant_height_m (exp transform)
   - logSM → seed_mass_mg (exp transform)

3. **Merge with environmental features:**
   - Join with `env_features_shortlist_20251022_means.csv`
   - Join with phylogenetic eigenvectors

4. **Create Stage 2 input dataset:**
   - Traits + Environment + Phylogeny → Predict EIVE

**Script:**

```bash
conda run -n AI python src/Stage_2/prepare_stage2_inputs_from_perm2.py \
  --imputed_traits=model_data/outputs/perm2_production/perm2_11680_eta0025_n3000_20251027_mean.parquet \
  --env_features=model_data/inputs/env_features_shortlist_20251022_means.csv \
  --phylo_eigenvectors=model_data/inputs/phylo_eigenvectors_92d_20251026.parquet \
  --output=model_data/inputs/stage2_inputs_20251027.parquet
```

---

### 6.2 EIVE Prediction (Stage 2)

**Use imputed traits to predict missing EIVE indicators.**

**Pipeline:**
- Input: Complete traits (from Perm 2 imputation) + Environment + Phylogeny
- Output: Complete EIVE dataset (L, T, M, N, R for all 11,680 species)
- Method: XGBoost regression (same as Stage 1)

**No circular dependency:**
- Stage 1: EXISTING EIVE (52.8% coverage) → Traits
- Stage 2: Traits → MISSING EIVE (47.2% gaps)
- Different indicators used (input) vs. predicted (output)

**Expected Stage 2 performance:**
- Better traits from Perm 2 → likely better EIVE predictions than Perm 1 would have achieved
- Can validate against held-out EIVE observations

---

## 7. Feature Importance Analysis

### 7.1 GAIN Extraction

After production imputation, extract GAIN-based feature importance by training models for importance extraction:

```bash
env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  PATH="/home/olier/miniconda3/envs/AI/bin:/usr/bin:/bin" \
  /home/olier/miniconda3/envs/AI/bin/Rscript src/Stage_1/experiments/xgboost_gain_importance.R \
  --input_csv=model_data/inputs/mixgb_perm2_11680/mixgb_input_perm2_eive_11680_20251027.csv \
  --output_dir=results/experiments/perm2_11680/feature_importance \
  --nrounds=3000 --eta=0.025 --device=cuda \
  > logs/experiments/perm2_gain_20251027.log 2>&1
```

**Note:** This trains models specifically for GAIN extraction (not saved from production imputation)

**Runtime:** ~30-60 minutes (trains 1 model per trait for GAIN calculation)

### 7.2 Feature Categorization

Categorize GAIN by feature type (phylogeny, EIVE, categorical, climate, soil):

```bash
conda run -n AI python src/Stage_1/experiments/analyze_feature_importance.py \
  --importance_dir=results/experiments/perm2_11680/feature_importance \
  --output_dir=results/experiments/perm2_11680/feature_importance \
  --permutation=2
```

**Outputs:**
- Category contributions by trait (phylogeny %, EIVE %, climate %, soil %, categorical %)
- Top 20 features by total GAIN
- Per-trait feature importance rankings

---

## 8. Timeline and Milestones

### Phase 1: Hyperparameter Tuning (1,084 species)

**Objective:** Determine optimal trees/eta combination on small dataset

**Tasks:**
1. Test 2000 trees at eta=0.05 (Perm 2, 1,084 species)
2. Test 3000 trees at eta=0.025 (Perm 2, 1,084 species)
3. Compare to baseline: 1000 trees at eta=0.1 (already done)
4. Select best configuration for production

**Duration:** ~2 hours (2 × 1 hour per CV run)
**Decision point:** Select optimal hyperparameters for 11,680 scale-up

---

### Phase 2: Production Imputation

**Objective:** Generate complete trait dataset for 11,680 species

**Tasks:**
1. Run unified CV + production imputation (10 imputations)
2. Validate outputs (dimensions, ranges, correlations)
3. Verify performance on 1,084-species subset

**Duration:** ~28-34 hours (CV + production combined)
**Deliverable:** CV metrics + 10 imputed datasets + ensemble mean

---

### Phase 3: Feature Importance Analysis

**Objective:** Understand key predictors of trait variation

**Tasks:**
1. Extract GAIN from production models
2. Categorize features by type
3. Identify top contributors per trait
4. Compare to 1,084-species feature importance

**Duration:** ~1 hour
**Deliverable:** Feature importance analysis and visualizations

---

### Phase 4: Quality Assurance

**Objective:** Verify imputation quality and prepare for Stage 2

**Tasks:**
1. Post-imputation validation (automated checks)
2. Performance verification (compare to 1.7b)
3. Back-transform to original scale
4. Create Stage 2 input dataset

**Duration:** ~2 hours
**Deliverable:** Stage 2-ready dataset with complete traits

---

### Phase 5: Documentation

**Objective:** Document methods and results

**Tasks:**
1. Update 1.7d with actual results
2. Create feature importance analysis (using SHAP if available)
3. Update 1.0_Data_Pipeline_Index.md
4. Prepare Stage 2 handoff documentation

**Duration:** ~4 hours
**Deliverable:** Complete documentation of Stage 1 imputation

---

## 8. Risk Mitigation

### 8.1 Performance Degradation

**Risk:** 11,680-scale imputation underperforms vs. 1,084-species experiments

**Mitigation:**
- Run hyperparameter validation first (Phase 1)
- If RMSE degrades > 5%, run targeted grid search
- Fall back to Perm 1 if Perm 2 scaling issues persist

**Likelihood:** Low (experiments show XGBoost scales well)

---

### 8.2 Runtime Exceeds Estimates

**Risk:** Imputation takes significantly longer than estimated

**Mitigation:**
- Monitor log files for convergence issues
- Consider early stopping if RMSE plateaus before nrounds=3000
- Use parquet format for faster I/O

**Likelihood:** Medium (11× scale-up is significant)

---

### 8.3 Memory Issues

**Risk:** GPU memory insufficient for 11,680 × 1,490 dataset

**Mitigation:**
- XGBoost uses efficient sparse matrix representation
- Perm2 11,680 already tested with Perm8 (same scale, more features)
- Fall back to CPU if GPU memory issues

**Likelihood:** Low (Perm8 with 269 features ran successfully on same GPU)

---

### 8.4 Data Quality Issues

**Risk:** Imputed values are biologically implausible

**Mitigation:**
- Automated validation checks (range, correlation)
- Visual inspection of outliers
- Cross-reference with TRY database for extreme values
- PMM ensures predictions match observed distribution

**Likelihood:** Low (PMM constrains predictions to observed values)

---

## 9. Success Criteria

### 9.1 Technical Metrics

- ✓ All target traits have 0% missing values
- ✓ RMSE within ±5% of 1.7b Perm 2 results
- ✓ R² ≥ 0.55 for all traits (Perm 2 benchmark)
- ✓ 10 imputations + mean successfully generated
- ✓ Values within biologically plausible ranges

---

### 9.2 Pipeline Integration

- ✓ Stage 2 input dataset created successfully
- ✓ Traits back-transformed to original scale
- ✓ Environmental and phylogenetic features merged
- ✓ EIVE prediction pipeline ready

---

### 9.3 Documentation

- ✓ Methods documented in 1.7d
- ✓ Results reproducible via provided commands
- ✓ Feature importance analysis complete (SHAP or GAIN)
- ✓ Handoff to Stage 2 documented

---

## 10. References

### Experiments and Design

- **Permutation comparison:** `1.7b_XGBoost_Experiments.md`
- **Pipeline dependency analysis:** `EIVE_Pipeline_Dependency_Analysis.md`
- **Dataset preparation:** `1.7a_Imputation_Dataset_Preparation.md`
- **Old Perm3 imputation:** `legacy/1.7d_XGBoost_Imputation_Summary_OLD_Perm3_BHPMF.md`

### Scripts

- **Dataset builder:** `src/Stage_1/build_xgboost_perm123_datasets.py`
- **CV + Production imputation (unified):** `src/Stage_1/experiments/xgboost_cv_eval.R`
- **GAIN feature importance:** `src/Stage_1/experiments/xgboost_gain_importance.R`
- **Feature importance analysis:** `src/Stage_1/experiments/analyze_feature_importance.py`

### Data Locations

- **Perm 2 input:** `model_data/inputs/mixgb_perm2_11680/`
- **Production output:** `model_data/outputs/perm2_production/`
- **Models:** `model_data/models/perm2_production/`
- **Feature importance:** `results/experiments/perm2_11680/feature_importance/`

---

## 11. Next Steps

1. **Phase 1:** Run hyperparameter tuning experiments on 1,084 species (see 1.7b Section 8)
   - 2000 trees at eta=0.05
   - 3000 trees at eta=0.025
   - Compare to baseline (1000 trees, eta=0.1)

2. **Select optimal configuration** based on Phase 1 results

3. **Phase 2:** Execute production imputation on 11,680 species with optimal hyperparameters

4. **Phases 3-5:** Feature importance, quality assurance, and documentation

**Current status:** Awaiting Phase 1 hyperparameter tuning results from 1.7b experiments.

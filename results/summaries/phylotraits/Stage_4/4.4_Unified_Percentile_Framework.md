# Stage 4.4: Unified Percentile Framework

**Document:** 4.4 Unified Percentile Framework
**Date:** 2025-11-03
**Purpose:** Transition from weighted positive/negative framework to unified percentile-based scoring
**Supersedes:** Document 4.2 (weighted framework), Document 4.3 (positive/negative split)

---

## Executive Summary

**Key Innovation:** Eliminate arbitrary weights and positive/negative splits by using **direct percentile rankings** for all metrics, normalized so that **high percentile = good** for all components.

### Framework Simplification

**Before (Document 4.3):**
```
NEGATIVE (weighted): N1(35%) + N2(35%) + N4(20%) + N5(5%) + N6(5%) = [0,1]
POSITIVE (weighted): P1(25%) + P2(20%) + P3(15%) + P4(20%) + P5(10%) + P6(10%) = [0,1]
FINAL SCORE = positive - negative ∈ [-1, +1]

Problems:
- Arbitrary weights (why 35% vs 20%?)
- Complex interpretation (what does -0.3 mean?)
- Two-component aggregation obscures individual factors
```

**After (Unified Framework):**
```
9 CALIBRATED METRICS (all 0-100 scale, HIGH = GOOD):
1-9: Each metric = percentile rank from 120K calibrated guilds
OVERALL COMPATIBILITY = mean(1-9) ∈ [0, 100]

Benefits:
- No arbitrary weights - simple mean
- Clear interpretation: "This guild is at 56.7th percentile"
- Full profile visibility - see all 9 strengths/weaknesses
- Comparable across metrics - all on same scale

Note: N5 (Nitrogen) and N6 (Soil pH) displayed as binary flags, not percentiles
```

---

## The 9 Calibrated Metrics

### Metric Naming Convention

All metrics are framed so that **high percentile = desirable outcome**.

**Metrics calibrated via Monte Carlo simulation:**

| # | Metric Name | Raw Component | Interpretation |
|---|-------------|---------------|----------------|
| 1 | **Pathogen Independence** | 100 - N1 | High = few shared pathogens (good) |
| 2 | **Pest Independence** | 100 - N2 | High = few shared herbivores (good) |
| 3 | **Growth Strategy Compatibility** | 100 - N4 | High = no CSR conflicts (good) |
| 4 | **Insect Pest Control** | P1 | High = strong biocontrol (good) |
| 5 | **Fungal Disease Control** | P2 | High = antagonist fungi (good) |
| 6 | **Beneficial Fungi Networks** | P3 | High = shared beneficial fungi (good) |
| 7 | **Phylogenetic Diversity** | P4 | High = diverse lineages (good) |
| 8 | **Structural Diversity** | P5 | High = layered canopy (good) |
| 9 | **Pollinator Support** | P6 | High = shared pollinators (good) |

**Overall Compatibility Score = mean(1-9) ∈ [0, 100]**

### Metrics Excluded from Calibration

**N5 (Nitrogen Self-Sufficiency) and N6 (Soil Compatibility) are NOT calibrated** because they have clear binary or narrow-range interpretations:

- **N5**: Presence/absence of N-fixing plants (0 or 1)
  - Guild Builder will highlight: "Contains N-fixing plants ✓" or "Add legume for nitrogen ⚠"
  - Not meaningful to percentile-rank (either you have N-fixers or you don't)

- **N6**: pH compatibility range
  - Guild Builder will display: "pH range: 5.5-7.0 (compatible ✓)" or "pH mismatch detected ⚠"
  - Direct value display more informative than percentile

These will be displayed as **binary flags** or **direct values** in the Guild Builder UI, not as percentile rankings.

### Component Details

**Pathogen Independence (N1):**
- Plants have different pathogen susceptibility profiles
- High score = plants share few fungal pathogens
- Reduces disease outbreak risk

**Pest Independence (N2):**
- Plants attract different herbivore communities
- High score = plants share few herbivores
- Reduces pest pressure

**Why "Independence" not "Resistance"?**
- "Resistance" implies active defense
- "Independence" better captures the concept: plants don't share vulnerabilities
- They're independent in their susceptibility patterns

**Beneficial Fungi Networks (P3):**
- **Includes four types of beneficial fungi:**
  1. **AMF** (Arbuscular mycorrhizal fungi) - nutrient exchange
  2. **EMF** (Ectomycorrhizal fungi) - nutrient exchange
  3. **Endophytic fungi** - plant growth promotion, stress tolerance
  4. **Saprotrophic fungi** - nutrient cycling, decomposition
- High score = plants share beneficial fungi that promote plant health
- Creates underground fungal networks connecting plants

### Component Calculation Formulas

**These are the raw score computations used during Monte Carlo calibration. Percentiles are then calculated from the distribution of these raw scores.**

#### N1: Pathogen Fungi Overlap

**Formula:**
```python
n1_raw = Σ (overlap_ratio² × severity)  for each shared pathogen

where:
  overlap_ratio = (# plants sharing pathogen) / (total plants in guild)
  severity = 1.0 if host-specific pathogen, 0.6 if generalist
  only count pathogens shared by ≥2 plants
```

**Example (5-plant guild):**
- Pathogen A: shared by 3 plants → (3/5)² × 0.6 = 0.216
- Pathogen B: shared by 2 plants (host-specific) → (2/5)² × 1.0 = 0.160
- n1_raw = 0.216 + 0.160 = 0.376

**Interpretation:** Higher raw score = more pathogen overlap = worse (inverted for display)

#### N2: Herbivore Overlap

**Formula:**
```python
n2_raw = Σ (overlap_ratio² × 0.5)  for each shared herbivore

where:
  overlap_ratio = (# plants sharing herbivore) / (total plants)
  only count TRUE herbivores (exclude pollinators/visitors)
  only count herbivores shared by ≥2 plants
```

**Example (5-plant guild):**
- Herbivore X: shared by 4 plants → (4/5)² × 0.5 = 0.320
- Herbivore Y: shared by 2 plants → (2/5)² × 0.5 = 0.080
- n2_raw = 0.320 + 0.080 = 0.400

**Interpretation:** Higher raw score = more herbivore overlap = worse (inverted for display)

#### N4: CSR Conflict Density

**Formula:**
```python
conflict_density = total_conflicts / max_possible_pairs

where:
  total_conflicts = C-C conflicts + C-S conflicts + C-R conflicts + R-R conflicts
  max_possible_pairs = n_plants × (n_plants - 1)
```

**Conflict types:**
1. **High-C + High-C** (Competitor vs Competitor): base = 1.0
   - Modulated by height difference and growth form
2. **High-C + High-S** (Competitor vs Stress-tolerator): base = 0.6
   - 0.0 if S is shade-adapted (light_pref < 3.2)
   - 0.9 if S is sun-loving (light_pref > 7.47)
3. **High-C + High-R** (Competitor vs Ruderal): base = 0.8
4. **High-R + High-R** (Ruderal vs Ruderal): base = 0.3

**Thresholds:**
- High-C: CSR_C > 60
- High-S: CSR_S > 60
- High-R: CSR_R > 50

**Example (3-plant guild: 2 competitors, 1 stress-tolerator):**
- C-C pair: 1 conflict (conflict = 1.0)
- C-S pairs: 2 × 0.6 = 1.2 conflicts
- total_conflicts = 2.2
- max_pairs = 3 × 2 = 6
- conflict_density = 2.2 / 6 = 0.367

**Why conflict_density?** Makes scores comparable across 2-plant vs 7-plant guilds. A 2-plant guild with 1 conflict (density = 0.5) is worse than a 7-plant guild with 3 conflicts (density = 0.143).

**Interpretation:** Higher density = more conflicts = worse (inverted for display)

#### P1: Insect Pest Control (Biocontrol)

**Formula:**
```python
p1_raw = Σ biocontrol_mechanisms across all plant pairs

Mechanism 1: Predators (weight 1.0)
  Plant B predators that target Plant A herbivores

Mechanism 2: Specific entomopathogenic fungi (weight 1.0)
  Plant B fungi that target Plant A herbivores (via lookup table)

Mechanism 3: General entomopathogenic fungi (weight 0.2)
  Plant B has entomopathogenic fungi and Plant A has herbivores

p1_normalized = tanh(p1_raw / max_pairs × 20)
```

**Entomopathogenic fungi in biocontrol:**
- Coverage: 364 / 11,680 plants (3.1%)
- Top genera: septobasidium, orbilia, aschersonia, myriangium
- Mechanism 2 uses `herbivore_predators.parquet` lookup table (insect → fungi mapping)
- Mechanism 3 provides general biocontrol bonus without specific matching

**Example (3-plant guild):**
- Plant A has 2 aphid species (herbivores)
- Plant B has lecanicillium (entomopathogenic fungus that targets aphids)
- Mechanism 2: 1 match × 1.0 = 1.0
- Mechanism 3: Plant B has ento fungi and Plant A has herbivores → +1 × 0.2 = 0.2
- p1_raw = 1.2
- max_pairs = 3 × 2 = 6
- p1_normalized = tanh(1.2 / 6 × 20) = tanh(4.0) = 0.999

**Interpretation:** Higher score = stronger cross-plant insect pest control = good

**Note:** P1/P2 require herbivore-predator and pathogen-antagonist lookup tables which are computationally expensive. Set to 0 for initial calibration; fully implemented in guild_scorer_v3.py.

#### P2: Fungal Disease Control

**Formula:**
```python
p2_raw = Σ (len(mycoparasites_b) × 0.3) for all plant pairs where:
  - Plant A has pathogenic fungi
  - Plant B has mycoparasite fungi

p2_normalized = tanh(p2_raw / max_pairs × 10)
```

**Mechanism: General Mycoparasite Presence (weight 0.3)**

When Plant B hosts mycoparasite fungi and Plant A hosts pathogenic fungi, the mycoparasites provide general disease suppression benefits to the guild.

**Mycoparasite fungi coverage:**
- Coverage: 305 / 11,680 plants (2.6%) with mycoparasites
- 62 unique mycoparasite genera extracted from FungalTraits + FunGuild
- Top genera: trichoderma (85 plants), tremella (38), dialonectria (35)
- Sources: FungalTraits `primary_lifestyle='mycoparasite'` + FunGuild `guild LIKE '%Mycoparasite%'`

**Ecological Context: Mycoparasites as Rare Trait**

Mycoparasites represent only **1.59% of all fungal genera** (171/10,765 in FungalTraits) - a genuinely rare evolved trait similar to arbuscular mycorrhizal fungi (0.47%). This natural scarcity explains:

1. **Why commercial Trichoderma products exist**: Compensating for evolutionary rarity
2. **Why 83% of 7-plant guilds score P2 = 0**: Most lack natural biocontrol fungi
3. **Why high P2 scores indicate exceptional guilds**: The fortunate 17% with built-in disease suppression

Plants hosting Trichoderma, Gliocladium, or other mycoparasites provide ecosystem-level disease control that most gardens lack naturally.

**Example (4-plant guild):**
- Plant A has 3 pathogenic fungi genera
- Plant C has 2 mycoparasite fungi genera (trichoderma, hypomyces)
- Pairs (A,C): 2 mycoparasite genera × 0.3 = 0.6
- p2_raw = 0.6
- max_pairs = 4 × 3 = 12
- p2_normalized = tanh(0.6 / 12 × 10) = tanh(0.5) = 0.46

**Interpretation:** Higher score = stronger pathogen antagonism = good

---

**Why NOT Specific Pathogen-Antagonist Matching (Mechanism 1)?**

**Data investigation revealed:**

1. **GloBI fungus-fungus data exists** (56,951 interactions) but quality is problematic:
   - 3,668 parasitic fungus-fungus relationships found
   - 553 fungal "antagonist" genera
   - BUT: Only 54/553 (9.8%) validated as true mycoparasites in FungalTraits
   - Remaining 90% are lichen parasites, wood-decay competitors, not biocontrol fungi

2. **Limited pathogen coverage:**
   - 77 of our plant pathogen genera have antagonists in GloBI
   - Trichoderma → Rhizoctonia relationship confirmed (affects 211 plants)
   - Literature: Trichoderma controls 100+ pathogens
   - GloBI: Only 1 useful target for our plants
   - Not comprehensive enough for reliable specific matching

3. **FungalTraits/FunGuild limitations:**
   - FungalTraits: `Specific_hosts` column refers to PLANT hosts, not fungal targets
   - Example: Eudarluca → "rusts" (generic family, not species)
   - FunGuild: Only has guild classification, no target information
   - Neither database specifies which pathogens mycoparasites control

**Conclusion:** We know WHICH fungi are mycoparasites, but NOT which pathogens they eat. Mechanism 2 (general presence) is more reliable than attempting species-specific matching with incomplete data.

---

**Why NOT Include Fungivores (Collembola, Mites)?**

**Data investigation revealed:**

1. **Fungivore data exists** in GloBI:
   - 311 insect species eat fungi
   - 31 Collembola (springtail) → fungus relationships
   - 31 plant-Collembola interactions in our dataset

2. **But data quality is too vague:**
   - Fungi targets: Mostly generic "Fungi" label, not specific pathogen genera
   - Only 2 specific: Clitocybe, Cudonia (edible mushrooms, not pathogens)
   - Plant relationships: "interactsWith", "adjacentTo" (too vague to determine attraction)
   - Cannot build reliable Plant → Fungivore → Pathogen network

3. **Coverage too sparse:**
   - 31 interactions vs 11,680 plants
   - Cannot determine which plants ATTRACT fungivores vs merely co-occur

**Conclusion:** Insufficient data to add fungivore mechanism. Future enhancement if better soil organism datasets become available.

#### P3: Beneficial Fungi Networks

**Formula:**
```python
p3_raw = (network_score × 0.6) + (coverage_score × 0.4)

where:
  network_score = Σ (count / n_plants)  for each shared beneficial fungus
    - only count fungi shared by ≥2 plants
    - includes AMF, EMF, endophytic, saprotrophic fungi

  coverage_score = (# plants with ANY beneficial fungi) / (total plants)
```

**Example (4-plant guild):**
- Fungus A (AMF): shared by 3 plants → 3/4 = 0.75
- Fungus B (EMF): shared by 2 plants → 2/4 = 0.50
- network_score = 0.75 + 0.50 = 1.25
- 4 plants have beneficial fungi → coverage_score = 4/4 = 1.0
- p3_raw = (1.25 × 0.6) + (1.0 × 0.4) = 0.75 + 0.40 = 1.15

**Interpretation:** Higher score = better fungal networks = good

#### P4: Phylogenetic Diversity (Mean Pairwise Distance)

**Formula:**
```python
p4_raw = mean(pairwise_euclidean_distances(phylo_eigenvectors))

where:
  phylo_eigenvectors = 92-dimensional phylogenetic coordinate space
  pairwise distances = all C(n,2) distances between plants
```

**Example (3-plant guild):**
- Distance(plant1, plant2) = 0.15
- Distance(plant1, plant3) = 0.18
- Distance(plant2, plant3) = 0.12
- p4_raw = (0.15 + 0.18 + 0.12) / 3 = 0.15

**Interpretation:** Higher MPD = more phylogenetic diversity = good

**Why 92 eigenvectors?** Captures phylogenetic relationships from dated molecular phylogeny across all major plant clades.

#### P5: Vertical Stratification with Light Validation

**Critical Insight (Bill Shipley)**: Height diversity alone is meaningless if shorter plants are sun-loving - they'll be shaded out by taller plants. Stratification must be validated by light compatibility.

**Formula:**
```python
p5_raw = (stratification_quality × 0.7) + (form_diversity × 0.3)

where:
  stratification_quality = valid_height_differences / total_height_differences

  For each tall-short plant pair with height_diff > 2m:
    IF short_plant.light_pref < 4.0:  # Shade-tolerant (EIVE-L 1-3)
      valid += height_diff  # Can thrive under canopy
    ELIF short_plant.light_pref > 7.0:  # Sun-loving (EIVE-L 8-9)
      invalid += height_diff  # Will be shaded out
    ELSE:  # Flexible (EIVE-L 4-7)
      valid += height_diff × 0.6  # Partial compatibility

  form_diversity = (unique_growth_forms - 1) / 5
```

**Light Preference Scale (EIVE-L)**:
- **1-3**: Shade plants (deep shade to moderate shade)
- **4-7**: Flexible (semi-shade to half-light)
- **8-9**: Sun plants (full light requirement)

---

**Example 1: Valid Stratification**

```
Guild: Quercus robur (27.08m, L=6.24) + Corylus avellana (3.93m, L=5.41) + Oxalis acetosella (0.09m, L=1.16)

Height pairs:
  Quercus → Corylus: 23.15m diff, L=5.41 (flexible) → valid = 23.15 × 0.6 = 13.89
  Quercus → Oxalis: 26.99m diff, L=1.16 (shade) → valid = 26.99
  Corylus → Oxalis: 3.84m diff, L=1.16 (shade) → valid = 3.84

Total valid = 13.89 + 26.99 + 3.84 = 44.72
Total invalid = 0
stratification_quality = 44.72 / 44.72 = 1.0

Forms: 3 unique (tree, shrub/tree, herbaceous)
form_diversity = (3-1) / 5 = 0.4

p5_raw = (1.0 × 0.7) + (0.4 × 0.3) = 0.70 + 0.12 = 0.82

Interpretation: Excellent vertical stratification - shade-adapted understory ✓
```

---

**Example 2: Invalid Stratification**

```
Guild: Quercus robur (27.08m, L=6.24) + Lactuca sativa (0.72m, L=7.63) + Achillea erba-rotta (0.09m, L=9.83)

Height pairs:
  Quercus → Lactuca: 26.36m diff, L=7.63 (sun) → invalid = 26.36
  Quercus → Achillea: 26.99m diff, L=9.83 (sun) → invalid = 26.99
  Lactuca → Achillea: 0.63m diff (< 2m threshold, skip)

Total valid = 0
Total invalid = 26.36 + 26.99 = 53.35
stratification_quality = 0 / 53.35 = 0.0

Forms: 2 unique (tree, herbaceous)
form_diversity = (2-1) / 5 = 0.2

p5_raw = (0.0 × 0.7) + (0.2 × 0.3) = 0.0 + 0.06 = 0.06

Interpretation: Apparent height diversity but ecologically invalid - sun plants will die ✗
```

---

**Example 3: Mixed Compatibility**

```
Guild: Salix eleagnos (4.24m, L=7.58) + Oxalis acetosella (0.09m, L=1.16) + Achillea erba-rotta (0.09m, L=9.83)

Height pairs:
  Salix → Oxalis: 4.15m diff, L=1.16 (shade) → valid = 4.15
  Salix → Achillea: 4.15m diff, L=9.83 (sun) → invalid = 4.15
  Oxalis → Achillea: 0m diff (< 2m threshold, skip)

Total valid = 4.15
Total invalid = 4.15
stratification_quality = 4.15 / (4.15 + 4.15) = 0.50

Forms: 2 unique (tree, herbaceous)
form_diversity = (2-1) / 5 = 0.2

p5_raw = (0.50 × 0.7) + (0.2 × 0.3) = 0.35 + 0.06 = 0.41

Interpretation: Mixed stratification - shade plant thrives, sun plant struggles ~
```

---

**Why NOT Merge P5 with N4 (CSR Conflicts)?**

**The Overlap**: 36.5% of guilds are penalized by BOTH metrics when P5 includes light validation:
- **N4**: High-C competitor shading High-S sun-loving plant → CSR strategy conflict
- **P5**: Tall plant shading sun-loving short plant → invalid vertical stratification

**Same ecological phenomenon (shading incompatibility), different theoretical perspectives**.

**But we keep them separate because:**

**1. Different Conceptual Frameworks**

| Aspect | N4: CSR Conflicts | P5: Vertical Stratification |
|--------|------------------|---------------------------|
| **Theory** | Grime's CSR theory | Niche differentiation |
| **Question** | Do strategies clash? | Is vertical space well-used? |
| **Primary input** | CSR values (C, S, R) | Height + light preferences |
| **Scope** | Only extreme strategies (C>60, S>60, R>50) | ALL plants regardless of CSR |
| **Coverage** | 7.4% of shading issues | 92.6% of shading issues |

**2. Horticultural Decision-Making Value**

Separate scores provide **actionable diagnostic information**:

```
Scenario A: N4=0.8 (high), P5=0.3 (low)
  Diagnosis: "Strategy conflicts + poor stratification"
  Actions:
    - Reduce number of high-C competitors
    - OR ensure shorter plants are shade-adapted
    - Add understory shade-lovers

Scenario B: N4=0.2 (low), P5=0.3 (low)
  Diagnosis: "Compatible strategies but poor vertical structure"
  Actions:
    - Add height diversity
    - Mix shade-adapted ground covers with taller plants
    - No need to worry about CSR conflicts

Scenario C: N4=0.8 (high), P5=0.9 (high)
  Diagnosis: "Strategy conflicts mitigated by good stratification"
  Actions:
    - Acceptable guild - stratification reduces competition
    - Monitor but may not need changes

Merged metric would give: "Compatibility score = 0.5"
  → Which problem? Strategy or structure?
  → What should user change?
```

**3. Coverage Complementarity**

N4 and P5 catch different aspects:

| Case | N4 Catches? | P5 Catches? | Example |
|------|-------------|-------------|---------|
| High-C + High-S sun-lover | ✓ Yes | ✓ Yes | Oak (C=80) + sun-loving shrub (S=70, L=8) |
| Medium-C + Low-C sun-lover | ✗ No | ✓ Yes | Apple (C=55) + lettuce (C=40, L=9) |
| High-C + High-S shade-lover | ✓ Yes (reduced) | ✓ Yes (valid) | Oak + shade fern (S=75, L=2) |
| Low-C herb + Low-C herb | ✗ No | ✗ No | Lettuce + radish (both R-strategists) |

**Together they provide complete coverage**.

**4. The 36.5% Overlap is Ecologically Appropriate**

When a guild has BOTH CSR conflicts AND structural incompatibility:
- These are genuinely severe problems
- Like "running red light while speeding" - two violations
- **Double penalty is justified** - user should prioritize fixing these guilds

**5. User Mental Model**

Gardeners understand:
- **"Strategy conflicts"**: Some plants are bullies (C), some need stress (S)
- **"Vertical layers"**: Canopy, understory, ground cover
- **"Light needs"**: Shade vs sun plants

These are **distinct concepts** in horticultural practice. Merging would create confusion.

---

**Implementation Note: Light Data Coverage**

EIVE-L (light preference) available for 9,043 / 11,680 plants (77.4%).

**For plants without light data**:
```python
if pd.isna(short_plant.light_pref):
    # Conservative assumption: neutral/flexible
    valid += height_diff × 0.5
```

This prevents penalizing guilds due to missing data while still validating when light preferences are known.

**Interpretation:** Higher score = ecologically valid vertical stratification = good

#### P6: Pollinator Support (Shared Pollinators)

**Formula:**
```python
p6_raw = Σ (overlap_ratio^1.5)  for each shared pollinator

where:
  overlap_ratio = (# plants sharing pollinator) / (total plants)
  only count pollinators shared by ≥2 plants
  exponent 1.5 creates superlinear benefit (networks > isolated pairs)
```

**Example (4-plant guild):**
- Bee species A: shared by 3 plants → (3/4)^1.5 = 0.65
- Butterfly B: shared by 2 plants → (2/4)^1.5 = 0.35
- p6_raw = 0.65 + 0.35 = 1.00

**Interpretation:** Higher score = better pollinator sharing = good

**Why exponent 1.5?** Pollinator networks have superlinear benefits - 3 plants sharing 1 pollinator is better than 2 isolated pairs.

---

## Multi-Guild Fungi: Intentional Double Counting

### The Mechanism

Fungal genera can have **multiple ecological roles** (primary + secondary lifestyles in FungalTraits database). The same fungal genus may appear in **multiple guild lists** in the dataset `plant_fungal_guilds_hybrid.parquet`.

**Example real data:**
```python
Plant: wfo-0000510888
{
    'pathogenic_fungi': ['alternaria', 'cercospora', ...],  # alternaria HERE
    'saprotrophic_fungi': ['alternaria'],                    # AND HERE
    'endophytic_fungi': [],
    ...
}
```

### Where Multi-Guild Fungi Are Counted

**Fungi with dual roles contribute to multiple metrics:**

| Fungal Guild Combinations | Counted In | Effect |
|---------------------------|------------|--------|
| **Pathogen + Saprotroph** | N1 (pathogen penalty) + P3 (beneficial network) | Common (alternaria, heterobasidion, fusarium) |
| **Pathogen + Endophyte** | N1 (pathogen penalty) + P3 (beneficial network) | Rare (phacidium) |
| **Entomopathogen + Saprotroph** | P1 (biocontrol) + P3 (beneficial network) | Common (orbilia, myriangium, lecanicillium) |
| **Entomopathogen + Endophyte** | P1 (biocontrol) + P3 (beneficial network) | Rare (hypocrella, cordyceps) |

**Note:** Entomopathogenic fungi (insect parasites) never appear in pathogenic lists - they attack insects, not plants.

### Deduplication Within Metrics

The `_count_shared_organisms()` function prevents double counting **within the same metric**:

```python
# Example: alternaria appears in BOTH endophytic AND saprotrophic for same plant
# P3 counts alternaria ONCE for that plant (uses set() to deduplicate)

def _count_shared_organisms(self, df, *columns):
    for _, row in df.iterrows():
        plant_organisms = set()  # ← Prevents duplicates within plant
        for col in columns:
            plant_organisms.update(row[col])
        for org in plant_organisms:
            organism_counts[org] += 1  # Count once per plant
```

### Ecological Rationale

**Why double counting is correct:**

1. **Reflects real trade-offs**: A guild gets BOTH the pathogen risk (N1) AND the decomposition benefit (P3) from Fusarium
2. **Ecologically documented**: Many fungi have dual roles (e.g., Fusarium = pathogen + endophyte + saprotroph)
3. **Percentile calibration accounts for correlation**: The 120K calibration guilds include these dual-role patterns, so percentile rankings already reflect realistic distributions

**Example guild impact:**
- Guild with Fusarium present on 3 plants:
  - N1 penalty: overlap_ratio² = (3/7)² = 0.184 × severity
  - P3 benefit: coverage = 3/7 = 0.429 (if also counted as saprotroph)
  - Net: Guild Builder shows both the risk and benefit separately

### Coverage Statistics

**Entomopathogenic fungi** (insect biocontrol):
- Coverage: 364 / 11,680 plants (3.1%)
- Top genera: septobasidium (118 plants), orbilia (39), aschersonia (37)
- Multi-guild: ~30% also appear in saprotrophic lists

**Pathogenic fungi with dual roles:**
- Pathogen + Saprotroph: Very common (alternaria, heterobasidion, rosellinia, inonotus)
- Pathogen + Endophyte: Rare (phacidium)
- These contribute to ~10% of plants with pathogenic fungi

### Statistical Implication

Multi-guild fungi create **correlation between N1 and P3** (and between P1 and P3 for entomopathogenic fungi). This is:
- ✓ **Ecologically realistic** - captures real-world trade-offs
- ⚠ **Statistically non-independent** - N1 and P3 are not fully independent variables

This correlation is **already captured in calibration** since the Monte Carlo sampling includes these natural patterns.

---

### Statistical Rationale and Soundness Evaluation

**Why these particular formulas? A simple explanation:**

#### The Core Principle: Ratio-Based Normalization

**Simple version:** Divide by guild size to make scores fair.

**Why this matters:**
- A 2-plant guild with 1 shared pathogen should score WORSE than a 7-plant guild with 2 shared pathogens
- Solution: Use `count / n_plants` ratios instead of raw counts
- This makes "intensity" comparable across guild sizes

**Where we use it:**
- N1, N2: `overlap_ratio = count / n_plants`
- N4: `conflict_density = conflicts / max_pairs`
- P3, P6: `coverage = count / n_plants`

**Soundness: ✓ Strong**
- Standard statistical approach for comparing populations of different sizes
- Ecologically meaningful (measures prevalence, not absolute count)
- Tested empirically: 2-plant and 7-plant guilds produce comparable percentile ranges

#### Quadratic Penalties for Risks (N1, N2)

**Simple version:** Widespread threats are exponentially worse.

**Formula:** `overlap_ratio²` instead of `overlap_ratio`

**Why quadratic?**
- A pathogen affecting 4/5 plants (80%) is MUCH worse than one affecting 2/5 plants (40%)
- Linear penalty: 0.80 vs 0.40 = 2× worse
- Quadratic penalty: 0.64 vs 0.16 = 4× worse ← matches ecological reality

**Ecological rationale:**
- Disease outbreaks have threshold effects (spread accelerates beyond certain prevalence)
- Quadratic captures this non-linear risk escalation

**Example:**
- Pathogen X affects 1/5 plants → (0.2)² = 0.04 (minor issue)
- Pathogen Y affects 4/5 plants → (0.8)² = 0.64 (major outbreak risk)

**Soundness: ✓ Strong**
- Epidemiological models support non-linear disease risk
- Conservative approach (penalizes widespread threats heavily)
- Alternative (linear) would underweight severe overlaps

#### Superlinear Benefits for Networks (P6)

**Simple version:** Pollinator networks have increasing returns.

**Formula:** `overlap_ratio^1.5` instead of `overlap_ratio^1.0`

**Why superlinear?**
- 3 plants sharing 1 bee species is better than 3 isolated plant-bee pairs
- Network effects: more connections → more resilience
- Exponent 1.5 is intermediate between linear (1.0) and quadratic (2.0)

**Example:**
- 2 plants share pollinator: (0.5)^1.5 = 0.35
- 4 plants share pollinator: (1.0)^1.5 = 1.00
- Ratio: 1.00/0.35 = 2.9× better (stronger than linear 2×)

**Soundness: ~ Moderate**
- ✓ Ecological principle is sound (network benefits are real)
- ? Specific exponent 1.5 is somewhat arbitrary
- Could be data-driven: fit exponent to observed pollination success vs network size
- Recommendation: Validate exponent against pollination literature

#### Weighted Composite Scores (P3, P5)

**P3 formula:** `network_score × 0.6 + coverage_score × 0.4`

**Simple version:** Balance sharing vs presence.

**Why 60/40 split?**
- Network score (60%): Rewards SHARED beneficial fungi (strong signal)
- Coverage score (40%): Rewards ANY beneficial fungi (ensures participation)
- Without coverage component: guilds with diverse fungi but no overlap score 0
- Without network component: guilds with isolated fungi score same as networked

**P5 formula:** `height_diversity × 0.6 + form_diversity × 0.4`

**Why 60/40 split?**
- Height (60%): More continuous, objective measurement
- Form (40%): Categorical, but captures functional diversity

**Soundness: ~ Moderate**
- ✓ Composite approach prevents single-dimension dominance
- ? Weights (60/40) are heuristic, not data-derived
- Recommendation: Could optimize weights via regression against ecosystem function metrics
- Note: Percentile calibration somewhat dampens the impact of weight choice

#### Arbitrary Normalization Constants (P5)

**Formula:** `height_range / 20.0` and `unique_forms / 5.0`

**Why 20m and 5 forms?**
- 20m: Typical full forest canopy stratification (ground → canopy)
- 5 forms: Approximate maximum distinct growth forms (tree, shrub, vine, herb, grass)

**Problem:** What if you have a 30m tree or 7 distinct forms?
- Answer: Scores cap at 1.0 (this is actually OK for percentile ranking)

**Soundness: ~ Weak to Moderate**
- ? Constants chosen by ecological intuition, not data
- ✓ Capping at 1.0 prevents extreme outliers from dominating
- Better approach: Use 95th percentile of observed data as normalization constant
- Example: If 95% of guilds have height_range < 18m, use 18 instead of 20

**Recommendation:**
```python
# Data-driven normalization (future improvement)
height_norm = np.percentile(all_guild_height_ranges, 95)  # e.g., 17.3m
form_norm = np.percentile(all_guild_form_counts, 95)      # e.g., 4

height_diversity = min(height_range / height_norm, 1.0)
form_diversity = min(unique_forms / form_norm, 1.0)
```

#### Mean Pairwise Distance (P4)

**Simple version:** Average how different plants are evolutionarily.

**Why mean instead of sum?**
- Sum would favor larger guilds (more pairs → higher sum)
- Mean normalizes by number of pairs automatically
- Standard metric in phylogenetic diversity literature

**Why Euclidean distance in eigenvector space?**
- Eigenvectors capture phylogenetic relationships from dated molecular tree
- Euclidean distance = evolutionary dissimilarity
- Alternative: Faith's PD (sum branch lengths) - requires tree topology, not eigenvectors

**Soundness: ✓ Strong**
- MPD is well-established in ecology literature
- Eigenvector approach is mathematically equivalent to tree-based methods
- Automatically handles guild size (mean vs sum)

#### P1/P2 Currently Set to Zero

**Issue:** Biocontrol and disease control require complex lookup tables.

**Impact on calibration:**
- 7 components active (N1, N2, N4, P3, P4, P5, P6)
- 2 components inactive (P1, P2)
- Overall score computed from 7/9 components initially

**Soundness: ✗ Incomplete**
- Acceptable for initial calibration (establish framework)
- P1/P2 are important components (biocontrol is major guild benefit)
- Must be added before production deployment

**Recommendation:**
```python
# Phase 1 (current): Calibrate with P1=P2=0
# Phase 2 (before production):
#   1. Create herbivore-predator relationship tables
#   2. Create pathogen-antagonist relationship tables
#   3. Re-run calibration with full P1/P2 computation
#   4. Compare percentile distributions to Phase 1
```

### Summary: Soundness Ratings

| Component | Approach | Soundness | Notes |
|-----------|----------|-----------|-------|
| **N1, N2** | Quadratic ratio | ✓ Strong | Ecologically defensible, epidemiologically sound |
| **N4** | Conflict density | ✓ Strong | Critical fix for guild size independence |
| **P3** | Weighted composite | ~ Moderate | Sound principle, weights could be optimized |
| **P4** | Mean pairwise distance | ✓ Strong | Standard phylogenetic metric |
| **P5** | Weighted composite | ~ Moderate | Arbitrary constants (20m, 5 forms) |
| **P6** | Superlinear ratio | ~ Moderate | Sound principle, exponent could be validated |
| **P1, P2** | Set to 0 | ✗ Incomplete | Must add before production |

### Recommendations for Future Refinement

1. **Data-driven normalization (P5):**
   - Replace 20m → 95th percentile of observed height ranges
   - Replace 5 forms → 95th percentile of observed form counts

2. **Validate exponents empirically:**
   - N1/N2: Test if quadratic outperforms linear/cubic via cross-validation
   - P6: Fit exponent to pollination success literature

3. **Optimize composite weights (P3, P5):**br
   - Use regression against ecosystem function proxies
   - Or keep 60/40 heuristic if percentile calibration dampens sensitivity

4. **Implement P1/P2:**
   - Build relationship lookup tables
   - Re-calibrate with full 9 components
   - Critical for production deployment

5. **Sensitivity analysis:**
   - Test how percentile rankings change with formula variations
   - If rankings are stable (Spearman ρ > 0.9), current approach is robust

**Current status:** Framework is statistically sound for 7/9 components. P1/P2 must be added. Minor refinements (data-driven constants, optimized exponents) would strengthen rigor but are not critical for initial deployment given percentile calibration approach.

---

## Percentile Calibration Approach

### Variable Guild Size Strategy

**Critical insight:** User's Guild Builder allows **2-10 plants**, but component scores scale differently with guild size:

| Component Type | Guild Size Dependency | Example |
|----------------|----------------------|---------|
| **Pairwise (P1, P2, N4)** | O(n²) scaling | 5-plant: 20 pairs, 10-plant: 90 pairs |
| **Additive (N1, N2, P3, P6)** | O(n) scaling | More plants → more organisms summed |
| **Statistical (N6, P5)** | Sample size bias | Larger guilds → wider observed ranges |
| **Size-independent (N5, P4)** | No scaling | Already normalized |

**Solution:** Calibrate with **variable guild sizes (2-7 plants)** to naturally capture size-dependent distributions.

**Why 2-7 range?**
- Covers typical polyculture sizes (2-7 companion plants)
- Guild Builder allows up to 10, but most users create 3-5 plant guilds
- Calibration distribution matches actual usage patterns
- Avoids need for complex mathematical size normalization

### 9 Components Calibrated with Variable-Size Guilds

**Calibration improvements:**
1. **9 components** use empirical percentile calibration
2. **Variable guild sizes (2-7 plants)** eliminate need for size normalization
3. **20K guilds per tier** provides publication-quality percentile estimates

**Component list (calibrated):**

1. **N1**: Pathogen fungi overlap
2. **N2**: Herbivore overlap
3. **N4**: CSR conflicts
4. **P1**: Insect pest control (optimized with dictionary lookups)
5. **P2**: Fungal disease control (optimized with dictionary lookups)
6. **P3**: Beneficial fungi sharing (AMF, EMF, endophytes, saprotrophs)
7. **P4**: Phylogenetic diversity (92 eigenvectors)
8. **P5**: Height stratification
9. **P6**: Shared pollinators

**Components NOT calibrated (displayed as flags):**
- **N5**: Nitrogen fixation (binary: present/absent)
- **N6**: pH compatibility (range display: e.g., "5.5-7.0")

**Calibration process:**
```python
# For each component, store percentiles p1, p5, p10, ..., p95, p99
# Percentiles computed from 10K guilds with sizes 2-7

Example for N1:
  raw_value = 0.82 (from 5-plant guild)
  p80 = 0.75, p90 = 0.85
  → percentile = 80 + (0.82 - 0.75)/(0.85 - 0.75) * (90 - 80) = 87th %ile
  → Pathogen Independence = 100 - 87 = 13th %ile (BAD - many shared pathogens)

# Works for any guild size because calibration distribution includes all sizes
```

**Performance with optimizations:**
- P1/P2 optimized with dictionary-based lookups (removed nested DataFrame filtering)
- Estimated calibration time: ~17 minutes for 10K guilds (all 11 components)
- Future optimization opportunity: Pre-compute plant-plant relationship matrices

---

## Climate-Stratified Calibration (Köppen-Geiger Tiers)

### Rationale

**Problem:** Comparing a tropical guild (orchids + palms) against a temperate guild (oaks + maples) is meaningless. Different climates have fundamentally different plant pools, biogeographic constraints, and compatibility patterns.

**Solution:** Climate-stratified Monte Carlo calibration using **Köppen-Geiger climate zones** derived from actual GBIF occurrence data.

### Data Pipeline

**Step 1: Assign Köppen Zones to 31M GBIF Occurrences**

- Used `kgcpy` library to assign Köppen-Geiger zone to each GBIF occurrence coordinate
- 31,345,882 occurrences → all successfully labeled with Köppen zones
- 32 unique Köppen zones found (Af, Am, Aw, BWh, BWk, BSh, BSk, Csa, Csb, Csc, Cfa, Cfb, Cfc, Cwa, Cwb, Cwc, Dfa, Dfb, Dfc, Dfd, Dwa, Dwb, Dwc, Dwd, Dsa, Dsb, Dsc, Dsd, ET, EF, Ocean)
- Data stored in: `data/stage1/worldclim_occ_samples_with_koppen.parquet`

**Step 2: Aggregate to Plant-Level Köppen Distributions**

- For each of 11,680 plants, calculate:
  - Occurrence counts per Köppen zone
  - Percentages per zone
  - "Main zones" = zones with ≥5% of plant's occurrences (outlier filtering)
  - Top zone = most common Köppen zone (plant's primary climate)
- Data stored in: `data/stage4/plant_koppen_distributions.parquet`

**Step 3: Group Köppen Codes into Six Calibration Tiers**

**Tier Structure** (based on Köppen climate groups):

| Tier | Name | Köppen Codes | Plant Count | % of Dataset |
|------|------|--------------|-------------|--------------|
| 1 | **Tropical** | Af, Am, As, Aw | 1,633 | 14.0% |
| 2 | **Mediterranean** | Csa, Csb, Csc | 4,036 | 34.6% |
| 3 | **Humid Temperate** | Cfa, Cfb, Cfc, Cwa, Cwb, Cwc | 8,619 | 73.8% |
| 4 | **Continental** | Dfa, Dfb, Dfc, Dfd, Dwa, Dwb, Dwc, Dwd, Dsa, Dsb, Dsc, Dsd | 4,367 | 37.4% |
| 5 | **Boreal/Polar** | ET, EF | 1,059 | 9.1% |
| 6 | **Arid** | BWh, BWk, BSh, BSk | 2,759 | 23.6% |

**Note:** Percentages don't sum to 100% because of multi-assignment (see below).

### Multi-Assignment Approach

**Critical Design:** Plants can belong to **multiple climate tiers** if they have main zones (≥5% occurrences) in multiple Köppen codes that map to different tiers.

**Example:**
```
Plant: wfo-0000000138
  Main zones: Cfb (83.6%), Dfb (12.7%)
  Tier assignments: Tier 3 (Humid Temperate) + Tier 4 (Continental)

Why this is correct:
  - Plant naturally grows in both UK (Cfb) and Poland (Dfb)
  - UK gardener can use this plant → should be in Tier 3 calibration pool
  - Polish gardener can use this plant → should be in Tier 4 calibration pool
```

**Multi-Assignment Statistics:**
- Total unique plants: **11,680**
- Total plant-tier assignments: **22,473** (sum across all tiers)
- **Multi-assignment multiplier: 1.92×** (avg plant is in ~2 tiers)

**Distribution:**
- 31.1% of plants in **1 tier** (climate specialists)
- 47.4% of plants in **2 tiers** (most common - moderate range)
- 19.1% of plants in **3 tiers** (wide-ranging)
- 2.4% of plants in **4-5 tiers** (cosmopolitan)

### Dataset Structure

**Final integrated dataset:**
- File: `model_data/outputs/perm2_production/perm2_11680_with_koppen_tiers_20251103.parquet`
- Total columns: **795** (original 778 + 17 Köppen/tier columns)

**New Köppen-related columns:**
- `total_occurrences`: Total GBIF occurrences used
- `n_koppen_zones`: Number of Köppen zones plant occurs in
- `n_main_zones`: Number of zones with ≥5% occurrences
- `top_zone_code`: Most common Köppen zone (e.g., 'Cfb')
- `top_zone_percent`: % of occurrences in top zone
- `ranked_zones_json`: JSON array of all zones (ranked by frequency)
- `main_zones_json`: JSON array of main zones (≥5%)
- `zone_counts_json`: JSON dict of occurrence counts per zone
- `zone_percents_json`: JSON dict of percentages per zone

**Tier assignment columns (boolean flags):**
- `tier_1_tropical`: TRUE if plant has main zone in Tropical tier
- `tier_2_mediterranean`: TRUE if plant has main zone in Mediterranean tier
- `tier_3_humid_temperate`: TRUE if plant has main zone in Humid Temperate tier
- `tier_4_continental`: TRUE if plant has main zone in Continental tier
- `tier_5_boreal_polar`: TRUE if plant has main zone in Boreal/Polar tier
- `tier_6_arid`: TRUE if plant has main zone in Arid tier

**Convenience columns:**
- `tier_memberships_json`: JSON array of tier names
- `n_tier_memberships`: Number of tiers plant belongs to

### Calibration Strategy

**Revised sampling approach:**
- Sample **100,000 guilds total** (stratified across 6 tiers)
- ~17,000 guilds per tier (6 × 17K ≈ 100K)
- Each guild: randomly sample 7 plants from that tier's pool
- Variable guild size (2-7) still applies within each tier

**Tier-specific sampling example:**
```python
# Load dataset
plants = con.execute("""
    SELECT * FROM read_parquet('model_data/.../perm2_11680_with_koppen_tiers_20251103.parquet')
""").fetchdf()

# Sample guilds for Tier 3 (Humid Temperate)
tier_3_plants = plants[plants['tier_3_humid_temperate'] == True]
print(f"Tier 3 pool: {len(tier_3_plants):,} plants")  # 8,619 plants

# Sample 17K guilds from Tier 3 pool
for i in range(17000):
    guild_size = random.randint(2, 7)
    guild_plants = tier_3_plants.sample(n=guild_size)
    # Score this guild... store raw component values

# Repeat for all 6 tiers
```

**Multi-assignment handling:**
- Plants with `tier_3_humid_temperate == TRUE` AND `tier_4_continental == TRUE` appear in BOTH pools
- They can be sampled in Tier 3 calibration AND Tier 4 calibration
- This is correct behavior (wide-ranging species contribute to multiple climate contexts)

### User Scoring Workflow

**Step 1: Detect user location → Köppen zone**
```python
user_lat, user_lon = 51.5074, -0.1278  # London
user_koppen_zone = lookupCZ(user_lat, user_lon)  # Returns: 'Cfb'
```

**Step 2: Map Köppen zone → calibration tier**
```python
tier_mapping = {
    'Cfb': 'tier_3_humid_temperate',
    'Dfb': 'tier_4_continental',
    # ... etc
}
user_tier = tier_mapping[user_koppen_zone]  # 'tier_3_humid_temperate'
```

**Step 3: Load tier-specific percentile calibration**
```python
# Load pre-computed percentiles for Tier 3
tier_3_percentiles = load_percentiles('tier_3_humid_temperate')

# Score user's guild
user_guild_raw_scores = compute_raw_scores(user_guild)
user_guild_percentiles = convert_to_percentiles(user_guild_raw_scores, tier_3_percentiles)
```

**Step 4: Return percentile ranking**
```
Your guild ranks at the 56.7th percentile compared to 17,000
Humid Temperate guilds (plants from Cfb, Cfa, Cfc, Cwa, Cwb, Cwc zones).
```

### Benefits

1. **Ecologically defensible**: Köppen classification is scientific standard
2. **Climate-appropriate comparisons**: Tropical guilds vs tropical benchmarks
3. **Based on actual occurrence data**: Not inferred from bio1-bio19
4. **Handles wide-ranging species**: Multi-assignment captures biogeographic reality
5. **User location mapping**: Automatic tier detection from coordinates
6. **Fair percentile rankings**: User compared against guilds from same climate context

### Verification

**Comprehensive verification pipeline:**
- File: `src/Stage_4/verify_koppen_labelling.py`
- **28 tests**, 26 passed (92.9%)
- Verified data integrity, Köppen validity, aggregation correctness, multi-assignment logic
- Confirmed: 22,473 total assignments > 11,680 unique plants (multi-assignment working)

**Only 2 failures:**
- 20 plants (0.17%) with "Ocean" top zone not assigned to tiers (aquatic species - edge case)
- 20 single-zone plants incorrectly in multiple tiers (also Ocean-related)

### Implementation Files

**Data files:**
1. `data/stage1/worldclim_occ_samples_with_koppen.parquet` (31M occurrences + Köppen zones)
2. `data/stage4/plant_koppen_distributions.parquet` (11,680 plants + Köppen distributions)
3. `model_data/outputs/perm2_production/perm2_11680_with_koppen_tiers_20251103.parquet` (final integrated dataset)

**Scripts:**
1. `src/Stage_4/assign_koppen_zones.py` (assign zones to occurrences)
2. `src/Stage_4/aggregate_koppen_distributions.py` (aggregate to plant level)
3. `src/Stage_4/analyze_koppen_tiers.py` (analyze distributions, recommend tiers)
4. `src/Stage_4/integrate_koppen_to_plant_dataset.py` (merge into main dataset)
5. `src/Stage_4/verify_koppen_labelling.py` (comprehensive verification)

---

## Output Format

### Full Profile Display

```
GUILD COMPATIBILITY PROFILE
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

INDEPENDENCE & COMPATIBILITY
  1. Pathogen Independence:       6.4%  ⚠ Many shared pathogens
  2. Pest Independence:         100.0%  ✓ Few shared herbivores
  3. Growth Strategy Compat:    100.0%  ✓ Compatible CSR strategies

BENEFICIAL INTERACTIONS
  4. Insect Pest Control:        99.0%  ✓ Excellent biocontrol
  5. Fungal Disease Control:      0.0%  ⚠ No antagonist fungi
  6. Beneficial Fungi Networks:  82.5%  ✓ Good fungal sharing
  7. Phylogenetic Diversity:     16.7%  ⚠ Similar evolutionary lineages
  8. Structural Diversity:       21.3%  ⚠ Similar plant heights
  9. Pollinator Support:         99.0%  ✓ Excellent pollinator attraction

GUILD CHARACTERISTICS (not percentile-ranked)
  • Nitrogen: No N-fixing plants ⚠ (add legume recommended)
  • Soil pH: 6.0-6.5 (compatible ✓)

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
OVERALL COMPATIBILITY: 56.7/100 (based on 9 calibrated metrics)

Interpretation: This guild ranks at the 56.7th percentile compared
to 120,000 climate-stratified guilds in your climate zone (Humid Temperate).

STRENGTHS (>80th percentile):
  • Excellent pest independence (no shared herbivores)
  • Strong insect pest control (biocontrol networks)
  • Good beneficial fungi sharing (AMF, EMF, endophytes)
  • Excellent pollinator support

WEAKNESSES (<20th percentile):
  • Very low pathogen independence (many shared pathogens)
  • Low phylogenetic diversity (similar plant families)
  • Low structural diversity (similar heights)

RECOMMENDATIONS:
  ⚠ Add N-fixing species (legume, alder, etc.) for nitrogen cycling
  ⚠ Increase phylogenetic diversity (add plants from different families)
  ⚠ Add vertical layering (mix trees, shrubs, herbs)
  ⚠ Consider disease management for shared pathogens
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

### Simplified Display (Frontend/API)

```json
{
  "overall_score": 56.7,
  "climate_veto": false,
  "metrics": {
    "pathogen_independence": {"score": 6.4, "status": "warning"},
    "pest_independence": {"score": 100.0, "status": "good"},
    "growth_compatibility": {"score": 100.0, "status": "good"},
    "nitrogen_sufficiency": {"score": 0.0, "status": "warning"},
    "soil_compatibility": {"score": 100.0, "status": "good"},
    "insect_control": {"score": 99.0, "status": "good"},
    "disease_control": {"score": 0.0, "status": "warning"},
    "beneficial_fungi": {"score": 82.5, "status": "good"},
    "phylo_diversity": {"score": 16.7, "status": "warning"},
    "structural_diversity": {"score": 21.3, "status": "warning"},
    "pollinator_support": {"score": 99.0, "status": "good"}
  },
  "strengths": ["pest_independence", "insect_control", "beneficial_fungi", "pollinator_support"],
  "weaknesses": ["pathogen_independence", "nitrogen_sufficiency", "phylo_diversity", "structural_diversity"]
}
```

---

## Implementation Architecture

### Data Flow

```
INPUT: Guild of 2-10 plants (user-selected)
  ↓
[1] Load plant data (climate, traits, organisms, fungi)
  ↓
[2] Climate VETO filter (unchanged from 4.3)
  ↓  (if VETO → return with outlier plants)
  ↓
[3] Compute RAW scores for 11 components
  ↓
[4] Normalize to percentiles:
    - ALL components (N1-N6, P1-P6): Use calibrated percentiles (interpolation)
    - Calibration includes guilds of sizes 2-7, so scores comparable across sizes
  ↓
[5] Invert N1-N6: metric = 100 - percentile
  ↓
[6] Compute overall score: mean(1-11)
  ↓
OUTPUT:
  - overall_score: 56.7/100
  - metrics: {metric1: 6.4, metric2: 100.0, ...}
  - strengths: [list of metrics >80]
  - weaknesses: [list of metrics <20]
  - recommendations: [based on weaknesses]
```

### File Structure

**Calibration:**
- `src/Stage_4/calibrate_normalizations_simple.py` → Updated to store p1-p99 for 9 components
- `data/stage4/normalization_params_v3.json` → Updated with full percentile range

**Scoring:**
- `src/Stage_4/guild_scorer_v3.py` → Updated to:
  - Use percentile interpolation for all 11 components (not piecewise p5/p50/p95)
  - Invert N1-N6 when displaying
  - Remove weight constants
  - Compute simple mean for overall score
  - Remove tanh fallback (all components now use calibrated percentiles)

**Testing:**
- `src/Stage_4/test_guilds_v3.py` → Updated output format

---

## Migration from Document 4.3

### What Changes

**Removed:**
- Weight constants (0.35, 0.20, etc.)
- Positive/negative split
- Weighted aggregation
- Complex [-1, +1] scoring

**Added:**
- Direct percentile interpretation
- Unified 0-100 scale
- Simple mean aggregation
- Inverted display for N components

**Unchanged:**
- Climate VETO filter (F1)
- Raw score computation methods
- Component definitions (N1-N6, P1-P6)
- Data sources (all parquet files)

### What Stays Compatible

**Backend data structures:**
- All parquet files remain unchanged
- Component computation logic unchanged
- Calibration approach unchanged (just different output)

**Frontend integration:**
- API can still return JSON
- Climate veto logic identical
- Component details still available

---

## Calibration Specification

### Guild Sampling Strategy

**Variable-size approach (Updated 2025-11-03):**

```
10,000 guilds total with variable sizes (2-7 plants):

Guild size distribution (matching expected usage):
  - 2 plants: 10% (1,000 guilds) - companion pairs
  - 3 plants: 20% (2,000 guilds) - triads
  - 4 plants: 25% (2,500 guilds) - small polycultures
  - 5 plants: 25% (2,500 guilds) - medium polycultures
  - 6 plants: 15% (1,500 guilds) - large polycultures
  - 7 plants: 5% (500 guilds) - very large polycultures

All guilds sampled as climate-compatible:
  - Ensures realistic combinations
  - Matches user-facing Guild Builder constraints
  - Climate VETO filter ensures compatibility

Sampling method:
  - Climate compatibility pre-computed for all 11,638 plants
  - Random selection from compatible sets
  - Estimated time: ~3 min (guild generation) + ~17 min (scoring) = 20 min total
```

**Why variable sizes instead of fixed 5-plant?**

Previous approach (Document 4.3) used 100K fixed-size guilds. This created calibration mismatch:
- **Problem:** 5-plant calibration → User creates 10-plant guild → Pairwise scores off-scale
- **Solution:** Variable sizes (2-7) → Percentiles naturally account for size effects
- **Trade-off:** Smaller sample (10K vs 100K), but more representative of actual usage

### Percentile Storage

**Before (3 points):**
```json
{
  "n1": {
    "method": "percentile",
    "p5": 0.0,
    "p50": 0.096,
    "p95": 0.768
  }
}
```

**After (13 points for smooth interpolation):**
```json
{
  "n1": {
    "method": "percentile",
    "p1": 0.0,
    "p5": 0.0,
    "p10": 0.0,
    "p20": 0.0,
    "p30": 0.0,
    "p40": 0.0,
    "p50": 0.096,
    "p60": 0.096,
    "p70": 0.192,
    "p80": 0.288,
    "p90": 0.504,
    "p95": 0.768,
    "p99": 1.560,
    "n_samples": 100000
  }
}
```

### Interpolation Algorithm

```python
def raw_to_percentile(raw_value, component_key, norm_params):
    """
    Convert raw score to percentile using linear interpolation.

    Args:
        raw_value: Raw component score
        component_key: 'n1', 'p4', etc.
        norm_params: Loaded from normalization_params_v3.json

    Returns:
        percentile: 0-100 (e.g., 87.3 means 87.3rd percentile)
    """
    params = norm_params[component_key]

    # Percentile points: [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99]
    percentiles = [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99]
    values = [params[f'p{p}'] for p in percentiles]

    # Edge cases
    if raw_value <= values[0]:
        return 0.0  # Below p1 → 0th percentile
    if raw_value >= values[-1]:
        return 100.0  # Above p99 → 100th percentile

    # Linear interpolation between bracketing percentiles
    for i in range(len(values) - 1):
        if values[i] <= raw_value <= values[i + 1]:
            if values[i + 1] - values[i] > 0:
                fraction = (raw_value - values[i]) / (values[i + 1] - values[i])
                percentile = percentiles[i] + fraction * (percentiles[i + 1] - percentiles[i])
            else:
                percentile = percentiles[i]

            return percentile

    return 50.0  # Fallback (should not reach)


def display_metric(raw_value, component_key, norm_params, invert=False):
    """
    Convert raw score to display value.

    Args:
        raw_value: Raw component score
        component_key: 'n1', 'p4', etc.
        norm_params: Calibration parameters
        invert: If True, display 100-percentile (for N components)

    Returns:
        display_value: 0-100 score for display
    """
    percentile = raw_to_percentile(raw_value, component_key, norm_params)

    if invert:
        return 100.0 - percentile  # For N1-N6 (high raw = bad → low display)
    else:
        return percentile  # For P3-P6 (high raw = good → high display)
```

---

## Testing Strategy

### Test Guilds

**Guild 1: Bad (Acacia monoculture)**
- Expected: Low overall score (10-20/100)
- Expected metrics:
  - Pathogen Independence: 0-10 (many shared pathogens)
  - Phylo Diversity: 0-10 (same genus)

**Guild 2: Good (Taxonomically diverse)**
- Expected: Medium score (40-60/100)
- Expected metrics:
  - Pathogen Independence: 60-80
  - Phylo Diversity: 70-90

**Guild 3: Excellent (Native pollinator plants)**
- Expected: High score (60-80/100)
- Expected metrics:
  - Pollinator Support: 90-100
  - Beneficial Fungi: 70-90

### Validation Criteria

**Percentile interpretation:**
```python
# For calibrated components (N1-N6, P3-P6):
assert 0 <= percentile <= 100
assert percentile matches empirical rank in 100K guilds

# For fallback components (P1-P2):
assert 0 <= tanh_score <= 100
assert tanh_score increases with raw biocontrol/pathogen_control
```

**Overall score:**
```python
assert overall_score == mean([metric1, metric2, ..., metric11])
assert 0 <= overall_score <= 100
```

**Interpretability:**
```python
# User should understand:
# "This guild is at 56.7th percentile" = better than 56.7% of calibrated guilds
# "Pathogen Independence = 6.4%" = worse than 93.6% of guilds (inverted)
```

---

## Monte Carlo Calibration Specification

### Theoretical Search Space

**Guild combinations per tier (7-plant guilds):**

| Tier | Plant Pool | Max Combinations | Scientific Notation |
|------|-----------|------------------|---------------------|
| Tier 1: Tropical | 1,633 | 6,065,692,722,877,582,336 | 6.1 × 10¹⁸ |
| Tier 2: Mediterranean | 4,036 | 3,443,234,838,090,015,571,968 | 3.4 × 10²¹ |
| Tier 3: Humid Temperate | 8,619 | 699,373,566,463,067,092,418,560 | 7.0 × 10²³ |
| Tier 4: Continental | 4,367 | 5,980,842,112,938,224,386,048 | 6.0 × 10²¹ |
| Tier 5: Boreal/Polar | 1,059 | 290,543,683,745,353,920 | 2.9 × 10¹⁷ |
| Tier 6: Arid | 2,759 | 239,620,050,697,873,293,312 | 2.4 × 10²⁰ |

**Total: 7.1 × 10²³ possible guilds across all tiers**

Even the smallest tier (Boreal/Polar) has 10¹⁷ combinations - effectively infinite for sampling purposes.

### Statistical Sample Size Justification

**Bootstrap Literature (Efron & Tibshirani, 1993):**
- Book: "An Introduction to the Bootstrap" (Chapman & Hall/CRC)
- Minimum recommendation: **1,000 samples** for percentile confidence intervals
- Equation 13.5 (p. 171): Percentile bootstrap method

**Order Statistics for Tail Percentiles:**
- For p01 estimation: need n × 0.01 ≥ 50 observations → n ≥ 5,000
- For p99 estimation: need n × 0.99 ≥ 50 observations → n ≥ 51
- Tail percentiles are the bottleneck

**Finite Population Correction:**
- FPC formula: n_adj = n₀ / (1 + (n₀-1)/N)
- Result: **No correction needed** - all tiers have N >> 10²⁰
- Sampling fractions << 0.001% (effectively random sampling)

### Three Calibration Options

**Option 1: Production (Good Quality)**
```
Sample Size: 10,000 guilds per tier × 6 tiers = 60,000 total
Statistical Power:
  - 100 observations at p01 tail (10K × 0.01 = 100)
  - Robust percentile estimation (bootstrap best practice)
  - Equal precision across all climate contexts
Computational Cost:
  - ~2 hours with optimized P1/P2 code
  - ~10 guilds/sec processing rate
Justification:
  - Exceeds Efron & Tibshirani minimum (1K) by 10×
  - Meets order statistics requirement (50 obs at p01)
  - Bootstrap literature best practice (5K-10K samples)
```

**Option 2: Budget-Constrained (Acceptable)**
```
Sample Size: 5,000 guilds per tier × 6 tiers = 30,000 total
Statistical Power:
  - 50 observations at p01 tail (5K × 0.01 = 50)
  - Minimum acceptable for tail estimation
  - Equal precision across tiers
Computational Cost:
  - ~1 hour runtime
Justification:
  - Exceeds Efron & Tibshirani minimum (1K) by 5×
  - Meets minimum order statistics requirement
```

**Option 3: Maximum Quality (Publication-Grade) ⭐ RECOMMENDED**
```
Sample Size: 20,000 guilds per tier × 6 tiers = 120,000 total
Statistical Power:
  - 200 observations at p01 tail (20K × 0.01 = 200)
  - Excellent tail behavior and rare percentile stability
  - Very high confidence across full distribution
  - Publication-quality percentile estimates
Computational Cost:
  - ~4 hours runtime (can run overnight)
  - Manageable one-time calibration cost
Justification:
  - Exceeds Efron & Tibshirani minimum (1K) by 20×
  - 4× better than order statistics requirement
  - Industry best practice for robust distribution estimation
  - Future-proof: supports finer percentile granularity if needed
```

### Recommended Implementation: Option 3

**Rationale for Maximum Quality:**

1. **One-Time Calibration**: Guild compatibility calibration is performed once and reused indefinitely. The 4-hour investment is negligible compared to the value of accurate, defensible percentiles.

2. **Scientific Rigor**: With 200 observations at p01 tail, we can confidently report:
   - "Based on Monte Carlo simulation of 120,000 climate-stratified guilds"
   - "Percentile estimates are robust to ±0.1 percentile points (95% CI)"
   - Publication-ready methodology

3. **Rare Guild Detection**: Users creating exceptional guilds (p99+) will get accurate rankings. With 20K samples:
   - p99 → 200 guilds better (clear benchmark)
   - p99.5 → 100 guilds better
   - p99.9 → 20 guilds better (still statistically meaningful)

4. **Climate Equity**: Equal 20K samples across all tiers ensures:
   - Users in Boreal/Polar (smallest tier) get same precision as Humid Temperate
   - No tier receives preferential treatment
   - Fair percentile comparisons regardless of user location

5. **Future Extensions**: 120K guild database supports future research:
   - Conditional percentiles (e.g., "guilds with N-fixers")
   - Subgroup analysis by plant traits
   - Alternative aggregation methods

### Two-Stage Calibration Strategy

**Stage 1: 2-Plant Pairwise Calibration (Plant Doctor & Recommendation Engine)**

Sample 20,000 random **2-plant pairs** per tier (120K total pairs):

**Theoretical search space (2-plant pairs):**
| Tier | Plant Pool | C(n,2) Combinations |
|------|-----------|---------------------|
| Tier 1: Tropical | 1,633 | 1,332,528 |
| Tier 2: Mediterranean | 4,036 | 8,142,630 |
| Tier 3: Humid Temperate | 8,619 | 37,139,271 |
| Tier 4: Continental | 4,367 | 9,533,161 |
| Tier 5: Boreal/Polar | 1,059 | 560,211 |
| Tier 6: Arid | 2,759 | 3,804,661 |
| **Total** | | **60,512,462 pairs** |

**Why 2-plant calibration first:**
1. **Plant Doctor functionality**: Quick evaluation of biocontrol pairings (e.g., trap crop + protected plant)
2. **Recommendation engine**: "Add plant X to complement plant Y"
3. **Computational efficiency**: 2-plant guilds ~50× faster than 7-plant (no O(n²) loops)
4. **Pairwise components reused**: P1/P2 pairwise scores computed in Stage 1 → cached for Stage 2

**Computational cost:** ~4 minutes (500 guilds/sec × 120K = 240 sec)

**Stage 2: 7-Plant Guild Calibration (Guild Builder Benchmark)**

Sample 20,000 random **7-plant guilds** per tier (120K total guilds):

**Why 7-plant benchmark:**
1. **Guild Builder default**: Users see "Your 3-plant guild scores at 45th percentile vs. 7-plant benchmark"
2. **Shows potential**: Lower diversity → lower percentiles (encourages adding plants)
3. **Tradeoff visibility**: More plants = more diversity/biocontrol, but also more pathogen overlap
4. **Pairwise reuse**: Many P1/P2 calculations already cached from Stage 1

**Computational cost:** ~2 hours (10 guilds/sec × 120K = 12,000 sec)

**Total calibration time:** Stage 1 (4 min) + Stage 2 (2 hours) = **~2 hours** (can run overnight)

### Implementation Pseudocode

**Stage 1: 2-Plant Calibration**

```python
import random
import json
from pathlib import Path

# Load dataset with Köppen tiers
plants = load_dataset('perm2_11680_with_koppen_tiers_20251103.parquet')

calibration_2plant = {}

for tier_name in ['tier_1_tropical', 'tier_2_mediterranean', 'tier_3_humid_temperate',
                   'tier_4_continental', 'tier_5_boreal_polar', 'tier_6_arid']:

    # Filter plants in this tier
    tier_plants = plants[plants[tier_name] == True]
    print(f"{tier_name}: {len(tier_plants)} plants")

    tier_pairs = []

    # Sample 20,000 random 2-plant pairs
    for i in range(20000):
        # Random sample without replacement
        pair = tier_plants.sample(n=2)

        # Compute all 9 raw component scores
        raw_scores = compute_guild_scores(pair)

        tier_pairs.append(raw_scores)

    # For each component, compute percentiles
    component_percentiles = {}

    for component in ['n1_raw', 'n2_raw', 'n4_density',  # n4 uses conflict density
                      'p1_raw', 'p2_raw', 'p3_raw', 'p4_raw', 'p5_raw', 'p6_raw']:

        values = [pair[component] for pair in tier_pairs]
        percentiles = compute_percentiles(values, [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99])

        component_percentiles[component] = percentiles

    calibration_2plant[tier_name] = component_percentiles

# Save Stage 1 results
with open('data/stage4/normalization_params_2plant.json', 'w') as f:
    json.dump(calibration_2plant, f, indent=2)

print(f"Stage 1 complete: 120,000 pairs processed (~4 minutes)")
```

**Stage 2: 7-Plant Calibration**

```python
calibration_7plant = {}

for tier_name in ['tier_1_tropical', 'tier_2_mediterranean', 'tier_3_humid_temperate',
                   'tier_4_continental', 'tier_5_boreal_polar', 'tier_6_arid']:

    tier_plants = plants[plants[tier_name] == True]
    print(f"{tier_name}: {len(tier_plants)} plants")

    tier_guilds = []

    # Sample 20,000 random 7-plant guilds
    for i in range(20000):
        guild = tier_plants.sample(n=7)

        # Compute all 9 raw component scores
        # Note: Many P1/P2 pairwise calculations can reuse cached results from Stage 1
        raw_scores = compute_guild_scores(guild)

        tier_guilds.append(raw_scores)

    # For each component, compute percentiles
    component_percentiles = {}

    for component in ['n1_raw', 'n2_raw', 'n4_density',  # n4 uses conflict density
                      'p1_raw', 'p2_raw', 'p3_raw', 'p4_raw', 'p5_raw', 'p6_raw']:

        values = [guild[component] for guild in tier_guilds]
        percentiles = compute_percentiles(values, [1, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99])

        component_percentiles[component] = percentiles

    calibration_7plant[tier_name] = component_percentiles

# Save Stage 2 results
with open('data/stage4/normalization_params_7plant.json', 'w') as f:
    json.dump(calibration_7plant, f, indent=2)

print(f"Stage 2 complete: 120,000 guilds processed (~2 hours)")
```

**Key Implementation Notes:**

1. **N4 uses conflict density** (`conflicts / max_pairs`), not raw conflict sum
   - Makes scores comparable across 2-plant vs 7-plant guilds
   - Calibration percentiles based on density metric

2. **Separate calibration files** for 2-plant and 7-plant
   - Plant Doctor uses `normalization_params_2plant.json`
   - Guild Builder uses `normalization_params_7plant.json`

3. **P1/P2 caching opportunity** (optional optimization)
   - Store pairwise biocontrol/pathogen scores from Stage 1
   - Reuse when computing 7-plant guilds in Stage 2
   - Can reduce Stage 2 runtime by ~30%

### Computational Estimates

**Stage 1 (2-Plant Pairs):**
- Processing rate: ~500 pairs/sec (fast, minimal pairwise loops)
- Total time: 120,000 pairs / 500 pairs/sec = 240 seconds = **4 minutes**

**Stage 2 (7-Plant Guilds):**
- Processing rate: ~10 guilds/sec (P1/P2 pairwise bottleneck)
- Total time: 120,000 guilds / 10 guilds/sec = 12,000 seconds = **2 hours**
- With P1/P2 caching: potentially reduced to ~1.5 hours

**Total Calibration Time:**
- Sequential: Stage 1 (4 min) + Stage 2 (2 hours) = **~2 hours**
- Can run overnight or during low-activity period
- One-time calibration; results reused indefinitely
- Run in background with `nohup`

### Output Artifacts

**Stage 1 File:** `data/stage4/normalization_params_2plant.json`

**Stage 2 File:** `data/stage4/normalization_params_7plant.json`

**Structure (both files):**
```json
{
  "tier_1_tropical": {
    "n1_raw": {"p01": 0.02, "p05": 0.05, ..., "p99": 0.95},
    "n2_raw": {"p01": 0.03, "p05": 0.07, ..., "p99": 0.92},
    "n4_density": {"p01": 0.01, "p05": 0.03, ..., "p99": 0.88},
    "p1_raw": {"p01": 0.00, "p05": 0.01, ..., "p99": 0.92},
    "p2_raw": {"p01": 0.00, "p05": 0.02, ..., "p99": 0.85},
    "p3_raw": {"p01": 0.05, "p05": 0.10, ..., "p99": 0.95},
    "p4_raw": {"p01": 0.20, "p05": 0.35, ..., "p99": 0.98},
    "p5_raw": {"p01": 0.10, "p05": 0.25, ..., "p99": 0.90},
    "p6_raw": {"p01": 0.01, "p05": 0.04, ..., "p99": 0.88}
  },
  "tier_2_mediterranean": { ... },
  ...
  "tier_6_arid": { ... }
}
```

**Size:** ~40 KB each (6 tiers × 9 components × 13 percentiles × ~60 bytes/number)

**Usage:**
- `normalization_params_2plant.json` → Plant Doctor, recommendation engine
- `normalization_params_7plant.json` → Guild Builder benchmark comparisons

### Validation Checks

**Post-calibration verification:**

1. **Percentile monotonicity**: p01 < p05 < p10 < ... < p95 < p99 for all components
2. **Reasonable ranges**: No percentile values are NaN or infinite
3. **Coverage**: All 9 components have percentiles for all 6 tiers
4. **Tier differences**: Percentile distributions differ between tiers (climate matters)
5. **Sample size check**: Exactly 20,000 guilds sampled per tier

```python
# Verification script
for tier_name, tier_data in calibration_results.items():
    for component, percentiles in tier_data.items():
        # Check monotonicity
        p_values = [percentiles[f'p{i:02d}'] for i in [1,5,10,20,30,40,50,60,70,80,90,95,99]]
        assert all(p_values[i] <= p_values[i+1] for i in range(len(p_values)-1))

        # Check no NaN/inf
        assert all(np.isfinite(v) for v in p_values)

print("✅ All validation checks passed")
```

---

## Documentation Status

**Supersedes:**
- Document 4.2: Guild Compatibility Framework (weighted approach)
- Document 4.3: Original Dataset Integration (positive/negative split)

**Complements:**
- Document 4.1: GloBI Data Structure (data sources unchanged)
- Document 4.5: Fungal Guild Classification (fungal data unchanged)

**Status:** Framework design complete

**Next Steps:**
1. Implement 2-stage calibration script (Stage 1: 2-plant, Stage 2: 7-plant)
2. Run Stage 1 calibration (~4 minutes) → `normalization_params_2plant.json`
3. Run Stage 2 calibration (~2 hours) → `normalization_params_7plant.json`
4. Update guild_scorer_v3.py to use appropriate calibration file based on context
5. Test with Plant Doctor (2-plant) and Guild Builder (7-plant benchmark)

**Completed (2025-11-03):**
- ✓ Identified P1/P2 performance bottleneck
- ✓ Optimized P1/P2 with dictionary-based lookups
- ✓ Analyzed guild-size dependency for all components
- ✓ Fixed CSR light preference thresholds (3.2 and 7.47 based on EIVE semantic bins)
- ✓ Fixed N4 to use conflict density (comparable across guild sizes)
- ✓ Designed 2-stage calibration: 2-plant pairs → 7-plant guilds
- ✓ Calculated theoretical combinations (60M pairs, 7×10²³ guilds)
- ✓ Justified 20K sample size per tier using Efron & Tibshirani (1993)
- ✓ Updated Document 4.4 with complete 2-stage calibration specification

**Last Updated:** 2025-11-03

# Stage 3.4: Calibration Analysis - Do Percentiles Improve Ecosystem Service Predictions?

**Date:** 2025-11-03
**Status:** Analysis complete
**Question:** Does using percentile-based classification improve the calibration (accuracy) of ecosystem service predictions?

---

## Executive Summary

**Answer: No, percentiles do not necessarily improve calibration. They improve consistency and interpretability, but may actually hurt calibration in some cases.**

**Key insight:** Percentile rank of C-score does not equal percentile rank of actual NPP. A plant at the 90th percentile for competitiveness might be at the 75th percentile for actual biomass production, or vice versa. Without ground-truth ecosystem service measurements, we cannot calibrate either approach.

**Recommendation:** Retain Shipley's theory-driven cutoffs for predictions, but **add percentile context for user communication**.

---

## What is "Calibration"?

**Calibration** = accuracy of predictions against ground truth.

For ecosystem services:
- **Well-calibrated NPP prediction:** If we label 100 plants as "Very High NPP", they should have actual NPP in the top ~10% of all plants
- **Poorly-calibrated NPP prediction:** If we label 100 plants as "Very High NPP", but half have mediocre actual NPP, the prediction is miscalibrated

**Critical limitation:** We have no actual NPP measurements for the 11,650 plants. We rely entirely on **CSR theory** (C-strategists have high NPP) validated by literature.

---

## Current Approach: Shipley's Theory-Driven Cutoffs

### Logic

**NPP prediction (herbaceous):**
```r
if (C >= 60) return("Very High")  # Top-tier competitors
if (C >= 50) return("High")       # Strong competitors
if (S >= 60) return("Low")        # Stress-tolerant (slow-growing)
return("Moderate")
```

**Underlying theory:**
- C-strategists allocate resources to **rapid growth** → high NPP
- S-strategists allocate resources to **stress tolerance** (thick leaves, slow turnover) → low NPP
- Cutoffs (60, 50) based on CSR literature patterns (Grime 1977, Pierce et al. 2016, Shipley 2025)

### Calibration Basis

**Not arbitrary** - based on:
1. **Mechanistic understanding**: LA, LDMC, SLA (traits used to calculate CSR) have known relationships to NPP from hundreds of studies
2. **Empirical validation**: Pierce et al. (2016) validated StrateFy against independent CSR classifications
3. **Expert judgment**: Shipley's 40+ years of CSR research

**But:** No direct validation against actual NPP measurements for these 11,650 plants.

---

## Percentile-Based Approach: What Changes?

### Logic

**NPP prediction (percentile-based):**
```r
C_percentile <- get_percentile(C, user_climate_tier, 'C')
if (C_percentile >= 90) return("Very High")  # Top 10% of climate peers
if (C_percentile >= 75) return("High")       # Top 25% of climate peers
```

**Underlying assumption:**
- 90th percentile C-score → 90th percentile actual NPP
- 75th percentile C-score → 75th percentile actual NPP

**Is this assumption valid?** Unknown - requires actual NPP data.

---

## Does Percentile Rank of C Match Percentile Rank of NPP?

### Scenario 1: Linear Relationship (Percentiles Match)

If NPP scales linearly with C-score across the full range:

```
Plant A: C=30 (25th %ile) → NPP = 2 g/m²/day (25th %ile) ✓
Plant B: C=60 (90th %ile) → NPP = 8 g/m²/day (90th %ile) ✓
Plant C: C=80 (99th %ile) → NPP = 12 g/m²/day (99th %ile) ✓
```

**Result:** Percentile-based classification perfectly calibrated.

### Scenario 2: Nonlinear Relationship (Percentiles Don't Match)

If NPP has diminishing returns at high C-scores:

```
Plant A: C=30 (25th %ile) → NPP = 2 g/m²/day (10th %ile) ✗
Plant B: C=60 (90th %ile) → NPP = 6 g/m²/day (75th %ile) ✗
Plant C: C=80 (99th %ile) → NPP = 7 g/m²/day (85th %ile) ✗
```

**Result:** Percentile-based classification miscalibrated. Plant A has lower NPP than C-percentile suggests; Plant C has lower NPP than C-percentile suggests.

### Scenario 3: Threshold Effect (Strategy Matters More Than Score)

If NPP is primarily determined by C-dominance (C > S and C > R), not absolute C value:

```
Plant A: C=35, S=30, R=35 (C-dominant) → NPP = 7 g/m²/day (High) ✓
Plant B: C=60, S=20, R=20 (C-dominant) → NPP = 8 g/m²/day (High) ✓
Plant C: C=30, S=60, R=10 (S-dominant) → NPP = 1 g/m²/day (Low) ✓
```

**Result:** Shipley's qualitative approach (C-dominant → High) is better calibrated than percentile ranks.

### What Does the Literature Say?

**Grime (1977), Pierce et al. (2016), Shipley (2025):**
- CSR scores predict **qualitative differences** between strategies (C > S > R for NPP)
- **Within-strategy variation** is less well-characterized
- No evidence that 90th percentile C → 90th percentile NPP

**Trait-NPP literature (Reich et al. 1997, Wright et al. 2004):**
- SLA correlates with relative growth rate (r ~ 0.6-0.7)
- But relationship is **nonlinear** and **climate-dependent**
- High-SLA plants in nutrient-poor soils don't achieve predicted NPP

**Conclusion:** Likely **nonlinear or threshold relationship** (Scenarios 2-3), not linear (Scenario 1).

---

## Problem 1: Climate Stratification May Hurt Calibration

### Example: Boreal vs. Tropical NPP

**Boreal plant:**
- C=45 → 92nd percentile for boreal climate (harsh conditions)
- Percentile approach: "Very High NPP" (top 10% for climate)
- Actual NPP: ~3 g/m²/day (short growing season, cold temperatures)

**Tropical plant:**
- C=60 → 50th percentile for tropical climate (competitive environment)
- Percentile approach: "Moderate NPP" (average for climate)
- Actual NPP: ~9 g/m²/day (year-round growth, high temperatures)

**Result:** Percentile approach labels the boreal plant "Very High" and tropical plant "Moderate", but the tropical plant has **3× higher actual NPP**!

**Why this happens:**
- Climate-stratified percentiles measure **relative performance within climate**
- Ecosystem services require **absolute performance across climates**
- A "highly competitive boreal plant" still produces less biomass than an "average tropical plant"

### When Climate Stratification Helps

**User question:** "Which of these three UK-compatible plants is most competitive?"

**Candidates:**
- Plant A: C=45 (UK distribution: 70th percentile)
- Plant B: C=50 (UK distribution: 80th percentile)
- Plant C: C=40 (UK distribution: 60th percentile)

**Percentile approach:** B > A > C ✓ (correct ranking for UK context)

**Fixed cutoff approach:** All labeled "Moderate" (C < 60) ✗ (cannot differentiate)

**Conclusion:** Climate stratification helps for **within-climate recommendations**, but hurts for **cross-climate absolute service predictions**.

---

## Problem 2: Distributional Bias ≠ Calibration Error

### The S-Strategy Overrepresentation

**Observation:** S-strategists have mean 38.9% vs. 31.1% for C-strategists (European flora bias).

**Percentile argument:** "S ≥ 60 is at 75th percentile (common), not 90th percentile like C ≥ 60 (rare). We should use percentiles to make 'Very High' mean 'top 10%' consistently."

**Counter-argument:** The distributional bias reflects **ecological reality**, not measurement error:

1. **European flora is stress-adapted** (harsh winters, nutrient-poor soils)
2. **S-strategists are genuinely more common** in European ecosystems
3. **S=60 is less ecologically exceptional** than C=60 in European context

If we normalize to percentiles:
- S=88 (90th percentile) labeled "Very High stress-tolerance"
- S=60 (75th percentile) labeled "High stress-tolerance"

But a plant with S=88 is **extremely stress-tolerant** (thick leaves, very slow growth, alpine/arctic specialist). Labeling S=60 plants (moderately stress-tolerant temperate plants) as "High" might be **more accurate** than insisting on 90th percentile threshold.

**Key question:** Is S=60 actually "Very High" stress-tolerance, or is it "High" stress-tolerance?
- **Percentile view:** It's only 75th percentile, so it's "High" not "Very High"
- **Ecological view:** It's moderately stress-tolerant, so "High" is appropriate

**Without ground-truth stress-tolerance measurements, we cannot resolve this.**

---

## Problem 3: Loss of Cross-Strategy Comparability

### Shipley's Integrated Framework

**Current approach** uses C, S, R **jointly** to predict services:

**Decomposition:**
```r
if (R >= 60 || C >= 60) return("Very High")  # Fast litter turnover
if (S >= 60) return("Low")                   # Slow litter turnover
```

**Logic:** Decomposition is high when plants are either:
- **C-dominant:** Thin leaves, high nutrient content → fast decomposition
- **R-dominant:** Short-lived organs, rapid turnover → fast decomposition
- **S-dominant:** Thick leaves, recalcitrant compounds → slow decomposition

This is a **mechanistic prediction** based on CSR theory, not a statistical pattern.

### Percentile Approach Breaks This

**Percentile version:**
```r
C_pct <- get_percentile(C, tier, 'C')
R_pct <- get_percentile(R, tier, 'R')
S_pct <- get_percentile(S, tier, 'S')

if (C_pct >= 90 || R_pct >= 90) return("Very High")
if (S_pct >= 90) return("Low")
```

**Problem:** What if a plant has C=60 (90th %ile), R=50 (70th %ile), S=20 (20th %ile)?

**Percentile logic:** "Very High decomposition" (C ≥ 90th %ile)

**But:** The moderate R and low S suggest this is a **C-dominant specialist** with thick leaves for competitive dominance, not fast turnover. Actual decomposition might be **moderate**, not "Very High".

**Shipley's cutoff logic:** C=60 and R<60 → might return "High" (not "Very High") depending on other conditions.

**Conclusion:** The **joint use of C, S, R** in Shipley's framework is mechanistically grounded. Converting each to independent percentiles loses this integration.

---

## What Would Actually Improve Calibration?

### Option 1: Ground-Truth Measurements (Ideal but Infeasible)

**Method:**
1. Measure actual NPP, decomposition, nutrient cycling for 200-500 species (field experiments)
2. Fit regression models: `actual_NPP ~ C + S + R + climate + height + family + ...`
3. Find cutoffs that predict actual service percentiles:
   ```python
   # Example: Find C threshold for 90th percentile NPP
   model = fit_npp_model(field_data)
   C_threshold = find_threshold(model, target_NPP_percentile=90, climate='temperate')
   # Result: C >= 58 predicts 90th percentile NPP in temperate climates
   ```
4. Update cutoffs to be empirically calibrated

**Barriers:**
- **Cost:** $500K-$1M for multi-year field experiments
- **Time:** 3-5 years for ecosystem service data
- **Scope:** Cannot measure 11,650 species (sample 200-500, model the rest)

### Option 2: Literature Meta-Analysis (Feasible)

**Method:**
1. Systematic literature review: studies measuring NPP/decomposition + CSR scores
2. Extract paired data (C score, actual NPP) from published studies
3. Fit meta-regression across studies:
   ```
   log(NPP) ~ C + S + R + climate + phylogeny + random(study)
   ```
4. Estimate CSR thresholds from fitted relationship

**Precedent:**
- Wright et al. (2004) GLOPNET database (trait-function relationships)
- TRY database trait-ecosystem function analyses

**Feasibility:** 2-3 months for a systematic review, requires access to paywalled papers

### Option 3: Proxy Validation (Moderate Feasibility)

**Method:**
1. Use **TRY database** traits known to correlate with NPP:
   - Leaf nitrogen content (TRY TraitID 14) → correlates with NPP
   - Specific leaf area (TRY TraitID 3) → used in C score calculation
   - Leaf lifespan (TRY TraitID 59) → inverse predictor of NPP
2. Test whether Shipley's cutoffs predict these proxies:
   ```python
   # Do plants with C >= 60 have higher leaf N than C < 60 plants?
   high_C = plants[plants['C'] >= 60]['leaf_N']
   low_C = plants[plants['C'] < 60]['leaf_N']
   t_test(high_C, low_C)  # Expect significant difference
   ```
3. If cutoffs don't align with proxies, recalibrate

**Feasibility:** 1-2 weeks (TRY data already loaded in Stage 1)

---

## Hybrid Approach: Retain Cutoffs, Add Percentile Context

### Recommendation

**For ecosystem service predictions (backend logic):**
- **Keep Shipley's theory-driven cutoffs** (C ≥ 60, S ≥ 60, etc.)
- These are based on decades of CSR literature and mechanistic understanding
- No evidence that percentiles would improve accuracy

**For user communication (frontend display):**
- **Add percentile context** to help users interpret ratings
- Example:
  ```
  NPP Rating: Very High
  Basis: C-score = 63 (90th percentile for Temperate climates)

  Interpretation: This plant's competitive ability ranks in the top 10%
  of temperate-climate plants, suggesting very high biomass production.
  ```

### Implementation

```python
def predict_ecosystem_service(plant, service_type, user_climate_tier):
    """
    Predict ecosystem service using Shipley's cutoffs.
    Add percentile context for user interpretation.
    """
    # STEP 1: Predict using theory-driven cutoffs (unchanged)
    if service_type == 'npp':
        if plant['life_form'] == 'woody':
            npp_score = plant['height_m'] * (plant['C'] / 100)
            rating = classify_woody_npp(npp_score)
        else:
            if plant['C'] >= 60:
                rating = "Very High"
            elif plant['C'] >= 50:
                rating = "High"
            elif plant['S'] >= 60:
                rating = "Low"
            else:
                rating = "Moderate"

    # STEP 2: Add percentile context for interpretation
    C_percentile = get_percentile(plant['C'], user_climate_tier, 'C')
    S_percentile = get_percentile(plant['S'], user_climate_tier, 'S')
    R_percentile = get_percentile(plant['R'], user_climate_tier, 'R')

    # Explain the rating
    if rating == "Very High":
        explanation = (
            f"This plant's competitiveness (C={plant['C']:.1f}) ranks at the "
            f"{C_percentile:.0f}th percentile for {user_climate_tier} climates, "
            f"indicating exceptional biomass production potential."
        )

    return {
        'rating': rating,
        'confidence': 'High',
        'C_score': plant['C'],
        'C_percentile': C_percentile,
        'S_percentile': S_percentile,
        'R_percentile': R_percentile,
        'explanation': explanation
    }
```

### Benefits

**Preserves calibration:**
- Shipley's cutoffs remain unchanged (theory-driven predictions)
- No risk of miscalibration from percentile artifacts

**Improves interpretability:**
- Users understand "90th percentile" means "top 10%"
- Can compare C=60 (90th %ile) vs S=60 (75th %ile) fairly
- Climate context helps ("exceptional for boreal climates")

**Enables recommendations:**
- "Your guild lacks R-strategists (mean R = 15th percentile)"
- "Add a plant with R > 75th percentile for disturbance resilience"

---

## Conclusion

**Does using percentiles improve calibration of ecosystem services?**

**No**, for the following reasons:

1. **No validation data**: We have no ground-truth NPP/decomposition measurements to calibrate against. Both approaches rely on CSR theory.

2. **Percentile rank of C ≠ percentile rank of NPP**: The relationship is likely nonlinear or threshold-based, not linear. A plant at 90th percentile for C might be at 75th percentile for actual NPP.

3. **Climate stratification hurts cross-climate comparisons**: A boreal plant at 90th percentile C still has lower absolute NPP than a tropical plant at 50th percentile C. Climate-stratified percentiles confuse "relative performance" with "absolute service delivery".

4. **Shipley's cutoffs are literature-validated**: Not arbitrary - based on decades of CSR research and mechanistic understanding.

5. **Joint CSR framework lost**: Shipley uses C, S, R together (e.g., decomposition high when R ≥ 60 **or** C ≥ 60). Converting to independent percentiles breaks this integration.

**However, percentiles DO improve:**
- **Consistency**: Same statistical meaning across C/S/R
- **User communication**: "90th percentile" is clearer than "Very High"
- **Recommendation logic**: Can target specific percentile thresholds

**Recommendation:** **Hybrid approach**
- Backend predictions: Keep Shipley's theory-driven cutoffs
- Frontend display: Add percentile context for user interpretation
- Best of both worlds: Preserve calibration, improve communication

---

## Next Steps

If you want to improve actual calibration (not just presentation):

**Priority 1: Proxy Validation (2 weeks)**
- Use TRY database traits (leaf N, leaf lifespan) as NPP proxies
- Test whether Shipley's cutoffs align with these proxies
- Recalibrate cutoffs if misalignment found

**Priority 2: Literature Meta-Analysis (2-3 months)**
- Systematic review of studies with CSR scores + measured ecosystem services
- Fit meta-regression to estimate CSR-service relationships
- Update cutoffs based on empirical evidence

**Priority 3: Field Validation (3-5 years, $500K+)**
- Measure actual NPP, decomposition, nutrient cycling for 200-500 species
- Build calibrated prediction models
- Gold-standard validation (long-term goal)

**For now:** Implement hybrid approach (retain cutoffs, add percentile context) as a low-cost improvement to user communication without risking calibration accuracy.

# Stage 2 — XGBoost Modelling Overview

## Purpose
- **Objective**: transition from Stage 1 data products (traits, climate, soil, agroclim, phylogeny) to Stage 2 axis models using XGBoost.
- **Scope**: focus on the 1 084-species modelling shortlist; encyclopedia-scale (11.6 k) tables are out-of-scope for this round.
- **Model family**: XGBoost regressors only; no Random Forest reruns for Stage 2.
- **Validation**: retain canonical 10-fold CV with shuffled species, but skip LOSO and spatial blocks.

## Inputs & Preparation
- **Traits & environment**: `model_data/inputs/modelling_master_20251022.{parquet,csv}` (log traits, imputed gaps, climate/soil/agroclim quantiles, `p_phylo_*`, `sla_source` provenance).
- **Axis references**: see Stage 1 summaries (`1.7`, `1.9`, `1.10`) for derivation of `log*` targets and species coverage.
- **Feature assembly** (per axis):
  1. Filter the modelling master to species with non-missing axis scores.
  2. Select predictor columns (traits, climate, soil, agroclim, phylo) and rename the axis value to `y`.
  3. Write one CSV per axis to `model_data/inputs/stage2_features/<AXIS>_features_YYYYMMDD.csv`.
- **Species column**: preserve `species_normalized` for fold diagnostics.

## Modelling Command
- **Script**: `src/Stage_2/xgb_kfold.py` (new Stage 2 helper; simplified from legacy `Stage_3RF_XGBoost/analyze_xgb_hybrid_interpret.py`).
- **Hyperparameter search**: per axis the script now sweeps **three learning rates** and **three tree counts** (up to 5 000 trees) when supplied via `--learning_rates` and `--n_estimators_grid`. Each combination shares the same depth/subsample settings; the best (highest mean R², tie-broken by lowest RMSE) is chosen automatically and logged.
- **Anti-leakage safeguards**: inside every CV fold the training split is standardised (mean/SD) before fitting; those statistics are then applied to the held-out species, preventing any peek at validation data. Columns with no finite values are dropped prior to modelling.
- **Baseline defaults**: if no grid is provided the runner falls back to the canonical settings (`n_estimators=600`, `learning_rate=0.05`, `max_depth=6`, `subsample=0.8`, `colsample_bytree=0.8`).
- **Example**:
  ```bash
  conda run -n AI python src/Stage_2/xgb_kfold.py \
    --features_csv model_data/inputs/stage2_features/T_features_20251022.csv \
    --axis T \
    --out_dir model_data/outputs/stage2_xgb/T_20251022 \
    --cv_folds 10 \
    --learning_rates 0.03,0.05,0.08 \
    --n_estimators_grid 1500,3000,5000 \
    --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
    --pd_pairs "logLDMC:wc2.1_30s_bio_12_q50,logSM:wc2.1_30s_bio_4_q50"
  ```
- **GPU toggle**: `--gpu true` when CUDA is available; leave `false` for CPU.

## Outputs
- `xgb_<AXIS>_cv_metrics.json` → aggregate R²/RMSE/MAE summary.
- `xgb_<AXIS>_cv_metrics_kfold.json` → same metrics with explicit strategy flag.
- `xgb_<AXIS>_cv_grid.csv` → full hyperparameter grid (learning rate, tree count, metrics per combo).
- `xgb_<AXIS>_cv_predictions_kfold.csv` → row-level fold predictions/residuals (species-aware).
- `xgb_<AXIS>_shap_importance.csv` → mean absolute contribution for each predictor.
- Optional PD files (`xgb_<AXIS>_pd1_*`, `xgb_<AXIS>_pd2_*`) when variables are requested.
- `xgb_<AXIS>_model.json` & `xgb_<AXIS>_scaler.json` → serialized booster and z-score parameters for downstream reuse.
- Per-axis write-ups: `2.1_L_Axis_XGBoost.md`, `2.2_T_Axis_XGBoost.md`, `2.3_M_Axis_XGBoost.md`, `2.4_N_Axis_XGBoost.md`, `2.5_R_Axis_XGBoost.md`.

## Verification Plan
- **Data readiness**
  - Feature CSV: no missing `y`; all numeric traits (leaf area, Nmass, LDMC, SLA, seed mass, height) strictly positive or in valid fraction ranges.
  - Confirm redundant columns (raw LMA/SLA, sample counts, `_imputed_flag/_sd`) are absent so the model only sees canonical predictors.
- **Run audit**
  - Capture console output in `logs/stage2_xgb/YYYYMMDD/<AXIS>.log` and ensure the 3×3 hyperparameter grid executes without failure.
  - Inspect `xgb_<AXIS>_cv_grid.csv` to verify the selected combo matches the highest mean R² (tie-broken by RMSE).
- **Metric sanity**
  - Compare k-fold metrics against canonical expectations (`R² ≥ 0.55` for T/M/L, `≥ 0.45` for N, `≥ 0.35` for R) and flag deviations > 0.10.
  - Recalculate MAE/RMSE from `xgb_<AXIS>_cv_predictions_kfold.csv` to confirm they match the JSON summary.
- **Top predictors & residuals**
  - Review `xgb_<AXIS>_shap_importance.csv` to ensure the top 15 features align with ecological expectations (no provenance columns).
  - Check residual distribution for heavy tails (`|residual| > 3 × sd`) and cross-reference with Stage 1 trait diagnostics if anomalies persist.
- **Artefact integrity**
- Confirm `xgb_<AXIS>_model.json` and `xgb_<AXIS>_scaler.json` are produced and the scaler includes only the retained predictor list.

## Verification Log
- Latest run (2025-10-22): `logs/stage2_xgb/20251022/verification_summary.md`.

## Next Steps
- Automate feature-table generation (Python helper in `src/Stage_2`) to guarantee reproducible axis CSVs.
- Define a Makefile target (`stage2_xgb_all`) that iterates axes (T, M, L, N, R) and writes outputs under `model_data/outputs/stage2_xgb/<AXIS>_YYYYMMDD/`.
- Draft Stage 2 reporting templates summarizing CV metrics, feature importances, and PD insight for integration with Stage 3 documentation.
- Add regression tests that confirm column naming conventions (underscores) so future runs do not drop partial-dependence pairs silently.

---

## Stage 2 Experimental Configurations (2025-10-24)

### Motivation
Stage 1 XGBoost experiments revealed that **full environmental quantiles (q05/q50/q95/iqr) degrade performance by 55-58%** compared to median-only (q50) features (see Perm7 vs Perm3 in `1.7a_XGBoost_Experiments.md`). This finding raises the question: does q50 sufficiency generalize to Stage 2 EIVE axis prediction?

### Experimental Design

We test two q50-only configurations to isolate the effect of EIVE features on axis prediction:

| Config | Dataset | EIVE Features | Phylo Codes | Environmental | Columns |
|--------|---------|---------------|-------------|---------------|---------|
| **Full (Baseline)** | `modelling_master_20251022` | ✅ p_phylo_* | ✅ All | q05/q50/q95/iqr | ~588 |
| **Config A** | `modelling_master_q50_with_eive_20251024` | ✅ p_phylo_* | ✅ All | **q50 only** | ~137 |
| **Config B** | `modelling_master_q50_no_eive_20251024` | ❌ None | ⚠️ depth/terminal only | **q50 only** | ~129 |

**Key differences:**
- **Config A:** Tests q50 sufficiency while preserving ecological signal (p_phylo_T/M/L/N/R)
- **Config B:** Tests pure trait + environment axis prediction without EIVE features (mirrors Perm3 philosophy)

### Hypotheses

**H1 (q50 Sufficiency):** If Config A performance ≥ Full quantiles baseline, then median environmental values are sufficient for axis prediction (variability metrics add noise).

**H2 (EIVE Necessity - Strong Expectation):**
- **Config A >> Config B is EXPECTED** - EIVE features should easily outperform no-EIVE
- **Why:** We are **predicting EIVE axis values as targets** (T/M/L/N/R), not imputing traits
- p_phylo_* features should be essential predictors (expected R² delta: 20-40%)
- Config B serves as control to quantify p_phylo contribution vs trait-environment alone

**Critical Distinction from Stage 1:**
- **Stage 1 (trait imputation):** EIVE features were HARMFUL (Perm3 beat Perm1 by 3-16%)
  - Traits and environment are the core signal; EIVE adds noise
- **Stage 2 (axis prediction):** EIVE features should be ESSENTIAL
  - EIVE axes ARE the targets - p_phylo_* directly predicts what we're modeling
- **Fundamental difference:** Using EIVE to predict traits vs using traits to predict EIVE

### Feature Assembly Updates

**CORRECTED DESIGN (mirroring original L axis experiment):**

Both configs include ALL p_phylo_* features. The ONLY difference is raw cross-axis EIVEres_*.

1. **Config A (WITH cross-axis EIVE):**
   - Load `modelling_master_q50_with_eive_20251024.parquet`
   - Includes: traits, logs, TRY alternates, **ALL p_phylo_*** (T/M/L/N/R), **ALL EIVEres_*** (T/M/L/N/R), env_q50
   - When generating axis-specific features (e.g., for L): exclude target EIVEres_L, keep other EIVEres (M/N/R/T)
   - 1,084 rows × 182 columns

2. **Config B (WITHOUT cross-axis EIVE):**
   - Load `modelling_master_q50_no_eive_20251024.parquet`
   - Includes: traits, logs, TRY alternates, **ALL p_phylo_*** (T/M/L/N/R), NO EIVEres, env_q50
   - Tests if p_phylo_* alone is sufficient (without raw cross-axis EIVE values)
   - 1,084 rows × 177 columns

### Expected Modelling Commands

**STEP 1: Generate feature tables for each axis**

You'll need to create feature CSVs from the master datasets, similar to how `L_features_20251024.csv` was created from `modelling_master_20251022.parquet`.

For each axis (T/M/L/N/R), create:
- `model_data/inputs/stage2_features/{AXIS}_features_q50_with_eive_20251024.csv` (from Config A)
- `model_data/inputs/stage2_features/{AXIS}_features_q50_no_eive_20251024.csv` (from Config B)

Key requirements:
- Join Config A/B with EIVE residuals, rename target axis to 'y'
- For Config A (WITH cross-axis): Include EIVEres_* for OTHER axes (e.g., for L: include EIVEres_M/N/R/T, exclude target EIVEres_L)
- For Config B (NO cross-axis): Exclude ALL EIVEres_*
- Both configs: KEEP ALL p_phylo_* features
- Drop provenance columns (*_source)

**STEP 2: Run XGBoost experiments**

**Config A example (T axis - WITH cross-axis EIVE):**
```bash
conda run -n AI python src/Stage_2/xgb_kfold.py \
  --features_csv model_data/inputs/stage2_features/T_features_q50_with_eive_20251024.csv \
  --axis T \
  --out_dir model_data/outputs/stage2_xgb/T_q50_with_eive_20251024 \
  --cv_folds 10 \
  --learning_rates 0.03,0.05,0.08 \
  --n_estimators_grid 1500,3000,5000 \
  --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
  --gpu true
```

**Config B example (T axis - WITHOUT cross-axis EIVE):**
```bash
conda run -n AI python src/Stage_2/xgb_kfold.py \
  --features_csv model_data/inputs/stage2_features/T_features_q50_no_eive_20251024.csv \
  --axis T \
  --out_dir model_data/outputs/stage2_xgb/T_q50_no_eive_20251024 \
  --cv_folds 10 \
  --learning_rates 0.03,0.05,0.08 \
  --n_estimators_grid 1500,3000,5000 \
  --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
  --gpu true
```

**Note:** Both configs use same pd_vars (including p_phylo_T). The difference is whether EIVEres_M/L/N/R are in the feature table.

### Comparison Metrics

For each axis (T/M/L/N/R), compare:

| Metric | Full Quantiles | Config A (q50 + EIVE) | Config B (q50, no EIVE) |
|--------|----------------|----------------------|-------------------------|
| R² (10-fold CV) | baseline | Δ vs baseline | Δ vs Config A |
| RMSE | baseline | Δ vs baseline | Δ vs Config A |
| Top-10 features | SHAP importance | SHAP importance | SHAP importance |
| Runtime | baseline | expected -30% | expected -35% |

**Decision criteria:**
- **Primary (q50 sufficiency):** If Config A ≥ 95% of baseline R²: adopt q50-only for production
- **Expected (EIVE necessity):** Config A should exceed Config B by R² ≥ 0.20 (strong EIVE signal)
  - If Config B within 5% of Config A: UNEXPECTED - would indicate trait-environment relationships capture EIVE redundantly
  - If Config A advantage < 10%: weak EIVE signal - investigate feature engineering
  - If Config A advantage > 30%: strong EIVE signal - confirms p_phylo_* features are critical

### Implementation Status

**Dataset Preparation:**
- ✅ Datasets documented in `1.10_Modelling_Master_Table.md` Section 4
- ✅ Dataset construction script: `scripts/build_stage2_q50_configs.py`
- ✅ Datasets built and verified (2025-10-24):
  - `model_data/inputs/modelling_master_q50_with_eive_20251024.{parquet,csv}` (1,084 × 182)
  - `model_data/inputs/modelling_master_q50_no_eive_20251024.{parquet,csv}` (1,084 × 177)
- ✅ Verification completed: `scripts/verify_stage2_q50_configs.py`
  - Row integrity: PASS
  - Trait bounds: PASS (extremes preserved from original)
  - p_phylo coverage: PASS (all 5 features fully populated)
  - Environmental: PASS (137 q50 columns, no q05/q95/iqr)
  - EIVE features: PASS (Config A: 10, Config B: 5)
  - Species alignment: PASS (identical 1,084 species)

**Implementation Status:**
- ✅ Feature table generation: `src/Stage_2/build_q50_features.py` (2025-10-25)
  - Generated 10 feature CSVs (5 axes × 2 configs)
  - Config A: 172 columns (traits + p_phylo + EIVEres cross-axis + env_q50)
  - Config B: 168 columns (traits + p_phylo + env_q50, NO EIVEres)
- ✅ All experiments completed (2025-10-25)
  - L, T, M, N, R axes: 10 experiments total (2 configs × 5 axes)

### Experimental Results (2025-10-25)

**R² Performance:**

| Axis | Full+EIVE | Full noEIVE | A (q50+EIVE) | B (q50 noEIVE) | Δ Full→A | Δ A→B | Δ FullNoEIVE→B |
|------|-----------|-------------|--------------|----------------|----------|-------|----------------|
| **L** | 0.635±0.032 | 0.605±0.042 | **0.629±0.042** | 0.586±0.038 | -0.006 | -0.043 | **-0.019** ⚠️ |
| **T** | 0.832±0.044 | 0.825±0.045 | **0.819±0.060** | 0.804±0.068 | -0.013 | -0.015 | **-0.021** ⚠️ |
| **M** | 0.653±0.079 | 0.609±0.079 | **0.666±0.066** ✓ | 0.597±0.074 | +0.013 | -0.069 | **-0.012** ⚠️ |
| **N** | 0.711±0.044 | 0.609±0.053 | **0.717±0.042** ✓ | 0.599±0.059 | +0.006 | -0.118 | **-0.010** ⚠️ |
| **R** | 0.582±0.082 | 0.542±0.093 | **0.559±0.093** | 0.484±0.109 | -0.023 | -0.075 | **-0.058** ⚠️ |

**Rank Accuracy (±1 EIVE rank):**

| Axis | Full+EIVE | Full noEIVE | A (q50+EIVE) | B (q50 noEIVE) | Δ FullNoEIVE→B |
|------|-----------|-------------|--------------|----------------|----------------|
| **L** | 89.5% | 88.0% | 88.7% | 87.2% | **-0.8%** |
| **T** | 97.8% | 97.5% | 97.5% | 97.0% | **-0.5%** (robust) |
| **M** | 89.9% | 89.0% | 89.8% | 87.5% | **-1.5%** |
| **N** | 86.2% | 80.7% | 86.9% | 80.1% | **-0.6%** |
| **R** | 87.8% | 87.2% | 88.0% | 84.8% | **-2.4%** ⚠️ |

**Key observations:**
- **Environmental dependency persists in rank accuracy**: Config B (q50 noEIVE) underperforms Full noEIVE across all axes
- **R axis most degraded**: -2.4 percentage points in ±1 rank accuracy, confirming strongest environmental dependence
- **T axis most robust**: Only -0.5 percentage points, reflecting climate-dominated prediction
- **N axis shows bimodal pattern**: Large EIVE effect on R² (+11.8%) but modest rank accuracy impact (-0.6%), suggesting EIVE improves prediction magnitude more than ordinal ranking

**Column definitions:**
- **Full+EIVE**: Full quantiles (q05/q50/q95/iqr) with p_phylo + cross-axis EIVEres (original baseline)
- **Full noEIVE**: Full quantiles with p_phylo, NO cross-axis EIVEres (original no-EIVE control)
- **A (q50+EIVE)**: q50 only with p_phylo + cross-axis EIVEres (tests H1: q50 sufficiency)
- **B (q50 noEIVE)**: q50 only with p_phylo, NO cross-axis EIVE res (tests environmental dependency)
- **Δ FullNoEIVE→B**: Critical comparison showing q50 performance WITHOUT cross-axis EIVE vs full quantiles

**L Axis Findings:**
- **H1 (q50 sufficiency)**: Config A within 1% of full quantiles (Δ = -0.006 R²) → **q50 is sufficient**
- **H2 (EIVE necessity)**: Config A exceeds Config B by Δ = +0.043 R² → cross-axis EIVE features add moderate value
- Hyperparameters: learning_rate=0.03, n_estimators=3000

**T Axis Findings:**
- **H1 (q50 sufficiency)**: Config A within 2% of full quantiles (Δ = -0.013 R²) → **q50 is sufficient**
- **H2 (EIVE necessity)**: Config A exceeds Config B by Δ = +0.015 R² → smaller EIVE effect (climate-dominated axis)
- Hyperparameters: learning_rate=0.05, n_estimators=1500

**M Axis Findings:**
- **H1 (q50 sufficiency)**: Config A **EXCEEDS** full quantiles by Δ = +0.013 R² → **q50 is superior** ✓
- **H2 (EIVE necessity)**: Config A exceeds Config B by Δ = +0.069 R² → moderate EIVE contribution
- Hyperparameters: learning_rate=0.03, n_estimators=1500

**N Axis Findings:**
- **H1 (q50 sufficiency)**: Config A **EXCEEDS** full quantiles by Δ = +0.006 R² → **q50 is superior** ✓
- **H2 (EIVE necessity)**: Config A exceeds Config B by Δ = +0.118 R² → **STRONG EIVE signal** ⚠️
  - Largest EIVE effect across all axes (11.8% R² improvement)
  - Cross-axis EIVE features critical for nutrient axis prediction
- Hyperparameters: learning_rate=0.03, n_estimators=3000

**R Axis Findings:**
- **H1 (q50 sufficiency)**: Config A within 4% of full quantiles (Δ = -0.023 R²) → **q50 is sufficient**
- **H2 (EIVE necessity)**: Config A exceeds Config B by Δ = +0.075 R² → moderate EIVE contribution
- Hyperparameters: learning_rate=0.03, n_estimators=5000

**Overall Summary:**

**H1 (q50 sufficiency): CONDITIONAL - depends on cross-axis EIVE presence** ⚠️
- **WITH cross-axis EIVE (Config A):**
  - M and N axes: q50 actually outperforms full quantiles (+0.013, +0.006)
  - L, T, R axes: q50 within 1-4% of full quantiles
  - **Conclusion**: When cross-axis EIVE features present, environmental variability metrics add noise
- **WITHOUT cross-axis EIVE (Config B):**
  - ALL axes show q50 < full quantiles (Δ ranges -0.010 to -0.058)
  - R axis particularly degraded: -0.058 R² (11% relative loss)
  - **Critical finding**: Full environmental quantiles provide compensatory signal when EIVE absent
  - Environmental variability metrics (q05/q95/iqr) capture spatial heterogeneity that substitutes for missing cross-axis EIVE information

**H2 (EIVE necessity): Variable by axis (Δ ranges 0.015 to 0.118)**
- Minimal for T (climate-dominated): +0.015 R²
- Moderate for L, M, R: +0.043 to +0.075 R²
- Critical for N (nutrient): +0.118 R² ⚠️
- Cross-axis EIVE features contribute 2-16% performance improvement

**Key Mechanistic Insight:**
Environmental quantiles serve two distinct roles:
1. **With EIVE features**: Quantiles add noise (q50 sufficient)
2. **Without EIVE features**: Quantiles compensate for missing cross-axis information via environmental heterogeneity proxies

This suggests full quantiles capture EIVE-like signal through environmental variability patterns, validating the ecological coherence between axes and their environmental drivers.

### References

- Stage 1 Perm7 finding: `results/summaries/hybrid_axes/phylotraits/Stage_1/1.7a_XGBoost_Experiments.md` Section 3a
- Master table configs: `results/summaries/hybrid_axes/phylotraits/Stage_1/1.10_Modelling_Master_Table.md` Section 4
- Dataset builder: `scripts/build_stage2_q50_configs.py`
- Dataset verifier: `scripts/verify_stage2_q50_configs.py`
- Original L axis experiment: `results/summaries/hybrid_axes/phylotraits/Stage_2/2.1_L_Axis_XGBoost.md`

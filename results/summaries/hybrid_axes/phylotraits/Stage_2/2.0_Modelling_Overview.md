# Stage 2 — XGBoost Modelling Overview

**Date:** 2025-10-29 (updated for Stage 1.10 production datasets)
**Status:** Two-tier modeling approach (1,084 for tuning, 11,680 for production)

---

## 1. Purpose

**Objective:** Predict EIVE axis values (T, M, L, N, R) from traits, environment, and phylogenetic features using XGBoost

**Two-tier approach:**
1. **Tier 1 (1,084 species):** Hyperparameter tuning with grid search → fast iteration
2. **Tier 2 (11,680 species):** Production modeling with optimal config → maximum coverage

**Model family:** XGBoost regressors only
**Validation:** 10-fold CV with shuffled species (no LOSO, no spatial blocks)

---

## 2. Input Datasets (Stage 1.10 Outputs)

### 2.1 Tier 1: Modelling Shortlist (1,084 species)

**Purpose:** Hyperparameter tuning (fast iteration, robust GBIF coverage)

**File:**
```
model_data/inputs/modelling_master_1084_20251029.parquet
model_data/inputs/modelling_master_1084_20251029.csv
```

**Dimensions:** 1,084 species × 741 features

**Coverage:**
| Feature Group | Coverage |
|--------------|----------|
| Traits (log) | 100% (1,084 / 1,084) |
| Phylo eigenvectors | 99.6% (1,078 / 1,084) |
| Phylo predictors (p_phylo) | 94.7% (1,026 / 1,084) |
| EIVE indicators | ~83% (900 / 1,084) |
| Environmental quantiles (full) | 100% (1,084 / 1,084) |
| Categorical traits | 29-79% |

**Selection criteria:**
- GBIF ≥30 georeferenced occurrences
- Median GBIF: 4,370 occurrences
- Strong environmental data extraction

**Documentation:** See `1.10_Modelling_Master_Table.md` Section 2.2

---

### 2.2 Tier 2: Full Production (11,680 species)

**Purpose:** Encyclopedia-scale EIVE prediction (apply optimal config from tier 1)

**File:**
```
model_data/outputs/perm2_production/perm2_11680_complete_final_20251028.csv
model_data/outputs/perm2_production/perm2_11680_complete_final_20251028.parquet
```

**Dimensions:** 11,680 species × 741 features (identical feature set to 1,084)

**Coverage:**
| Feature Group | Coverage |
|--------------|----------|
| Traits (log) | 100% (11,680 / 11,680) |
| Phylo eigenvectors | 99.6% (11,638 / 11,680) |
| Phylo predictors (p_phylo) | 94.0% (10,977 / 11,680) |
| EIVE indicators | 52.8% (6,165 / 11,680) |
| Environmental quantiles (full) | 100% (11,680 / 11,680) |
| Categorical traits | 29-79% |

**Prediction target:**
- 5,515 species (47.2%) lack observed EIVE → predict from traits + environment + phylogeny

**Use cases:**
- Pan-European trait database production
- Maximum coverage for rare/under-sampled species
- Phylogenetic comparative methods

**Documentation:** See `1.10_Modelling_Master_Table.md` Section 2.1

---

### 2.3 Unified Feature Inventory (741 features)

| Feature Group | Count | Description |
|--------------|-------|-------------|
| **Identifiers** | 2 | wfo_taxon_id, wfo_scientific_name |
| **Log traits** | 6 | logLA, logNmass, logLDMC, logSLA, logH, logSM |
| **Phylo eigenvectors** | 92 | phylo_ev1...phylo_ev92 (PCoA on VCV matrix) |
| **EIVE indicators** | 5 | EIVEres-L/T/M/N/R (observed values) |
| **Phylo predictors** | 5 | p_phylo_T/M/L/N/R (Shipley formula) |
| **Categorical traits** | 7 | woodiness, growth_form, habitat, leaf, phenology, pathway, mycorrhiza |
| **Environmental quantiles** | 624 | WorldClim (252) + SoilGrids (168) + Agroclim (204) — q05/q50/q95/iqr for 156 vars |
| **TOTAL** | **741** | Same features across both tiers |

**Categorical trait names:**
- `try_woodiness` (6 levels)
- `try_growth_form` (27 levels)
- `try_habitat_adaptation` (5 levels)
- `try_leaf_type` (6 levels)
- `try_leaf_phenology` (3 levels)
- `try_photosynthesis_pathway` (5 levels)
- `try_mycorrhiza_type` (6 levels)

**Environmental quantiles rationale:**

Full quantiles (q05, q50, q95, iqr) included despite Perm 4 rejection for Stage 1 trait imputation:

- **Stage 1 result:** Perm 4 (full quantiles) was 1.2% worse than Perm 2 (q50 only) for trait imputation with 3.29× longer runtime
- **Stage 2 hypothesis:** EIVE indicators represent environmental adaptation — variability features may capture:
  - Ecological plasticity (wide tolerance ranges)
  - Extreme environment adaptation (cold hardiness, drought resistance)
  - Niche breadth complementary to median conditions
- **Flexibility:** Models can test with/without variability features to determine if they improve EIVE prediction
- **Cost:** Storage overhead acceptable for final production datasets

See `1.10_Modelling_Master_Table.md` Section 4.1 for full analysis.

---

## 3. Two-Tier Modeling Workflow

### 3.1 Tier 1: Hyperparameter Tuning (1,084 species)

**Purpose:** Find optimal XGBoost configuration per axis using grid search

**Grid search parameters:**
- Learning rates: 3 values (e.g., `0.03, 0.05, 0.08`)
- Tree counts: 3 values (e.g., `1500, 3000, 5000`)
- **Total:** 9 combinations per axis

**Fixed parameters:**
- `max_depth=6`
- `subsample=0.8`
- `colsample_bytree=0.8`

**Selection criteria:**
- **Primary:** Highest mean R² across 10 folds
- **Tie-breaker:** Lowest RMSE

**Runtime:** ~20-30 minutes per axis on 1,084 species

**Output:**
- `xgb_<AXIS>_cv_grid.csv` → All 9 combinations with R²/RMSE/MAE
- Optimal config logged at top of grid

---

### 3.2 Tier 2: Production Modeling (11,680 species)

**Purpose:** Apply optimal config from tier 1 to full dataset

**Config source:** Use hyperparameters selected from tier 1 grid search

**Runtime:** ~60-90 minutes per axis on 11,680 species

**Output:**
- `xgb_<AXIS>_model.json` → Final model trained on 11,680 (10-fold CV)
- `xgb_<AXIS>_scaler.json` → Z-score parameters for production deployment
- `xgb_<AXIS>_cv_predictions_kfold.csv` → Row-level predictions/residuals
- `xgb_<AXIS>_shap_importance.csv` → Feature importance rankings

**Predictions:**
- EIVE values for 5,515 species lacking observed EIVE
- Uncertainty estimates from CV folds

---

## 4. Feature Assembly (Per Axis)

For each axis (T, M, L, N, R), create two feature tables from master datasets.

### 4.1 Tier 1 Feature Table (1,084 species)

```python
import pandas as pd

# Load modelling shortlist
shortlist = pd.read_parquet('model_data/inputs/modelling_master_1084_20251029.parquet')

# Specify axis (T, M, L, N, or R)
AXIS = 'T'

# Filter to species with non-missing axis value
axis_data = shortlist[shortlist[f'EIVEres-{AXIS}'].notna()].copy()
print(f"Axis {AXIS}: {len(axis_data)} species with observed EIVE")

# Rename target axis to 'y'
axis_data['y'] = axis_data[f'EIVEres-{AXIS}']

# Drop target axis column (prevent data leakage)
axis_data = axis_data.drop(columns=[f'EIVEres-{AXIS}'])

# Drop provenance columns (not needed for modeling)
provenance_cols = [c for c in axis_data.columns if '_source' in c]
if provenance_cols:
    axis_data = axis_data.drop(columns=provenance_cols)
    print(f"Dropped {len(provenance_cols)} provenance columns")

# Save feature table
output_path = f'model_data/inputs/stage2_features/{AXIS}_features_1084_20251029.csv'
axis_data.to_csv(output_path, index=False)
print(f"Saved: {output_path}")
print(f"Shape: {axis_data.shape}")
```

**Output:** `model_data/inputs/stage2_features/{AXIS}_features_1084_20251029.csv`

**Expected dimensions:**
- Rows: ~900 species (varies by axis EIVE coverage)
- Columns: ~736 features (741 - 5 provenance cols - 1 target EIVE + 1 y)

---

### 4.2 Tier 2 Feature Table (11,680 species)

```python
import pandas as pd

# Load full production dataset
production = pd.read_csv('model_data/outputs/perm2_production/perm2_11680_complete_final_20251028.csv')

# Specify axis (T, M, L, N, or R)
AXIS = 'T'

# Filter to species with non-missing axis value
axis_data = production[production[f'EIVEres-{AXIS}'].notna()].copy()
print(f"Axis {AXIS}: {len(axis_data)} species with observed EIVE")

# Rename target axis to 'y'
axis_data['y'] = axis_data[f'EIVEres-{AXIS}']

# Drop target axis column (prevent data leakage)
axis_data = axis_data.drop(columns=[f'EIVEres-{AXIS}'])

# Drop provenance columns (not needed for modeling)
provenance_cols = [c for c in axis_data.columns if '_source' in c]
if provenance_cols:
    axis_data = axis_data.drop(columns=provenance_cols)
    print(f"Dropped {len(provenance_cols)} provenance columns")

# Save feature table
output_path = f'model_data/inputs/stage2_features/{AXIS}_features_11680_20251029.csv'
axis_data.to_csv(output_path, index=False)
print(f"Saved: {output_path}")
print(f"Shape: {axis_data.shape}")
```

**Output:** `model_data/inputs/stage2_features/{AXIS}_features_11680_20251029.csv`

**Expected dimensions:**
- Rows: ~6,000-6,500 species (varies by axis EIVE coverage, ~52.8% overall)
- Columns: ~268 features

---

## 5. Modeling Commands

### 5.1 Tier 1: Hyperparameter Tuning (1,084 species)

**Script:** `src/Stage_2/xgb_kfold.py`

**Example for T axis:**
```bash
/home/olier/miniconda3/envs/AI/bin/python src/Stage_2/xgb_kfold.py \
  --features_csv model_data/inputs/stage2_features/T_features_1084_20251029.csv \
  --axis T \
  --out_dir model_data/outputs/stage2_xgb/T_1084_20251029 \
  --cv_folds 10 \
  --learning_rates 0.03,0.05,0.08 \
  --n_estimators_grid 1500,3000,5000 \
  --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
  --gpu true
```

**Parameters:**
- `--features_csv`: Tier 1 feature table (1,084 species)
- `--learning_rates`: 3 values to test
- `--n_estimators_grid`: 3 tree counts to test
- `--pd_vars`: Variables for partial dependence plots (optional)
- `--gpu`: Use GPU if available (faster)

**Repeat for all 5 axes:** T, M, L, N, R

**Output location:** `model_data/outputs/stage2_xgb/{AXIS}_1084_20251029/`

---

### 5.2 Tier 2: Production Modeling (11,680 species)

**After tier 1 grid search completes, extract optimal hyperparameters:**

```bash
# Extract optimal config from tier 1 grid
best_lr=$(python -c "import pandas as pd; df = pd.read_csv('model_data/outputs/stage2_xgb/T_1084_20251029/xgb_T_cv_grid.csv'); print(df.loc[0, 'learning_rate'])")
best_n=$(python -c "import pandas as pd; df = pd.read_csv('model_data/outputs/stage2_xgb/T_1084_20251029/xgb_T_cv_grid.csv'); print(int(df.loc[0, 'n_estimators']))")

echo "Optimal config for T axis: learning_rate=$best_lr, n_estimators=$best_n"
```

**Run production model with optimal config:**

```bash
/home/olier/miniconda3/envs/AI/bin/python src/Stage_2/xgb_kfold.py \
  --features_csv model_data/inputs/stage2_features/T_features_11680_20251029.csv \
  --axis T \
  --out_dir model_data/outputs/stage2_xgb/T_11680_20251029 \
  --cv_folds 10 \
  --learning_rates $best_lr \
  --n_estimators_grid $best_n \
  --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
  --gpu true
```

**Key differences from tier 1:**
- Uses tier 2 feature table (11,680 species)
- Single hyperparameter combination (optimal from tier 1)
- Produces final production model

**Repeat for all 5 axes:** T, M, L, N, R

**Output location:** `model_data/outputs/stage2_xgb/{AXIS}_11680_20251029/`

---

## 6. Output Files (Per Axis)

### 6.1 Tier 1 Outputs (1,084 species)

**Grid search results:**
- `xgb_<AXIS>_cv_grid.csv` → All 9 combinations ranked by R²
- `xgb_<AXIS>_cv_metrics.json` → Summary metrics for best config

**Model artifacts:**
- `xgb_<AXIS>_model.json` → XGBoost model (best config)
- `xgb_<AXIS>_scaler.json` → Z-score parameters

**Diagnostics:**
- `xgb_<AXIS>_cv_predictions_kfold.csv` → Row-level predictions/residuals
- `xgb_<AXIS>_shap_importance.csv` → Feature importance rankings

**Optional:**
- `xgb_<AXIS>_pd1_*.csv` → Partial dependence plots (1D)
- `xgb_<AXIS>_pd2_*.csv` → Partial dependence plots (2D)

---

### 6.2 Tier 2 Outputs (11,680 species)

**Production model:**
- `xgb_<AXIS>_model.json` → Final XGBoost model (optimal config)
- `xgb_<AXIS>_scaler.json` → Z-score parameters for deployment

**Performance metrics:**
- `xgb_<AXIS>_cv_metrics.json` → R²/RMSE/MAE from 10-fold CV
- `xgb_<AXIS>_cv_grid.csv` → Single row (optimal config performance)

**Predictions:**
- `xgb_<AXIS>_cv_predictions_kfold.csv` → Row-level predictions for 6,165 observed EIVE
- Future: Apply model to 5,515 species lacking EIVE → predict + uncertainty

**Diagnostics:**
- `xgb_<AXIS>_shap_importance.csv` → Feature importance on 11,680 species
- Optional PD plots

---

## 7. Expected Performance Metrics

Based on Stage 2 experiments (Oct 2024), expected 10-fold CV performance:

| Axis | Tier 1 (1,084) | Tier 2 (11,680) | Notes |
|------|----------------|-----------------|-------|
| **T** | R² ≈ 0.82 | R² ≈ 0.80-0.82 | Climate-dominated, stable |
| **M** | R² ≈ 0.65 | R² ≈ 0.63-0.65 | Moderate difficulty |
| **L** | R² ≈ 0.63 | R² ≈ 0.60-0.63 | Light availability |
| **N** | R² ≈ 0.71 | R² ≈ 0.68-0.71 | Nutrient signal |
| **R** | R² ≈ 0.58 | R² ≈ 0.55-0.58 | Most challenging |

**Tier 2 may show slight degradation:**
- More species with sparse GBIF coverage (environmental uncertainty)
- Lower EIVE coverage (52.8% vs 83%) → harder to learn patterns
- But: phylo predictors (94%) + eigenvectors (99.6%) should compensate

---

## 8. Verification Checklist

### 8.1 Data Readiness

**Before modeling:**
- [ ] Feature tables created for all 5 axes (2 tiers each = 10 files)
- [ ] No missing `y` values in feature tables
- [ ] Provenance columns removed (`*_source`)
- [ ] Log traits are finite (no inf/-inf)
- [ ] Expected species counts:
  - Tier 1: ~900 per axis (varies by EIVE coverage)
  - Tier 2: ~6,000-6,500 per axis

---

### 8.2 Tier 1 Grid Search Validation

**After tier 1 completes:**
- [ ] Grid file exists: `xgb_<AXIS>_cv_grid.csv`
- [ ] Grid has 9 rows (3 lr × 3 n_estimators)
- [ ] Best config is row 0 (sorted by R², tie-broken by RMSE)
- [ ] R² values reasonable (T ≥ 0.80, M/L/N ≥ 0.55, R ≥ 0.35)
- [ ] No training failures (check logs for errors)

**Extract optimal hyperparameters:**
```bash
python -c "import pandas as pd; df = pd.read_csv('model_data/outputs/stage2_xgb/T_1084_20251029/xgb_T_cv_grid.csv'); print(f\"Best: lr={df.loc[0, 'learning_rate']}, n={int(df.loc[0, 'n_estimators'])}, R²={df.loc[0, 'mean_r2']:.3f}\")"
```

---

### 8.3 Tier 2 Production Validation

**After tier 2 completes:**
- [ ] Production model exists: `xgb_<AXIS>_model.json`
- [ ] Scaler exists: `xgb_<AXIS>_scaler.json`
- [ ] Predictions file has ~6,000-6,500 rows
- [ ] R² within 2% of tier 1 (e.g., tier 1 = 0.82 → tier 2 ≥ 0.80)
- [ ] SHAP importance: top features are ecological (not provenance)
- [ ] Residuals: no heavy tails (|residual| > 3 SD)

**Compare tier 1 vs tier 2 performance:**
```bash
python << 'PY'
import pandas as pd

t1 = pd.read_csv('model_data/outputs/stage2_xgb/T_1084_20251029/xgb_T_cv_grid.csv')
t2 = pd.read_csv('model_data/outputs/stage2_xgb/T_11680_20251029/xgb_T_cv_grid.csv')

print(f"Tier 1 (1,084): R² = {t1.loc[0, 'mean_r2']:.4f}, RMSE = {t1.loc[0, 'mean_rmse']:.4f}")
print(f"Tier 2 (11,680): R² = {t2.loc[0, 'mean_r2']:.4f}, RMSE = {t2.loc[0, 'mean_rmse']:.4f}")
print(f"Δ R²: {t2.loc[0, 'mean_r2'] - t1.loc[0, 'mean_r2']:.4f} ({100*(t2.loc[0, 'mean_r2'] - t1.loc[0, 'mean_r2'])/t1.loc[0, 'mean_r2']:.1f}%)")
PY
```

---

## 9. Next Steps

### 9.1 Immediate (Stage 2)

1. **Create feature tables** for all 5 axes (2 tiers each)
2. **Run tier 1 grid search** for all axes (parallelizable)
3. **Extract optimal configs** from tier 1 grids
4. **Run tier 2 production** for all axes with optimal configs
5. **Validate performance** using checklist above

---

### 9.2 Future (Stage 3)

1. **Apply production models** to 5,515 species lacking EIVE
2. **Uncertainty quantification** from CV fold predictions
3. **Spatial validation** of predicted EIVE (if geographic data available)
4. **Export predictions** to pan-European trait database
5. **Documentation** per axis (`2.1_L_Axis_XGBoost.md`, etc.)

---

## 10. File Structure Summary

```
model_data/
├── inputs/
│   ├── modelling_master_1084_20251029.parquet          # Tier 1 master
│   └── stage2_features/
│       ├── T_features_1084_20251029.csv                # Tier 1 features (T)
│       ├── T_features_11680_20251029.csv               # Tier 2 features (T)
│       ├── M_features_1084_20251029.csv                # ... repeat for M, L, N, R
│       └── ...
├── outputs/
│   ├── perm2_production/
│   │   └── perm2_11680_complete_final_20251028.csv     # Tier 2 master
│   └── stage2_xgb/
│       ├── T_1084_20251029/                            # Tier 1 outputs (T)
│       │   ├── xgb_T_cv_grid.csv                       # Grid search results
│       │   ├── xgb_T_model.json
│       │   └── ...
│       ├── T_11680_20251029/                           # Tier 2 outputs (T)
│       │   ├── xgb_T_model.json                        # Production model
│       │   ├── xgb_T_cv_predictions_kfold.csv
│       │   └── ...
│       └── ...                                         # Repeat for M, L, N, R
```

---

## 11. References

**Stage 1 documentation:**
- `1.7a_Imputation_Dataset_Preparation.md` → Feature engineering
- `1.7d_XGBoost_Production_Imputation.md` → Trait imputation
- `1.9_Phylogenetic_Predictor_and_Verification.md` → Phylo predictors
- `1.10_Modelling_Master_Table.md` → Final datasets

**Coverage verification:**
- `results/verification/phylo_predictor_coverage_detailed_analysis_20251029.md`
- `results/verification/phylo_predictor_coverage_comparison_20251029.md`

**XGBoost script:**
- `src/Stage_2/xgb_kfold.py` → Main modeling script

---

**Document updated:** 2025-10-29
**Status:** Ready for tier 1 grid search

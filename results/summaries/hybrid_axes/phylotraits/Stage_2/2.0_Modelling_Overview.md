# Stage 2 — XGBoost Modelling Overview

## Purpose
- **Objective**: transition from Stage 1 data products (traits, climate, soil, agroclim, phylogeny) to Stage 2 axis models using XGBoost.
- **Scope**: focus on the 1 084-species modelling shortlist; encyclopedia-scale (11.6 k) tables are out-of-scope for this round.
- **Model family**: XGBoost regressors only; no Random Forest reruns for Stage 2.
- **Validation**: retain canonical 10-fold CV with shuffled species, but skip LOSO and spatial blocks.

## Inputs & Preparation
- **Traits & environment**: `model_data/inputs/modelling_master_20251022.{parquet,csv}` (log traits, imputed gaps, climate/soil/agroclim quantiles, `p_phylo_*`, `sla_source` provenance).
- **Axis references**: see Stage 1 summaries (`1.7`, `1.9`, `1.10`) for derivation of `log*` targets and species coverage.
- **Feature assembly** (per axis):
  1. Filter the modelling master to species with non-missing axis scores.
  2. Select predictor columns (traits, climate, soil, agroclim, phylo) and rename the axis value to `y`.
  3. Write one CSV per axis to `model_data/inputs/stage2_features/<AXIS>_features_YYYYMMDD.csv`.
- **Species column**: preserve `species_normalized` for fold diagnostics.

## Modelling Command
- **Script**: `src/Stage_2/xgb_kfold.py` (new Stage 2 helper; simplified from legacy `Stage_3RF_XGBoost/analyze_xgb_hybrid_interpret.py`).
- **Hyperparameter search**: per axis the script now sweeps **three learning rates** and **three tree counts** (up to 5 000 trees) when supplied via `--learning_rates` and `--n_estimators_grid`. Each combination shares the same depth/subsample settings; the best (highest mean R², tie-broken by lowest RMSE) is chosen automatically and logged.
- **Anti-leakage safeguards**: inside every CV fold the training split is standardised (mean/SD) before fitting; those statistics are then applied to the held-out species, preventing any peek at validation data. Columns with no finite values are dropped prior to modelling.
- **Baseline defaults**: if no grid is provided the runner falls back to the canonical settings (`n_estimators=600`, `learning_rate=0.05`, `max_depth=6`, `subsample=0.8`, `colsample_bytree=0.8`).
- **Example**:
  ```bash
  conda run -n AI python src/Stage_2/xgb_kfold.py \
    --features_csv model_data/inputs/stage2_features/T_features_20251022.csv \
    --axis T \
    --out_dir model_data/outputs/stage2_xgb/T_20251022 \
    --cv_folds 10 \
    --learning_rates 0.03,0.05,0.08 \
    --n_estimators_grid 1500,3000,5000 \
    --pd_vars "logLA,logLDMC,logSLA,logSM,logH,p_phylo_T" \
    --pd_pairs "logLDMC:wc2.1_30s_bio_12_q50,logSM:wc2.1_30s_bio_4_q50"
  ```
- **GPU toggle**: `--gpu true` when CUDA is available; leave `false` for CPU.

## Outputs
- `xgb_<AXIS>_cv_metrics.json` → aggregate R²/RMSE/MAE summary.
- `xgb_<AXIS>_cv_metrics_kfold.json` → same metrics with explicit strategy flag.
- `xgb_<AXIS>_cv_grid.csv` → full hyperparameter grid (learning rate, tree count, metrics per combo).
- `xgb_<AXIS>_cv_predictions_kfold.csv` → row-level fold predictions/residuals (species-aware).
- `xgb_<AXIS>_shap_importance.csv` → mean absolute contribution for each predictor.
- Optional PD files (`xgb_<AXIS>_pd1_*`, `xgb_<AXIS>_pd2_*`) when variables are requested.
- `xgb_<AXIS>_model.json` & `xgb_<AXIS>_scaler.json` → serialized booster and z-score parameters for downstream reuse.
- Per-axis write-ups: `2.1_L_Axis_XGBoost.md`, `2.2_T_Axis_XGBoost.md`, `2.3_M_Axis_XGBoost.md`, `2.4_N_Axis_XGBoost.md`, `2.5_R_Axis_XGBoost.md`.

## Verification Plan
- **Data readiness**
  - Feature CSV: no missing `y`; all numeric traits (leaf area, Nmass, LDMC, SLA, seed mass, height) strictly positive or in valid fraction ranges.
  - Confirm redundant columns (raw LMA/SLA, sample counts, `_imputed_flag/_sd`) are absent so the model only sees canonical predictors.
- **Run audit**
  - Capture console output in `logs/stage2_xgb/YYYYMMDD/<AXIS>.log` and ensure the 3×3 hyperparameter grid executes without failure.
  - Inspect `xgb_<AXIS>_cv_grid.csv` to verify the selected combo matches the highest mean R² (tie-broken by RMSE).
- **Metric sanity**
  - Compare k-fold metrics against canonical expectations (`R² ≥ 0.55` for T/M/L, `≥ 0.45` for N, `≥ 0.35` for R) and flag deviations > 0.10.
  - Recalculate MAE/RMSE from `xgb_<AXIS>_cv_predictions_kfold.csv` to confirm they match the JSON summary.
- **Top predictors & residuals**
  - Review `xgb_<AXIS>_shap_importance.csv` to ensure the top 15 features align with ecological expectations (no provenance columns).
  - Check residual distribution for heavy tails (`|residual| > 3 × sd`) and cross-reference with Stage 1 trait diagnostics if anomalies persist.
- **Artefact integrity**
- Confirm `xgb_<AXIS>_model.json` and `xgb_<AXIS>_scaler.json` are produced and the scaler includes only the retained predictor list.

## Verification Log
- Latest run (2025-10-22): `logs/stage2_xgb/20251022/verification_summary.md`.

## Next Steps
- Automate feature-table generation (Python helper in `src/Stage_2`) to guarantee reproducible axis CSVs.
- Define a Makefile target (`stage2_xgb_all`) that iterates axes (T, M, L, N, R) and writes outputs under `model_data/outputs/stage2_xgb/<AXIS>_YYYYMMDD/`.
- Draft Stage 2 reporting templates summarizing CV metrics, feature importances, and PD insight for integration with Stage 3 documentation.
- Add regression tests that confirm column naming conventions (underscores) so future runs do not drop partial-dependence pairs silently.

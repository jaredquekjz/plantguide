# Stage 1.7c — BHPMF Gap-Filling and Imputation

**Canonical BHPMF imputation pipeline using sklearn 10-fold CV and SLA as canonical trait**

**Date:** 2025-10-25
**Purpose:** BHPMF-based trait imputation with standardized CV methodology
**Dependencies:** 1.7b Imputation Dataset Preparation

---

## 1. Methodology Overview

1. **Canonical SLA principle**
   - Uses **SLA (mm²/mg)** as THE canonical leaf economics trait (not LMA)
   - Priority: Direct measurements > LMA-converted (1000/LMA) > Imputed
   - Eliminates redundancy when used as predictors
   - Consistent across BHPMF, XGBoost, and Stage 2 modelling

2. **Balanced chunking**
   - Random shuffle before chunking to ensure balanced trait coverage across all 6 chunks
   - Prevents chunk006 hanging issue (78% all-missing → 14.6%)

3. **Sklearn 10-fold CV**
   - Uses `sklearn.model_selection.KFold(n_splits=10, shuffle=True, random_state=20251025)`
   - Cell-level masking: For each trait, mask 10% of observed values per fold
   - Same methodology as Stage 2 modelling for consistency
   - 6 chunks × 6 traits × 10 folds = **360 CV runs**

4. **BHPMF gap filling**
   - Traits imputed (following Schrodt et al. 2015 methodology):
     `Leaf area (mm2)`, `Nmass (mg/g)`, `SLA (mm2/mg)`, `Plant height (m)`, `Diaspore mass (mg)`, `LDMC`
   - Workflow: Raw → log-transform → z-standardize → BHPMF → un-standardize → exp() to original
   - Environmental covariates: **156 q50 features (WorldClim, SoilGrids, Agroclim) - COMPLETE**
   - Pre-computed log transforms: Used as auxiliary features (6 additional predictors)
   - **NO raw trait auxiliary features** (attempted but broke imputation - see Section 5)
   - Hierarchical structure: genus + family
   - Parameters:
     ```
     used_levels = 0          # genus + species
     prediction_level = 2     # species
     num_samples = 1000
     burn = 100
     gaps = 2
     num_latent = 10
     tuning = false
     ```

---

## 2. Canonical Input Files

| File | Path | Purpose |
|------|------|---------|
| **BHPMF input (merged)** | `model_data/inputs/trait_imputation_input_canonical_20251025_merged.csv` | 11,680 sp × 172 cols (16 trait + 156 env) |
| **Balanced chunks** | `model_data/inputs/chunks_canonical_20251025/` | 6 chunks × ~1,947 species each (merged data) |
| **10-fold CV datasets** | `model_data/inputs/bhpmf_cv_10fold_canonical_masked/` | 360 masked datasets (6×6×10) |
| **Environmental features** | `model_data/inputs/env_features_shortlist_20251025_complete_q50_xgb.csv` | **156 q50 features (COMPLETE)** |
| **Traits source** | `model_data/inputs/traits_model_ready_20251022_shortlist.csv` | Source traits before aggregation |

---

## 3. Reproduction Commands

### 3.1 Create Canonical Input with SLA

```bash
conda run -n AI python src/Stage_1/create_bhpmf_canonical_input.py \
  --traits=model_data/inputs/traits_model_ready_20251022_shortlist.csv \
  --env=model_data/inputs/env_features_shortlist_20251025_complete_q50_xgb.csv \
  --output=model_data/inputs/trait_imputation_input_canonical_20251025_merged.csv
```

**Output:** 11,680 species × 172 columns (16 trait + 156 env)
- SLA coverage: 5,524 obs (47.3%) — includes direct + LMA-converted
- Genus/Family present for BHPMF hierarchy
- Environmental coverage: 100% (all 11,680 species)

---

### 3.2 Create Balanced Chunks

```bash
conda run -n AI python src/Stage_1/create_balanced_chunks.py \
  --input=model_data/inputs/trait_imputation_input_canonical_20251025_merged.csv \
  --output_dir=model_data/inputs/chunks_canonical_20251025 \
  --n_chunks=6 \
  --seed=20251025
```

**Output:** 6 balanced chunks with ~14.6% all-missing species each (vs 78% in old chunk006)
- Chunks contain MERGED data (172 columns: traits + env)

---

### 3.3 Build 10-Fold CV Datasets

```bash
conda run -n AI python src/Stage_1/build_bhpmf_10fold_cv_datasets.py \
  --chunk_dir=model_data/inputs/chunks_canonical_20251025/traits \
  --output_dir=model_data/inputs/bhpmf_cv_10fold_canonical_masked \
  --n_folds=10 \
  --seed=20251025
```

**Output:** 360 masked CSV files (6 chunks × 6 traits × 10 folds)

---

### 3.4 Run BHPMF 10-Fold CV

```bash
nohup bash src/Stage_1/run_bhpmf_10fold_canonical_cv.sh \
  > logs/bhpmf_10fold_canonical_nohup_20251025.log 2>&1 &
```

**Runtime:** ~60 minutes (360 runs × ~10 sec each)

**Monitor:**
```bash
tail -f logs/bhpmf_10fold_canonical_nohup_20251025.log
```

**Script:** `src/Stage_1/run_bhpmf_10fold_canonical_cv.sh`

**R wrapper:** `src/legacy/Stage_2_Data_Processing/phylo_impute_traits_bhpmf.R`

---

### 3.5 Collect Results

```bash
conda run -n AI python src/Stage_1/collect_bhpmf_10fold_results.py \
  --cv_dir=model_data/outputs/bhpmf_cv_10fold_canonical \
  --output=model_data/outputs/bhpmf_cv_10fold_canonical_predictions.csv
```

**Output:** Aggregated predictions with log/logit-scale RMSE per trait

---

## 4. BHPMF 10-Fold CV Results

**Date:** 2025-10-25
**Status:** ✓ COMPLETED
**Runtime:** ~56 minutes (360 runs)
**Predictions:** 34,421 test observations

**RMSE Summary (log/logit scale, sklearn 10-fold CV):**

| Trait | RMSE | Scale | Test n |
|-------|------|-------|--------|
| **Leaf area (mm²)** | **2.3535** | log | 5,232 |
| **Nmass (mg/g)** | **0.5284** | log | 4,085 |
| **SLA (mm²/mg)** | **0.8056** | log | 5,524 |
| **Plant height (m)** | **2.2005** | log | 9,009 |
| **Diaspore mass (mg)** | **3.5562** | log | 7,696 |
| **LDMC** | **4.6038** | logit | 2,875 |

**Configuration:**
- Dataset: 11,680-species shortlist (canonical SLA)
- CV: sklearn 10-fold (6 chunks × 6 traits × 10 folds = 360 runs)
- Output: `model_data/outputs/bhpmf_cv_10fold_canonical_predictions.csv`

---

## 4b. BHPMF 10-Fold CV Results (ORIGINAL SCALE - Complete Env)

**Date:** 2025-10-25
**Status:** ✓ COMPLETED (with bug fixes)
**Dataset:** 11,680 species × 172 columns (16 trait + 156 env q50)
**Environmental:** WorldClim (63) + SoilGrids (42) + Agroclim (51)
**Runtime:** ~60 minutes (360 runs)

**CRITICAL:** BHPMF works in log-space internally, but for fair comparison with XGBoost (which imputes in original scale), RMSE is reported in **original scale**.

**Bug Fixes Applied (2025-10-25):** Two critical bugs were discovered and fixed:
1. **Missing environmental features:** 156 env q50 columns in merged data were NOT being included in BHPMF matrix. Fixed by adding auto-detection for `_q50` columns already present in data.
2. **Broken raw trait auxiliary feature:** Raw trait copies (`*_raw`) were created AFTER CV masking, so they were also NA when the target was masked. This defeated the purpose and caused BHPMF to impute both, producing nonsensical predictions (correlation -0.111, 60% stuck at two values). Fixed by removing raw trait feature entirely (not in original paper anyway).

**Validation:** After fixes, test fold showed:
- Correlation: -0.111 → 0.285 ✓
- Mean prediction: 76.59 → 15.48 (vs 17.38 obs) ✓
- Stuck values: 480/812 → 0 ✓

**Conservative Approach:** Following original BHPMF paper (Schrodt et al. 2015):
- Raw traits → log-transform → z-standardize → BHPMF → back-transform
- Pre-computed log transforms used as auxiliary features (not raw copies)
- Report RMSE in original scale for XGBoost comparison

**RMSE Summary (original scale, 10-fold CV with 156 env features):**

| Trait | RMSE (orig) | Std | Test n | Folds |
|-------|-------------|-----|--------|-------|
| **Leaf area (mm²)** | **925,244.77** | 589,142.52 | 5,212 | 60 |
| **Nmass (mg/g)** | **38.76** | 16.87 | 4,048 | 60 |
| **SLA (mm²/mg)** | **62.44** | 32.40 | 5,510 | 60 |
| **Plant height (m)** | **492.89** | 394.37 | 8,079 | 60 |
| **Diaspore mass (mg)** | **208,494.32** | 223,156.55 | 7,319 | 60 |
| **LDMC** | **0.3129** | 0.0693 | 2,866 | 60 |

**Notes:**
- Large RMSE values for Leaf area and Diaspore mass reflect highly skewed distributions with extreme outliers
- BHPMF predictions were converted from log-space to original scale before RMSE calculation
- Each fold represents 6 chunks × 10 folds = 60 independent evaluations
- Ready for direct comparison with XGBoost (which imputes in original scale)

**Reproduction:**
```bash
# Compute original-scale RMSE from BHPMF output
conda run -n AI python scripts/compute_bhpmf_canonical_rmse.py
```

**Output:** `model_data/outputs/bhpmf_cv_10fold_canonical/bhpmf_10fold_cv_rmse_original_scale.csv`

**Comparison with log-scale RMSE (Section 4):**
- Log-scale RMSE (Section 4): Evaluates log-space predictions directly
- Original-scale RMSE (Section 4b): Converts predictions back to original scale for comparison with XGBoost
- Both are valid metrics, but original-scale enables fair cross-method comparison

---

## 5. Verification Checklist

### 5.1 Input Verification

```bash
conda run -n AI python -c "
import pandas as pd
df = pd.read_csv('model_data/inputs/trait_imputation_input_canonical_20251025_merged.csv')
assert df.shape == (11680, 172), f'Wrong dimensions: {df.shape}'
assert 'SLA (mm2/mg)' in df.columns, 'Missing canonical SLA'
assert 'Genus' in df.columns and 'Family' in df.columns, 'Missing hierarchy'
env_cols = [c for c in df.columns if c.endswith('_q50')]
assert len(env_cols) == 156, f'Wrong env count: {len(env_cols)}'
print('✓ Canonical input verified')
print(f'  Shape: {df.shape}')
print(f'  SLA coverage: {df[\"SLA (mm2/mg)\"].notna().sum()} ({100*df[\"SLA (mm2/mg)\"].notna().mean():.1f}%)')
print(f'  Env features: {len(env_cols)} q50 columns')
"
```

---

### 5.2 Chunk Balance Verification

```bash
for chunk in model_data/inputs/chunks_canonical_20251025/*.csv; do
  conda run -n AI python -c "
import pandas as pd, sys
df = pd.read_csv('$chunk')
all_missing = df[['Leaf area (mm2)', 'Nmass (mg/g)', 'SLA (mm2/mg)',
                  'Plant height (m)', 'Diaspore mass (mg)', 'LDMC']].isna().all(axis=1).mean()
sla_cov = df['SLA (mm2/mg)'].notna().mean()
print(f'{sys.argv[1]}: {len(df)} sp, {100*all_missing:.1f}% all-missing, {100*sla_cov:.1f}% SLA')
" "$(basename $chunk)"
done
```

**Expected:** ~14.6% all-missing, ~47% SLA coverage (balanced across all chunks)

---

### 5.3 CV Output Verification

```bash
conda run -n AI python -c "
import pandas as pd
preds = pd.read_csv('model_data/outputs/bhpmf_cv_10fold_canonical_predictions.csv')
print('✓ CV predictions loaded')
print(f'  Total predictions: {len(preds)}')
print(f'  Traits: {preds[\"trait\"].unique().tolist()}')
print(f'  RMSE summary:')
for trait in preds['trait'].unique():
    rmse = preds[preds['trait'] == trait]['rmse'].iloc[0]
    n = preds[preds['trait'] == trait]['n_test'].iloc[0]
    print(f'    {trait}: RMSE={rmse:.4f}, n={n}')
"
```

---

## 6. Key Implementation Details

### 6.1 R Script Updates for Canonical SLA

**File:** `src/legacy/Stage_2_Data_Processing/phylo_impute_traits_bhpmf.R`

**Critical bug fixes applied (2025-10-25):**

**Bug Fix #1: Auto-detect environmental q50 columns**
```r
# AUTO-DETECT environmental q50 columns already in merged data (for merged workflow)
env_q50_cols <- grep("_q50$", names(dt), value = TRUE)
if (length(env_q50_cols) > 0 && !add_env_covars) {
  ok(sprintf("Auto-detected %d env q50 columns already in merged data", length(env_q50_cols)))
  num_cols_all <- unique(c(num_cols_all, env_q50_cols))
}
```
- **Problem:** 156 env columns in merged data were ignored because script only added env if `--add_env_covars=true`
- **Fix:** Auto-detect `_q50` columns already present in merged data

**Bug Fix #2: Removed broken raw trait auxiliary feature**
```r
# DUAL-SCALE MODIFICATION: DISABLED FOR CV (creates raw copies AFTER masking = broken)
# Raw trait copies are created AFTER CV masking, so they're also NA when target is masked.
# This defeats the purpose (using raw as covariate) and causes BHPMF to impute both.
# For CV: Use log transforms only, not raw copies.

# Add pre-computed log transforms as auxiliary features (like XGBoost)
num_cols_log <- intersect(c("logLA", "logNmass", "logSLA", "logH", "logSM", "logLDMC"), names(dt))
num_cols_all  <- unique(c(num_cols_core, num_cols_new, traits_existing, num_cols_log))
```
- **Problem:** Raw copies created AFTER masking → both target and raw copy NA → BHPMF imputes both → catastrophic failure
- **Fix:** Use pre-computed log transforms as auxiliary features (not raw copies)
- **Rationale:** Original paper (Schrodt et al. 2015) uses log → z-standardize workflow, not raw trait auxiliary features

**Canonical SLA support:**
```r
# 1. Updated core traits list to use SLA
num_cols_core <- c("Leaf area (mm2)", "Nmass (mg/g)", "SLA (mm2/mg)",
                   "Plant height (m)", "Diaspore mass (mg)")

# 2. Legacy LMA support (auto-convert if present)
if (!("SLA (mm2/mg)" %in% names(dt)) && ("LMA (g/m2)" %in% names(dt))) {
  dt$`SLA (mm2/mg)` <- 1000 / dt$`LMA (g/m2)`
  message("Converted LMA to SLA (SLA = 1000/LMA)")
}

# 3. Updated log traits list
log_traits <- c("Leaf area (mm2)", "Nmass (mg/g)", "SLA (mm2/mg)",
                "Plant height (m)", "Diaspore mass (mg)")
```

**Backwards compatibility:** Script accepts both SLA (canonical) and LMA (legacy), auto-converting as needed.

---

### 6.2 CV Methodology: Cell-Level Holdout

**BHPMF uses cell-level cross-validation**, which correctly evaluates imputation tasks:

- When imputing trait X for a species, BHPMF can use:
  - Other observed traits (Y, Z) from the SAME species
  - Environmental features
  - Genus/Family hierarchical structure

- This is **cell-level holdout** (testing individual trait-species pairs), NOT species-level holdout (testing completely unseen species)

**Comparison to XGBoost:**
- Both methods use cell-level CV
- Both test the same task: Impute missing trait using partial observations + context
- BHPMF: 10-fold (10% test), XGBoost: 10-fold (10% test) — NOW MATCHED
- Fair comparison when using same dataset and CV methodology

---

## 7. Cross-Validation Results

### 7.1 RMSE Summary (Sklearn 10-Fold CV)

**Date:** 2025-10-26
**Runtime:** 59 minutes (360 runs)
**Output:** `model_data/outputs/bhpmf_cv_10fold_canonical_predictions.csv`

| Trait | RMSE (log/logit) | Test n | Median Obs |
|-------|------------------|--------|------------|
| Leaf area (mm²) | 1.9585 | 5,232 | 700.0 |
| Nmass (mg/g) | 0.4346 | 4,085 | 20.2 |
| LDMC | 2.5692 | 2,875 | 0.23 |
| SLA (mm²/mg) | 0.6212 | 5,524 | 15.5 |
| Plant height (m) | 1.7856 | 9,009 | 0.80 |
| Diaspore mass (mg) | 3.6060 | 7,696 | 2.56 |

**Notes:**
- RMSE computed on log scale (or logit for LDMC)
- Training set: ~1,800 species per chunk (due to memory constraints)
- BHPMF configuration: 156 env q50 features, no raw trait auxiliary features
- Conservative approach following Schrodt et al. 2015

---

### 7.2 Known Limitations

**Training Set Size:**
- BHPMF: ~1,800 species per chunk (17% of full dataset)
- Hardware limitation: Cannot fit full 11,680-species matrix in memory
- Impact: Reduces ability to learn global trait-environment relationships

**Feature Engineering:**
- No raw trait auxiliary features (caused catastrophic failures)
- Cannot leverage cross-scale relationships like XGBoost
- Limited to in-place transforms (raw → log → z-standardize → BHPMF)

**See Section 5.3 in 1.7d_XGBoost_Imputation_Summary.md for detailed BHPMF vs XGBoost comparison**

---

## 8. Scripts Reference

| Script | Purpose | Location |
|--------|---------|----------|
| `create_bhpmf_canonical_input.py` | Convert traits_model_ready to BHPMF format with canonical SLA | `src/Stage_1/` |
| `create_balanced_chunks.py` | Create 6 balanced chunks via random shuffle | `src/Stage_1/` |
| `build_bhpmf_10fold_cv_datasets.py` | Generate 360 masked CV datasets | `src/Stage_1/` |
| `verify_bhpmf_pre_flight.py` | Comprehensive pre-flight verification | `src/Stage_1/` |
| `run_bhpmf_10fold_canonical_cv.sh` | Bash wrapper for 360 BHPMF runs | `src/Stage_1/` |
| `phylo_impute_traits_bhpmf.R` | Core BHPMF imputation with env covariates | `src/legacy/Stage_2_Data_Processing/` |
| `collect_bhpmf_10fold_results.py` | Aggregate CV results and compute RMSE | `src/Stage_1/` |

---

## 9. Notes

- **Cell-level CV is the correct methodology** for imputation tasks (not species-level CV)
- **Canonical SLA standardization** ensures consistency across BHPMF, XGBoost, and Stage 2
- **Balanced chunking** prevents BHPMF hanging on chunks with extreme sparsity
- **10-fold CV** matches Stage 2 methodology for consistency and best practices
- **See 1.7d_XGBoost_Imputation_Summary.md** for XGBoost comparison and combined results

---

**Status:** ✓ Complete
**CV Results:** ✓ 10-fold sklearn CV complete (2025-10-26, 59 min runtime)
**Bugs Fixed:** ✓ Missing env auto-detection + broken raw trait feature removed (2025-10-25)
**Methodology:** ✓ Conservative approach following Schrodt et al. 2015 (log → z-standardize → BHPMF)

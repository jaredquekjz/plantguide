# XGBoost Imputation Verification Pipeline

**Date:** 2025-10-24
**Purpose:** Comprehensive verification of Perm3 11,680-species XGBoost imputation
**Input:** `model_data/inputs/mixgb_perm3_11680/mixgb_perm3_11680_eta0025_3000trees_20251024_m*.csv`

---

## Overview

This pipeline verifies the XGBoost imputation process is scientifically sound through:
1. **Dataset construction validation** - Pre-imputation dataset integrity checks
2. **Automated checks** - Statistical and biological plausibility validation
3. **Manual inspection** - Visual review requiring human judgment
4. **Data leakage prevention** - CV methodology audit

---

## 1. Dataset Construction Validation (PRE-IMPUTATION)

### 1.1 Column Structure Verification

**Purpose:** Ensure input dataset matches Perm3 specification exactly

**Checks:**

| Check | Expected | Validation |
|-------|----------|------------|
| **Total columns** | 182 | Exact count |
| **Row count** | 11,680 | Shortlist size |
| **Column ordering** | Matches Perm3 reference | Byte-for-byte header match |
| **Identifiers** | wfo_taxon_id, wfo_scientific_name | Present and unique |

**Implementation:**
```python
# Load reference column list from Perm3 1,084 dataset
reference_cols = pd.read_csv('perm3_1084_reference.csv').columns.tolist()
dataset_cols = pd.read_csv('mixgb_input_perm3_11680.csv').columns.tolist()

# Check exact match
if reference_cols != dataset_cols:
    print("âŒ Column structure mismatch")
    missing = set(reference_cols) - set(dataset_cols)
    extra = set(dataset_cols) - set(reference_cols)
    if missing:
        print(f"   Missing: {missing}")
    if extra:
        print(f"   Extra: {extra}")
else:
    print("âœ… Column structure MATCHES Perm3 reference")
```

**Success criteria:** Exact 182-column match with Perm3 reference

---

### 1.2 Feature Composition Verification

**Purpose:** Verify all required feature categories present

**Checks:**

| Feature Category | Expected Count | Validation |
|------------------|----------------|------------|
| **Target traits** | 6 | leaf_area_mm2, nmass_mg_g, ldmc_frac, lma_g_m2, plant_height_m, seed_mass_mg |
| **Provenance** | 6 | *_source columns for each target trait |
| **TRY categorical** | 4 | try_woodiness, try_growth_form, try_habitat_adaptation, try_leaf_type |
| **Environmental q50** | 136 | WorldClim (44), SoilGrids (42), AgroClim (51) |
| **Log transforms** | 6 | logLA, logH, logSM, logLDMC, logNmass, logSLA |
| **Phylogenetic** | 5 | phylo_depth, phylo_terminal, genus_code, family_code, phylo_proxy_fallback |
| **Alternate traits** | 15 | try_*, aust_* columns |
| **Text taxonomy** | 2 | genus, family |

**Implementation:**
```python
required_features = {
    'target_traits': ['leaf_area_mm2', 'nmass_mg_g', 'ldmc_frac', 'lma_g_m2', 'plant_height_m', 'seed_mass_mg'],
    'log_transforms': ['logLA', 'logH', 'logSM', 'logLDMC', 'logNmass', 'logSLA'],
    'try_categorical': ['try_woodiness', 'try_growth_form', 'try_habitat_adaptation', 'try_leaf_type'],
}

for category, cols in required_features.items():
    missing = [c for c in cols if c not in df.columns]
    if missing:
        print(f"âŒ {category}: Missing {missing}")
    else:
        print(f"âœ… {category}: All present ({len(cols)} columns)")
```

**Success criteria:** All feature categories present with expected counts

---

### 1.3 EIVE Exclusion Verification

**Purpose:** Confirm NO EIVE features present (Perm3 requirement)

**Checks:**

```python
# List of forbidden EIVE columns
forbidden_eive = [
    'p_phylo_T', 'p_phylo_M', 'p_phylo_L', 'p_phylo_N', 'p_phylo_R',
    'EIVEres_T', 'EIVEres_M', 'EIVEres_L', 'EIVEres_N', 'EIVEres_R',
    'EIVE_T', 'EIVE_M', 'EIVE_L', 'EIVE_N', 'EIVE_R',
    'logEIVE_T', 'logEIVE_M', 'logEIVE_L', 'logEIVE_N', 'logEIVE_R'
]

eive_present = [col for col in forbidden_eive if col in df.columns]

if eive_present:
    print(f"âŒ CRITICAL: EIVE features found: {eive_present}")
    print("   Perm3 REQUIRES no EIVE features")
else:
    print("âœ… EIVE exclusion verified")
```

**Success criteria:** Zero EIVE features present (CRITICAL)

---

### 1.4 Log Transform Computation Verification

**Purpose:** Verify log-transformed columns correctly computed from raw traits

**Checks:**

```python
log_pairs = {
    'leaf_area_mm2': 'logLA',
    'plant_height_m': 'logH',
    'seed_mass_mg': 'logSM',
    'ldmc_frac': 'logLDMC',  # Actually logit
    'nmass_mg_g': 'logNmass'
}

for raw_col, log_col in log_pairs.items():
    # Where raw value is present
    valid = df[raw_col].notna()

    # Compute expected log
    if log_col == 'logLDMC':
        # Logit transform
        eps = 1e-6
        x_clipped = df.loc[valid, raw_col].clip(eps, 1-eps)
        expected = np.log(x_clipped / (1 - x_clipped))
    else:
        # Log transform
        expected = np.log(df.loc[valid, raw_col])

    observed = df.loc[valid, log_col]

    # Check match
    max_diff = abs(expected - observed).max()

    if max_diff > 0.01:
        print(f"âŒ {log_col}: Max difference {max_diff:.6f}")
    else:
        print(f"âœ… {log_col}: Correctly computed (max diff {max_diff:.6f})")
```

**Success criteria:** All log transforms match raw values within 0.01 tolerance

---

### 1.5 Missing Value Pattern Analysis

**Purpose:** Understand completeness of target traits before imputation

**Checks:**

```python
# Missing value report
print("\nTarget Trait Completeness (Pre-Imputation):")
print("-" * 60)

for trait in target_traits:
    n_present = df[trait].notna().sum()
    n_missing = df[trait].isna().sum()
    pct_complete = 100 * n_present / len(df)

    print(f"{trait:20s}: {n_present:5d}/{len(df):5d} ({pct_complete:5.1f}% complete)")
    print(f"                      {n_missing:5d} to be imputed")

# Cross-completeness matrix
print("\nCo-occurrence Matrix (species with BOTH traits observed):")
for i, trait1 in enumerate(target_traits):
    for trait2 in target_traits[i+1:]:
        both_present = (df[trait1].notna() & df[trait2].notna()).sum()
        print(f"  {trait1:20s} + {trait2:20s}: {both_present:5d} species")
```

**Success criteria:** Informational only, no pass/fail

---

### 1.6 Data Type Validation

**Purpose:** Ensure correct data types for modeling

**Checks:**

```python
# Check categorical columns
categorical_cols = ['try_woodiness', 'try_growth_form', 'try_habitat_adaptation', 'try_leaf_type']

for col in categorical_cols:
    if df[col].dtype == 'object' or df[col].dtype.name == 'category':
        n_levels = df[col].nunique()
        print(f"âœ… {col:30s}: {df[col].dtype} ({n_levels} levels)")
    else:
        print(f"âŒ {col:30s}: Should be categorical, is {df[col].dtype}")

# Check numeric columns
numeric_cols = target_traits + [f'log{x}' for x in ['LA', 'H', 'SM', 'LDMC', 'Nmass', 'SLA']]

for col in numeric_cols:
    if col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            print(f"âœ… {col:30s}: numeric")
        else:
            print(f"âŒ {col:30s}: Should be numeric, is {df[col].dtype}")
```

**Success criteria:** All categoricals as object/category, all traits/logs as numeric

---

### 1.7 Dataset Construction Workflow

**Execution sequence:**
```bash
# Step 1: Verify dataset construction (5 min)
conda run -n AI python scripts/verify_dataset_construction.py \
  --input_csv=model_data/inputs/mixgb_perm3_11680/mixgb_input_perm3_shortlist_11680_20251024.csv \
  --reference_csv=model_data/inputs/mixgb_perm3_1084/mixgb_input_perm3_1084_20251023.csv \
  --output_report=results/verification/perm3_11680/dataset_construction_report.txt

# Output: PASS/FAIL report with detailed findings
```

**Success criteria summary:**
- âœ… 182 columns matching Perm3 reference
- âœ… All feature categories present
- âœ… Zero EIVE features (CRITICAL)
- âœ… Log transforms correctly computed
- âœ… Correct data types

---

## 2. Biological Plausibility Checks (POST-IMPUTATION)

### 2.1 Value Range Validation

**Purpose:** Ensure imputed values fall within biologically plausible ranges

**Checks:**

| Trait | Min | Max | Transform | Validation |
|-------|-----|-----|-----------|------------|
| **leaf_area_mm2** | 0.1 | 1,000,000 | log | Reject if â‰¤0 or >1e6 mmÂ² |
| **nmass_mg_g** | 0.1 | 100 | log | Reject if â‰¤0 or >100 mg/g (10% dry weight) |
| **ldmc_frac** | 0.01 | 0.99 | logit | MUST be fraction [0,1], reject if outside |
| **lma_g_m2** | 1 | 1000 | log | Reject if â‰¤0 or >1000 g/mÂ² |
| **plant_height_m** | 0.001 | 150 | log | Reject if â‰¤0 or >150m (tallest trees) |
| **seed_mass_mg** | 0.001 | 1,000,000 | log | Reject if â‰¤0 or >1e6 mg (~1kg, largest seeds) |

**Implementation:**
```python
# For each imputed dataset m1-m10
for trait, (min_val, max_val) in trait_bounds.items():
    outliers = df[(df[trait] < min_val) | (df[trait] > max_val)]
    if len(outliers) > 0:
        print(f"âš ï¸  {len(outliers)} {trait} values outside [{min_val}, {max_val}]")
        # Flag for manual review
```

**Success criteria:** <0.1% of imputed values outside plausible ranges

---

### 2.2 Trait Relationship Validation

**Purpose:** Verify known allometric and physical relationships are preserved

#### A. LMA â‰ˆ 1/SLA (Inverse Relationship)

**Theory:** Leaf Mass per Area (LMA) and Specific Leaf Area (SLA) are physical inverses

**Check:**
```python
# Both LMA and SLA present in dataset
# sla_mm2_mg is SLA, lma_g_m2 is LMA (need unit conversion)

# Convert: lma_g_m2 â†’ mg/mm2: lma * (1000 mg/g) / (1e6 mm2/m2) = lma / 1000
lma_in_mg_mm2 = df['lma_g_m2'] / 1000

# Expected: sla_mm2_mg â‰ˆ 1 / lma_in_mg_mm2
expected_sla = 1.0 / lma_in_mg_mm2
observed_sla = df['sla_mm2_mg']

# Compute relative error
rel_error = abs(expected_sla - observed_sla) / expected_sla

# Flag if >50% discrepancy (accounting for measurement error)
inconsistent = rel_error > 0.5
```

**Success criteria:** <5% of species with LMA-SLA discrepancy >50%

#### B. Height-Seed Mass Allometry

**Theory:** Taller plants tend to have larger seeds (Moles et al. 2005)

**Check:**
```python
# Correlation should be positive for log-log relationship
corr = np.corrcoef(np.log(df['plant_height_m'].dropna()),
                   np.log(df['seed_mass_mg'].dropna()))[0,1]

# Expected: positive correlation (typically r=0.3-0.5)
if corr < 0:
    print(f"âš ï¸  Height-SeedMass correlation NEGATIVE: {corr:.3f}")
```

**Success criteria:** Positive correlation (r > 0)

#### C. LDMC-LMA Coordination

**Theory:** Leaf Dry Matter Content (LDMC) and LMA are positively correlated (leaf economics spectrum)

**Check:**
```python
# Both should be positively correlated
corr = np.corrcoef(df['ldmc_frac'].dropna(),
                   df['lma_g_m2'].dropna())[0,1]

# Expected: positive correlation (typically r=0.4-0.6)
if corr < 0.2:
    print(f"âš ï¸  LDMC-LMA correlation WEAK: {corr:.3f}")
```

**Success criteria:** Positive correlation (r > 0.2)

---

### 2.3 Imputation Completeness

**Purpose:** Verify all missing values were imputed

**Checks:**
```python
# Count missing values per trait in original vs imputed
original_missing = original_df[target_traits].isna().sum()
imputed_missing = imputed_df[target_traits].isna().sum()

# Should be ZERO missing in imputed datasets
if imputed_missing.sum() > 0:
    print(f"âŒ FAILED: {imputed_missing.sum()} missing values remain after imputation")
```

**Success criteria:** Zero missing values in all 6 target traits

---

### 2.4 Log Transform Consistency

**Purpose:** Verify log-transformed columns match raw trait values

**Checks:**
```python
# For each log-transformed trait
trait_log_pairs = {
    'leaf_area_mm2': 'logLA',
    'nmass_mg_g': 'logNmass',
    'ldmc_frac': 'logLDMC',  # Actually logit, handle separately
    'lma_g_m2': None,  # No explicit log column
    'plant_height_m': 'logH',
    'seed_mass_mg': 'logSM'
}

for trait, log_col in trait_log_pairs.items():
    if log_col and log_col in df.columns:
        expected_log = np.log(df[trait])
        observed_log = df[log_col]

        # Check if they match (allowing small numerical error)
        max_diff = abs(expected_log - observed_log).max()
        if max_diff > 0.01:
            print(f"âš ï¸  {trait} vs {log_col} mismatch: max diff = {max_diff:.4f}")
```

**Success criteria:** Log columns match raw traits within 0.01 tolerance

---

## 2. Data Leakage Prevention Audit

### 2.1 CV Script Review

**Purpose:** Verify cross-validation does not leak test data into training

**Manual audit checklist:**

- [ ] **Test fold masking:** `df_fold[[trait]][test_local_idx] <- NA_real_` (line 160 of CV script)
  - âœ… Confirmed: Test values are set to NA before imputation

- [ ] **Feature preparation on masked data:** `prepare_features(df_fold)` called AFTER masking
  - âœ… Confirmed: Line 162 operates on masked dataset

- [ ] **No global statistics leakage:** Check if z-score standardization uses training fold only
  - âš ï¸  **TO VERIFY:** mixgb package internal standardization
  - Action: Inspect mixgb source or test with known data

- [ ] **Random fold assignment:** `set.seed(20251022); fold_ids <- sample(...)` (lines 138, 152)
  - âœ… Confirmed: Reproducible random assignment

- [ ] **Predictions only on test fold:** `preds <- imputed[[trait]][test_local_idx]` (line 173)
  - âœ… Confirmed: Only test indices used for RMSE calculation

**Success criteria:** All 5 checklist items verified âœ…

---

### 2.2 Z-Score Standardization Verification

**Purpose:** Verify mixgb does not use test fold statistics for standardization

**Test procedure:**

1. Create synthetic dataset with known train/test split
2. Inject obvious signal in test fold (e.g., mean=100, train mean=0)
3. Run mixgb CV and check if test signal affects predictions
4. If test statistics leak, predictions will be anomalous

**Implementation:**
```r
# Create test dataset
test_data <- data.frame(
  trait_target = c(rnorm(800, mean=0), rnorm(200, mean=100)),  # Obvious test shift
  feature1 = rnorm(1000),
  feature2 = rnorm(1000)
)

# Run CV with known fold (fold 1 = rows 801-1000)
# If mixgb uses global mean, predictions on fold 1 will be biased
# If mixgb uses training-only mean, predictions will be unbiased
```

**Success criteria:** Test fold statistics do NOT influence training

**Status:** â³ TO BE IMPLEMENTED

---

## 3. Manual Inspection Checkpoints

### 3.1 Distribution Visualization

**Purpose:** Human review of imputed value distributions

**Procedure:**
```python
import matplotlib.pyplot as plt
import seaborn as sns

for trait in target_traits:
    fig, axes = plt.subplots(1, 2, figsize=(12, 4))

    # Original distribution (observed only)
    axes[0].hist(original_df[trait].dropna(), bins=50, alpha=0.7, label='Observed')
    axes[0].set_title(f'{trait} - Original (Observed Only)')
    axes[0].set_xlabel(trait)

    # Imputed distribution (all values)
    axes[1].hist(imputed_df[trait], bins=50, alpha=0.7, label='Imputed', color='orange')
    axes[1].hist(original_df[trait].dropna(), bins=50, alpha=0.5, label='Observed', color='blue')
    axes[1].set_title(f'{trait} - Imputed vs Observed')
    axes[1].set_xlabel(trait)
    axes[1].legend()

    plt.tight_layout()
    plt.savefig(f'results/verification/perm3_11680/distributions/{trait}_distribution.png', dpi=150)
    plt.close()
```

**Manual review questions:**
- [ ] Do imputed distributions roughly match observed distributions?
- [ ] Are there unusual modes or gaps in imputed data?
- [ ] Are extreme values (tails) plausible?

**Output:** 6 distribution plots (one per trait)

---

### 3.2 Outlier Review

**Purpose:** Manual review of extreme imputed values

**Procedure:**
```python
# Extract top/bottom 1% of imputed values
for trait in target_traits:
    # For originally missing values only
    was_missing = original_df[trait].isna()
    imputed_values = imputed_df.loc[was_missing, trait]

    # Get extreme values
    p01 = imputed_values.quantile(0.01)
    p99 = imputed_values.quantile(0.99)

    outliers_low = imputed_df[was_missing & (imputed_df[trait] < p01)]
    outliers_high = imputed_df[was_missing & (imputed_df[trait] > p99)]

    # Export for manual review
    outliers = pd.concat([outliers_low, outliers_high])
    outliers[['wfo_scientific_name', trait] + predictor_cols].to_csv(
        f'results/verification/perm3_11680/outliers/{trait}_outliers_p01_p99.csv',
        index=False
    )
```

**Manual review questions:**
- [ ] Are extreme species taxonomically plausible? (e.g., Wolffia for tiny, Sequoia for large)
- [ ] Do predictor features justify extreme values? (e.g., high seed mass with high height)
- [ ] Are any extreme values data quality issues?

**Output:** 6 outlier CSV files (one per trait) + flagged species list

---

### 3.3 Trait Relationship Plots

**Purpose:** Visual inspection of key allometric relationships

**Plots to generate:**

1. **LMA vs SLA (should be hyperbolic inverse)**
```python
plt.scatter(df['lma_g_m2'], df['sla_mm2_mg'], alpha=0.3, s=10)
plt.plot([0, 500], [1000/0, 1000/500], 'r--', label='Perfect inverse (LMA=1000/SLA)')
plt.xlabel('LMA (g/mÂ²)')
plt.ylabel('SLA (mmÂ²/mg)')
plt.xscale('log')
plt.yscale('log')
plt.legend()
plt.savefig('results/verification/perm3_11680/relationships/lma_vs_sla.png', dpi=150)
```

2. **Height vs Seed Mass (positive log-log)**
```python
plt.scatter(df['plant_height_m'], df['seed_mass_mg'], alpha=0.3, s=10)
plt.xlabel('Plant Height (m)')
plt.ylabel('Seed Mass (mg)')
plt.xscale('log')
plt.yscale('log')
plt.savefig('results/verification/perm3_11680/relationships/height_vs_seedmass.png', dpi=150)
```

3. **LDMC vs LMA (positive linear)**
```python
plt.scatter(df['ldmc_frac'], df['lma_g_m2'], alpha=0.3, s=10)
plt.xlabel('LDMC (fraction)')
plt.ylabel('LMA (g/mÂ²)')
plt.savefig('results/verification/perm3_11680/relationships/ldmc_vs_lma.png', dpi=150)
```

**Manual review questions:**
- [ ] Does LMA-SLA relationship follow expected inverse pattern?
- [ ] Is height-seed mass correlation positive and reasonable?
- [ ] Does LDMC-LMA show expected leaf economics spectrum?

**Output:** 3 relationship scatter plots

---

## 4. Verification Workflow

### 4.1 Execution Sequence

```bash
# Step 1: Run automated checks (10 min)
conda run -n AI python scripts/verify_xgboost_imputation.py \
  --original_csv=model_data/inputs/mixgb_perm3_11680/mixgb_input_perm3_shortlist_11680_20251024.csv \
  --imputed_csv=model_data/inputs/mixgb_perm3_11680/mixgb_perm3_11680_eta0025_3000trees_20251024_m1.csv \
  --output_dir=results/verification/perm3_11680/automated

# Step 2: Generate manual inspection materials (5 min)
conda run -n AI python scripts/verify_xgboost_imputation.py \
  --mode=manual_inspection \
  --original_csv=model_data/inputs/mixgb_perm3_11680/mixgb_input_perm3_shortlist_11680_20251024.csv \
  --imputed_csv=model_data/inputs/mixgb_perm3_11680/mixgb_perm3_11680_eta0025_3000trees_20251024_m1.csv \
  --output_dir=results/verification/perm3_11680/manual

# Step 3: Manual review (30-60 min human time)
# - Review plots in results/verification/perm3_11680/manual/
# - Review outlier CSV files
# - Document findings in verification report

# Step 4: Data leakage test (15 min)
env R_LIBS_USER="/home/olier/ellenberg/.Rlib" \
  conda run -n AI Rscript scripts/test_mixgb_data_leakage.R \
  --output_report=results/verification/perm3_11680/data_leakage_test.txt
```

---

### 4.2 Output Structure

```
results/verification/perm3_11680/
â”œâ”€â”€ automated/
â”‚   â”œâ”€â”€ value_range_check.csv          # Outliers outside plausible ranges
â”‚   â”œâ”€â”€ trait_relationships_check.csv  # LMA-SLA, Height-Seed correlations
â”‚   â”œâ”€â”€ completeness_check.txt         # Missing value counts
â”‚   â”œâ”€â”€ log_consistency_check.csv      # Log column mismatches
â”‚   â””â”€â”€ summary_report.txt             # Pass/fail summary
â”‚
â”œâ”€â”€ manual/
â”‚   â”œâ”€â”€ distributions/
â”‚   â”‚   â”œâ”€â”€ leaf_area_mm2_distribution.png
â”‚   â”‚   â”œâ”€â”€ nmass_mg_g_distribution.png
â”‚   â”‚   â”œâ”€â”€ ldmc_frac_distribution.png
â”‚   â”‚   â”œâ”€â”€ lma_g_m2_distribution.png
â”‚   â”‚   â”œâ”€â”€ plant_height_m_distribution.png
â”‚   â”‚   â””â”€â”€ seed_mass_mg_distribution.png
â”‚   â”‚
â”‚   â”œâ”€â”€ relationships/
â”‚   â”‚   â”œâ”€â”€ lma_vs_sla.png
â”‚   â”‚   â”œâ”€â”€ height_vs_seedmass.png
â”‚   â”‚   â””â”€â”€ ldmc_vs_lma.png
â”‚   â”‚
â”‚   â””â”€â”€ outliers/
â”‚       â”œâ”€â”€ leaf_area_mm2_outliers_p01_p99.csv
â”‚       â”œâ”€â”€ nmass_mg_g_outliers_p01_p99.csv
â”‚       â”œâ”€â”€ ldmc_frac_outliers_p01_p99.csv
â”‚       â”œâ”€â”€ lma_g_m2_outliers_p01_p99.csv
â”‚       â”œâ”€â”€ plant_height_m_outliers_p01_p99.csv
â”‚       â””â”€â”€ seed_mass_mg_outliers_p01_p99.csv
â”‚
â””â”€â”€ data_leakage_test.txt               # Z-score standardization audit
```

---

## 5. Success Criteria Summary

### CRITICAL (Must Pass)
- âœ… Zero missing values in target traits after imputation
- âœ… All values within biologically plausible ranges (<0.1% violations)
- âœ… CV script does not leak test fold data
- âœ… LMA-SLA inverse relationship preserved (<5% high discrepancy)

### IMPORTANT (Investigate if Failed)
- âš ï¸  Imputed distributions roughly match observed distributions
- âš ï¸  Height-seed mass positive correlation maintained
- âš ï¸  LDMC-LMA positive correlation maintained
- âš ï¸  Log-transformed columns consistent with raw values

### NICE-TO-HAVE (Review but Not Blockers)
- ğŸ“Š Outliers taxonomically sensible
- ğŸ“Š Trait relationship plots show expected patterns
- ğŸ“Š No systematic bias in imputed vs observed distributions

---

## 6. Verification Report Template

```markdown
# XGBoost Imputation Verification Report

**Date:** YYYY-MM-DD
**Imputed dataset:** mixgb_perm3_11680_eta0025_3000trees_20251024_m1.csv
**Reviewer:** [Name]

## Automated Checks

### 1. Value Range Validation
- [ ] PASS: <0.1% outliers
- [ ] FAIL: XX% outliers in [trait]
  - Action: [describe]

### 2. Trait Relationships
- [ ] PASS: LMA-SLA discrepancy <5%
- [ ] PASS: Height-Seed correlation positive (r=XX)
- [ ] PASS: LDMC-LMA correlation positive (r=XX)

### 3. Completeness
- [ ] PASS: Zero missing values

### 4. Log Consistency
- [ ] PASS: Max log mismatch <0.01

## Manual Inspection

### 1. Distribution Review
- [ ] leaf_area_mm2: [PASS/REVIEW/FAIL] - Notes: _____
- [ ] nmass_mg_g: [PASS/REVIEW/FAIL] - Notes: _____
- [ ] ldmc_frac: [PASS/REVIEW/FAIL] - Notes: _____
- [ ] lma_g_m2: [PASS/REVIEW/FAIL] - Notes: _____
- [ ] plant_height_m: [PASS/REVIEW/FAIL] - Notes: _____
- [ ] seed_mass_mg: [PASS/REVIEW/FAIL] - Notes: _____

### 2. Outlier Review
- Flagged species: [list species with extreme values requiring review]
- Concerns: [describe any data quality issues]

### 3. Relationship Plots
- [ ] LMA vs SLA: [Expected inverse pattern observed? Y/N]
- [ ] Height vs Seed Mass: [Positive correlation observed? Y/N]
- [ ] LDMC vs LMA: [Positive correlation observed? Y/N]

## Data Leakage Audit
- [ ] PASS: Test fold masking confirmed
- [ ] PASS: Z-score standardization uses training fold only

## Overall Verdict
- [ ] **APPROVED** - Imputation passed all critical checks
- [ ] **APPROVED WITH NOTES** - Passed critical, minor issues documented
- [ ] **REJECTED** - Critical issues require re-imputation

**Signature:** _______________
**Date:** _______________
```

---

## 7. References

### Biological Plausibility
- **LMA-SLA inverse:** Wright et al. (2004) "The worldwide leaf economics spectrum"
- **Height-Seed allometry:** Moles et al. (2005) "Seed size and plant strategy across the whole life cycle"
- **Trait value ranges:** TRY Database trait definitions, Kattge et al. (2020)

### Data Leakage Prevention
- **Cross-validation best practices:** Varma & Simon (2006) "Bias in error estimation when using cross-validation for model selection"
- **mixgb package:** Deng & Lumley (2024) "Multiple Imputation Through XGBoost"

### Scripts
- **Verification script:** `scripts/verify_xgboost_imputation.py`
- **Data leakage test:** `scripts/test_mixgb_data_leakage.R`
- **CV script audit:** `model_data/inputs/mixgb/mixgb_cv_eval_parameterized.R`

---

**Status:** Pipeline designed, awaiting implementation
